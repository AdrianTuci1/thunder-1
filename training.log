âš¡ Thunder Trace: Script started, importing dependencies...
âš¡ Thunder Trace: Basic dependencies imported. Importing local modules...
/workspace/thunder/core/model_loader.py:2: UserWarning: WARNING: Unsloth should be imported before [transformers] to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.

Please restructure your imports with 'import unsloth' at the top of your file.
  from unsloth import FastLanguageModel
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
[bitsandbytes.cextension|WARNING]WARNING: BNB_CUDA_VERSION=128 environment variable detected; loading libbitsandbytes_cuda128.so.
This can be used to load a bitsandbytes version built with a CUDA version that is different from the PyTorch CUDA version.
If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=

ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
âš¡ Thunder Trace: All modules imported.
âš¡ Thunder Trace: Initializing run_training...
âš¡ Thunder Trace: Calling loader.load_model(inference_mode=False)...
âš¡ Thunder: Loading model unsloth/Llama-3.2-3B-Instruct with 2048 context...
==((====))==  Unsloth 2026.2.1: Fast Llama patching. Transformers: 4.57.6.
   \\   /|    NVIDIA GeForce RTX 4090. Num GPUs = 1. Max memory: 23.526 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.10.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.6.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.35. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
âš¡ Thunder PrefixLM: Adapting architecture for Diffusion (x0-parametrization)...
âš¡ Thunder PrefixLM: Activating Bidirectional Attention...
âš¡ Thunder Trace: Model and tokenizer loaded.
âš¡ Thunder PrefixLM: Applying new LoRA adapters...
âš¡ Thunder PrefixLM: Injecting LoRA (r=128, alpha=256)...
Unsloth 2026.2.1 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.
âš¡ Thunder Trace: Preparing datasets...
âš¡ Thunder: Preparing dataset ['Open-Orca/SlimOrca', 'nickrosh/Evol-Instruct-Code-80k-v1', 'qwedsacf/competition_math', 'nomic-ai/gpt4all-j-prompt-generations', 'zai-org/LongAlign-10k', 'nohurry/Opus-4.6-Reasoning-3000x-filtered']...
âš¡ Thunder: Loading dataset Open-Orca/SlimOrca...
âš¡ Thunder: Loading dataset nickrosh/Evol-Instruct-Code-80k-v1...
âš¡ Thunder: Loading dataset qwedsacf/competition_math...
âš¡ Thunder: Loading dataset nomic-ai/gpt4all-j-prompt-generations...
âš¡ Thunder: Loading dataset zai-org/LongAlign-10k...
âš¡ Thunder: Loading dataset nohurry/Opus-4.6-Reasoning-3000x-filtered...
âš¡ Thunder: Interleaving 6 datasets with ratios [0.15, 0.15, 0.1, 0.2, 0.2, 0.2]...
âš¡ Thunder: Preparing dataset (Augmentation: False)...
âš¡ Thunder Trace: Dataset prepared.
âš¡ Thunder PrefixLM: Starting custom training loop on cuda:0...
âš¡ Thunder: Training for 55000 total iterations (updates)...
Training:   0%|          | 0/55000 [00:00<?, ?it/s]Unsloth: Will smartly offload gradients to save VRAM!
Training:   0%|          | 1/55000 [00:15<236:28:17, 15.48s/it]Training:   0%|          | 1/55000 [00:15<236:28:17, 15.48s/it, Loss=11.5296, Denoising=11.3628]Training:   0%|          | 2/55000 [00:26<200:12:49, 13.11s/it, Loss=11.5296, Denoising=11.3628]Training:   0%|          | 2/55000 [00:27<200:12:49, 13.11s/it, Loss=11.5693, Denoising=11.4102]Training:   0%|          | 3/55000 [00:40<204:42:00, 13.40s/it, Loss=11.5693, Denoising=11.4102]Training:   0%|          | 3/55000 [00:40<204:42:00, 13.40s/it, Loss=11.5462, Denoising=11.3735]Training:   0%|          | 4/55000 [00:54<209:22:24, 13.71s/it, Loss=11.5462, Denoising=11.3735]Training:   0%|          | 4/55000 [00:55<209:22:24, 13.71s/it, Loss=11.5278, Denoising=11.3681]Training:   0%|          | 5/55000 [01:07<202:12:05, 13.24s/it, Loss=11.5278, Denoising=11.3681]Training:   0%|          | 5/55000 [01:07<202:12:05, 13.24s/it, Loss=11.5384, Denoising=11.3727]Training:   0%|          | 6/55000 [01:21<206:15:22, 13.50s/it, Loss=11.5384, Denoising=11.3727]Training:   0%|          | 6/55000 [01:21<206:15:22, 13.50s/it, Loss=11.4800, Denoising=11.3120]Training:   0%|          | 7/55000 [01:35<211:42:47, 13.86s/it, Loss=11.4800, Denoising=11.3120]Training:   0%|          | 7/55000 [01:36<211:42:47, 13.86s/it, Loss=11.3303, Denoising=11.1644]Training:   0%|          | 8/55000 [01:49<211:24:46, 13.84s/it, Loss=11.3303, Denoising=11.1644]Training:   0%|          | 8/55000 [01:49<211:24:46, 13.84s/it, Loss=11.5094, Denoising=11.3390]Training:   0%|          | 9/55000 [02:05<218:51:13, 14.33s/it, Loss=11.5094, Denoising=11.3390]Training:   0%|          | 9/55000 [02:05<218:51:13, 14.33s/it, Loss=11.4128, Denoising=11.2575]Training:   0%|          | 10/55000 [02:19<218:16:25, 14.29s/it, Loss=11.4128, Denoising=11.2575]Training:   0%|          | 10/55000 [02:19<218:16:25, 14.29s/it, Loss=11.5425, Denoising=11.3720]Training:   0%|          | 11/55000 [02:30<203:09:00, 13.30s/it, Loss=11.5425, Denoising=11.3720]Training:   0%|          | 11/55000 [02:30<203:09:00, 13.30s/it, Loss=11.5453, Denoising=11.3723]Training:   0%|          | 12/55000 [02:44<207:20:02, 13.57s/it, Loss=11.5453, Denoising=11.3723]Training:   0%|          | 12/55000 [02:44<207:20:02, 13.57s/it, Loss=11.6531, Denoising=11.4859]Training:   0%|          | 13/55000 [02:58<211:05:12, 13.82s/it, Loss=11.6531, Denoising=11.4859]Training:   0%|          | 13/55000 [02:59<211:05:12, 13.82s/it, Loss=11.5625, Denoising=11.3936]Training:   0%|          | 14/55000 [03:13<214:35:23, 14.05s/it, Loss=11.5625, Denoising=11.3936]Training:   0%|          | 14/55000 [03:13<214:35:23, 14.05s/it, Loss=11.4818, Denoising=11.3219]Training:   0%|          | 15/55000 [03:26<210:29:34, 13.78s/it, Loss=11.4818, Denoising=11.3219]Training:   0%|          | 15/55000 [03:26<210:29:34, 13.78s/it, Loss=11.4414, Denoising=11.2591]Training:   0%|          | 16/55000 [03:37<199:12:08, 13.04s/it, Loss=11.4414, Denoising=11.2591]Training:   0%|          | 16/55000 [03:38<199:12:08, 13.04s/it, Loss=11.4995, Denoising=11.3311]Training:   0%|          | 17/55000 [03:50<198:27:41, 12.99s/it, Loss=11.4995, Denoising=11.3311]Training:   0%|          | 17/55000 [03:50<198:27:41, 12.99s/it, Loss=11.4981, Denoising=11.3305]Training:   0%|          | 18/55000 [04:04<201:50:29, 13.22s/it, Loss=11.4981, Denoising=11.3305]Training:   0%|          | 18/55000 [04:04<201:50:29, 13.22s/it, Loss=11.5307, Denoising=11.3632]Training:   0%|          | 19/55000 [04:16<197:08:14, 12.91s/it, Loss=11.5307, Denoising=11.3632]Training:   0%|          | 19/55000 [04:16<197:08:14, 12.91s/it, Loss=11.5331, Denoising=11.3742]Training:   0%|          | 20/55000 [04:30<201:15:02, 13.18s/it, Loss=11.5331, Denoising=11.3742]Training:   0%|          | 20/55000 [04:30<201:15:02, 13.18s/it, Loss=11.5567, Denoising=11.3915]
--- PREVIEW (Step 20 | t=428) ---
Logit Range: [-0.35, 1.02]
Target: ### User:
Compute the sum of all prime numbers between 1000 and 1100, excluding any prime numbers that are palindromes. Additionally, for each prime number, print out its factors and determine whether...
Predict:  lá»‡antu:
Compute the sum of all key numbers between 1000 and 1100, excluding any prime numbers that are palindromes. Additionally, for each key number, print out its factors and determine whether it i...
--------------------------------------

Training:   0%|          | 21/55000 [04:44<204:29:42, 13.39s/it, Loss=11.5567, Denoising=11.3915]Training:   0%|          | 21/55000 [04:44<204:29:42, 13.39s/it, Loss=11.2551, Denoising=11.0857]Training:   0%|          | 22/55000 [04:58<206:22:48, 13.51s/it, Loss=11.2551, Denoising=11.0857]Training:   0%|          | 22/55000 [04:58<206:22:48, 13.51s/it, Loss=11.4603, Denoising=11.3013]Training:   0%|          | 23/55000 [05:10<199:59:54, 13.10s/it, Loss=11.4603, Denoising=11.3013]Training:   0%|          | 23/55000 [05:10<199:59:54, 13.10s/it, Loss=11.5034, Denoising=11.3253]Training:   0%|          | 24/55000 [05:22<197:12:58, 12.91s/it, Loss=11.5034, Denoising=11.3253]Training:   0%|          | 24/55000 [05:23<197:12:58, 12.91s/it, Loss=11.4771, Denoising=11.3129]
[WARNING] NaN loss detected! Skipping batch.
Training:   0%|          | 25/55000 [05:35<197:51:56, 12.96s/it, Loss=11.4771, Denoising=11.3129]Training:   0%|          | 25/55000 [05:36<197:51:56, 12.96s/it, Loss=11.5201, Denoising=11.3571]Training:   0%|          | 26/55000 [05:49<199:15:45, 13.05s/it, Loss=11.5201, Denoising=11.3571]Training:   0%|          | 26/55000 [05:49<199:15:45, 13.05s/it, Loss=11.5003, Denoising=11.3391]Training:   0%|          | 27/55000 [06:03<202:44:48, 13.28s/it, Loss=11.5003, Denoising=11.3391]Training:   0%|          | 27/55000 [06:03<202:44:48, 13.28s/it, Loss=11.5316, Denoising=11.3564]Training:   0%|          | 28/55000 [06:17<208:49:19, 13.68s/it, Loss=11.5316, Denoising=11.3564]Training:   0%|          | 28/55000 [06:17<208:49:19, 13.68s/it, Loss=11.5442, Denoising=11.3840]Training:   0%|          | 29/55000 [06:30<207:10:41, 13.57s/it, Loss=11.5442, Denoising=11.3840]Training:   0%|          | 29/55000 [06:31<207:10:41, 13.57s/it, Loss=11.4486, Denoising=11.2905]Training:   0%|          | 30/55000 [06:45<209:41:02, 13.73s/it, Loss=11.4486, Denoising=11.2905]Training:   0%|          | 30/55000 [06:45<209:41:02, 13.73s/it, Loss=11.3800, Denoising=11.2059]Training:   0%|          | 31/55000 [06:58<209:59:41, 13.75s/it, Loss=11.3800, Denoising=11.2059]Training:   0%|          | 31/55000 [06:59<209:59:41, 13.75s/it, Loss=11.4915, Denoising=11.3279]Training:   0%|          | 32/55000 [07:13<213:53:42, 14.01s/it, Loss=11.4915, Denoising=11.3279]Training:   0%|          | 32/55000 [07:13<213:53:42, 14.01s/it, Loss=11.3627, Denoising=11.1920]Training:   0%|          | 33/55000 [07:27<215:06:33, 14.09s/it, Loss=11.3627, Denoising=11.1920]Training:   0%|          | 33/55000 [07:27<215:06:33, 14.09s/it, Loss=11.4719, Denoising=11.3044]Training:   0%|          | 34/55000 [07:40<209:04:37, 13.69s/it, Loss=11.4719, Denoising=11.3044]Training:   0%|          | 34/55000 [07:40<209:04:37, 13.69s/it, Loss=11.3192, Denoising=11.1414]Training:   0%|          | 35/55000 [07:53<206:02:10, 13.49s/it, Loss=11.3192, Denoising=11.1414]Training:   0%|          | 35/55000 [07:53<206:02:10, 13.49s/it, Loss=11.4472, Denoising=11.2741]Training:   0%|          | 36/55000 [08:06<202:48:40, 13.28s/it, Loss=11.4472, Denoising=11.2741]Training:   0%|          | 36/55000 [08:06<202:48:40, 13.28s/it, Loss=11.5710, Denoising=11.4048]Training:   0%|          | 37/55000 [08:20<204:46:59, 13.41s/it, Loss=11.5710, Denoising=11.4048]Training:   0%|          | 37/55000 [08:20<204:46:59, 13.41s/it, Loss=11.6850, Denoising=11.4980]Training:   0%|          | 38/55000 [08:34<210:14:56, 13.77s/it, Loss=11.6850, Denoising=11.4980]Training:   0%|          | 38/55000 [08:34<210:14:56, 13.77s/it, Loss=11.4917, Denoising=11.3220]Training:   0%|          | 39/55000 [08:49<213:33:18, 13.99s/it, Loss=11.4917, Denoising=11.3220]Training:   0%|          | 39/55000 [08:49<213:33:18, 13.99s/it, Loss=11.4316, Denoising=11.2626]Training:   0%|          | 40/55000 [09:02<208:57:23, 13.69s/it, Loss=11.4316, Denoising=11.2626]Training:   0%|          | 40/55000 [09:02<208:57:23, 13.69s/it, Loss=11.4190, Denoising=11.2438]
--- PREVIEW (Step 40 | t=332) ---
Logit Range: [-0.29, 1.15]
Target: ### Assistant:
You are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. While performing the task think step-by-step and justify your steps.
...
Predict: ### Assistant:
You are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. While performing the task think step-by-step and justify your steps.
...
--------------------------------------

Training:   0%|          | 41/55000 [09:13<200:37:25, 13.14s/it, Loss=11.4190, Denoising=11.2438]Training:   0%|          | 41/55000 [09:14<200:37:25, 13.14s/it, Loss=11.5466, Denoising=11.3799]Training:   0%|          | 42/55000 [09:28<204:59:13, 13.43s/it, Loss=11.5466, Denoising=11.3799]Training:   0%|          | 42/55000 [09:28<204:59:13, 13.43s/it, Loss=11.4485, Denoising=11.2659]Training:   0%|          | 43/55000 [09:42<208:31:37, 13.66s/it, Loss=11.4485, Denoising=11.2659]Training:   0%|          | 43/55000 [09:42<208:31:37, 13.66s/it, Loss=11.4940, Denoising=11.3338]Training:   0%|          | 44/55000 [09:54<202:38:27, 13.27s/it, Loss=11.4940, Denoising=11.3338]Training:   0%|          | 44/55000 [09:54<202:38:27, 13.27s/it, Loss=11.5428, Denoising=11.3802]Training:   0%|          | 45/55000 [10:07<202:50:28, 13.29s/it, Loss=11.5428, Denoising=11.3802]Training:   0%|          | 45/55000 [10:08<202:50:28, 13.29s/it, Loss=11.4868, Denoising=11.3138]Training:   0%|          | 46/55000 [10:22<207:03:15, 13.56s/it, Loss=11.4868, Denoising=11.3138]Training:   0%|          | 46/55000 [10:22<207:03:15, 13.56s/it, Loss=11.3915, Denoising=11.2183]Training:   0%|          | 47/55000 [10:37<213:40:43, 14.00s/it, Loss=11.3915, Denoising=11.2183]Training:   0%|          | 47/55000 [10:37<213:40:43, 14.00s/it, Loss=11.5490, Denoising=11.3820]Training:   0%|          | 48/55000 [10:48<201:54:23, 13.23s/it, Loss=11.5490, Denoising=11.3820]Training:   0%|          | 48/55000 [10:48<201:54:23, 13.23s/it, Loss=11.4497, Denoising=11.2838]Training:   0%|          | 49/55000 [11:02<206:22:06, 13.52s/it, Loss=11.4497, Denoising=11.2838]Training:   0%|          | 49/55000 [11:03<206:22:06, 13.52s/it, Loss=11.5568, Denoising=11.3816]Training:   0%|          | 50/55000 [11:17<211:21:30, 13.85s/it, Loss=11.5568, Denoising=11.3816]Training:   0%|          | 50/55000 [11:17<211:21:30, 13.85s/it, Loss=11.5891, Denoising=11.4287]Training:   0%|          | 51/55000 [11:30<207:09:12, 13.57s/it, Loss=11.5891, Denoising=11.4287]Training:   0%|          | 51/55000 [11:30<207:09:12, 13.57s/it, Loss=11.5298, Denoising=11.3561]Training:   0%|          | 52/55000 [11:43<204:32:38, 13.40s/it, Loss=11.5298, Denoising=11.3561]Training:   0%|          | 52/55000 [11:43<204:32:38, 13.40s/it, Loss=11.5947, Denoising=11.4366]Training:   0%|          | 53/55000 [11:58<211:54:34, 13.88s/it, Loss=11.5947, Denoising=11.4366]Training:   0%|          | 53/55000 [11:58<211:54:34, 13.88s/it, Loss=11.5410, Denoising=11.3686]Training:   0%|          | 54/55000 [12:11<209:45:44, 13.74s/it, Loss=11.5410, Denoising=11.3686]Training:   0%|          | 54/55000 [12:11<209:45:44, 13.74s/it, Loss=11.5324, Denoising=11.3670]Training:   0%|          | 55/55000 [12:23<198:32:21, 13.01s/it, Loss=11.5324, Denoising=11.3670]Training:   0%|          | 55/55000 [12:23<198:32:21, 13.01s/it, Loss=11.3957, Denoising=11.2265]Training:   0%|          | 56/55000 [12:32<181:49:33, 11.91s/it, Loss=11.3957, Denoising=11.2265]Training:   0%|          | 56/55000 [12:32<181:49:33, 11.91s/it, Loss=11.4673, Denoising=11.3090]Training:   0%|          | 57/55000 [12:45<188:38:56, 12.36s/it, Loss=11.4673, Denoising=11.3090]Training:   0%|          | 57/55000 [12:46<188:38:56, 12.36s/it, Loss=11.5047, Denoising=11.3409]Training:   0%|          | 58/55000 [12:55<175:34:06, 11.50s/it, Loss=11.5047, Denoising=11.3409]Training:   0%|          | 58/55000 [12:55<175:34:06, 11.50s/it, Loss=11.5014, Denoising=11.3319]Training:   0%|          | 59/55000 [13:08<184:15:08, 12.07s/it, Loss=11.5014, Denoising=11.3319]Training:   0%|          | 59/55000 [13:08<184:15:08, 12.07s/it, Loss=11.4675, Denoising=11.2970]Training:   0%|          | 60/55000 [13:22<191:05:55, 12.52s/it, Loss=11.4675, Denoising=11.2970]Training:   0%|          | 60/55000 [13:22<191:05:55, 12.52s/it, Loss=11.4822, Denoising=11.3156]
--- PREVIEW (Step 60 | t=163) ---
Logit Range: [-0.30, 0.85]
Target: ### User:
The operation $\Diamond$ is defined by $a\Diamond b=ab^2-b+1$.  What is the value of $(-1)\Diamond 6$?

### Assistant:
$$(-1)\Diamond 6=(-1)6^2-6+1=\boxed{-41}$$...
Predict: ### User:
The operation $\Diamond$ is defined by $a\Diamond b=ab^2-b+1$.  What is the value of $(-1)\Diamond 6$?

### Assistant:
$$(-1)\Diamond 6,1)6^2-6+1=\boxed{-41}$$ reflect reflect thankfully [ t...
--------------------------------------

Training:   0%|          | 61/55000 [13:37<202:34:24, 13.27s/it, Loss=11.4822, Denoising=11.3156]Training:   0%|          | 61/55000 [13:37<202:34:24, 13.27s/it, Loss=11.4135, Denoising=11.2532]Training:   0%|          | 62/55000 [13:49<198:18:58, 13.00s/it, Loss=11.4135, Denoising=11.2532]Training:   0%|          | 62/55000 [13:49<198:18:58, 13.00s/it, Loss=11.4160, Denoising=11.2512]Training:   0%|          | 63/55000 [14:01<193:23:23, 12.67s/it, Loss=11.4160, Denoising=11.2512]Training:   0%|          | 63/55000 [14:01<193:23:23, 12.67s/it, Loss=11.4917, Denoising=11.3226]Training:   0%|          | 64/55000 [14:13<190:38:58, 12.49s/it, Loss=11.4917, Denoising=11.3226]Training:   0%|          | 64/55000 [14:13<190:38:58, 12.49s/it, Loss=11.3339, Denoising=11.1724]Training:   0%|          | 65/55000 [14:26<190:29:20, 12.48s/it, Loss=11.3339, Denoising=11.1724]Training:   0%|          | 65/55000 [14:26<190:29:20, 12.48s/it, Loss=11.4497, Denoising=11.2789]Training:   0%|          | 66/55000 [14:39<192:44:16, 12.63s/it, Loss=11.4497, Denoising=11.2789]Training:   0%|          | 66/55000 [14:39<192:44:16, 12.63s/it, Loss=11.5037, Denoising=11.3368]Training:   0%|          | 67/55000 [14:51<193:26:51, 12.68s/it, Loss=11.5037, Denoising=11.3368]Training:   0%|          | 67/55000 [14:52<193:26:51, 12.68s/it, Loss=11.3367, Denoising=11.1715]Training:   0%|          | 68/55000 [15:05<198:35:25, 13.01s/it, Loss=11.3367, Denoising=11.1715]Training:   0%|          | 68/55000 [15:05<198:35:25, 13.01s/it, Loss=11.5164, Denoising=11.3439]Training:   0%|          | 69/55000 [15:18<197:21:15, 12.93s/it, Loss=11.5164, Denoising=11.3439]Training:   0%|          | 69/55000 [15:18<197:21:15, 12.93s/it, Loss=11.6334, Denoising=11.4663]Training:   0%|          | 70/55000 [15:30<191:59:05, 12.58s/it, Loss=11.6334, Denoising=11.4663]Training:   0%|          | 70/55000 [15:30<191:59:05, 12.58s/it, Loss=11.4613, Denoising=11.2937]Training:   0%|          | 71/55000 [15:43<195:00:14, 12.78s/it, Loss=11.4613, Denoising=11.2937]Training:   0%|          | 71/55000 [15:43<195:00:14, 12.78s/it, Loss=11.4901, Denoising=11.3245]Training:   0%|          | 72/55000 [15:57<199:40:14, 13.09s/it, Loss=11.4901, Denoising=11.3245]Training:   0%|          | 72/55000 [15:57<199:40:14, 13.09s/it, Loss=11.2621, Denoising=11.0885]Training:   0%|          | 73/55000 [16:11<206:39:16, 13.54s/it, Loss=11.2621, Denoising=11.0885]Training:   0%|          | 73/55000 [16:12<206:39:16, 13.54s/it, Loss=11.5135, Denoising=11.3365]Training:   0%|          | 74/55000 [16:23<198:17:23, 13.00s/it, Loss=11.5135, Denoising=11.3365]Training:   0%|          | 74/55000 [16:23<198:17:23, 13.00s/it, Loss=11.5419, Denoising=11.3750]Training:   0%|          | 75/55000 [16:37<201:57:19, 13.24s/it, Loss=11.5419, Denoising=11.3750]Training:   0%|          | 75/55000 [16:37<201:57:19, 13.24s/it, Loss=11.3388, Denoising=11.1645]Training:   0%|          | 76/55000 [16:50<201:40:22, 13.22s/it, Loss=11.3388, Denoising=11.1645]Training:   0%|          | 76/55000 [16:50<201:40:22, 13.22s/it, Loss=11.4378, Denoising=11.2631]Training:   0%|          | 77/55000 [17:03<198:01:37, 12.98s/it, Loss=11.4378, Denoising=11.2631]Training:   0%|          | 77/55000 [17:03<198:01:37, 12.98s/it, Loss=11.4247, Denoising=11.2610]Training:   0%|          | 78/55000 [17:13<184:48:07, 12.11s/it, Loss=11.4247, Denoising=11.2610]Training:   0%|          | 78/55000 [17:13<184:48:07, 12.11s/it, Loss=11.4539, Denoising=11.2929]Training:   0%|          | 79/55000 [17:23<179:06:39, 11.74s/it, Loss=11.4539, Denoising=11.2929]Training:   0%|          | 79/55000 [17:24<179:06:39, 11.74s/it, Loss=11.3960, Denoising=11.2267]Training:   0%|          | 80/55000 [17:36<184:51:06, 12.12s/it, Loss=11.3960, Denoising=11.2267]Training:   0%|          | 80/55000 [17:37<184:51:06, 12.12s/it, Loss=11.4306, Denoising=11.2615]
--- PREVIEW (Step 80 | t=926) ---
Logit Range: [-0.28, 0.87]
Target: ### User:
Calculate the sum $1 + 3 + 5 + \cdots + 15 + 17$.

### Assistant:
The arithmetic sequence 1, 3, 5, $\dots$, 17, has common difference 2, so the $n^{\text{th}}$ term is $1 + 2(n - 1) = 2n - 1...
Predict: ### User:
Calculate the sum $1 + 3 + 5 + \cdots + 15 + 17$.

### Assistant:
The arithmetic sequence 1, 3, 5, $\dots$, 17, has common difference 2, so the $n^{\text{th}}$ term is $1 + 2(n - 1) = 2n - 1...
--------------------------------------

Training:   0%|          | 81/55000 [17:47<179:31:23, 11.77s/it, Loss=11.4306, Denoising=11.2615]Training:   0%|          | 81/55000 [17:48<179:31:23, 11.77s/it, Loss=11.4163, Denoising=11.2522]Training:   0%|          | 82/55000 [18:00<184:04:19, 12.07s/it, Loss=11.4163, Denoising=11.2522]Training:   0%|          | 82/55000 [18:00<184:04:19, 12.07s/it, Loss=11.5131, Denoising=11.3422]Training:   0%|          | 83/55000 [18:13<185:13:41, 12.14s/it, Loss=11.5131, Denoising=11.3422]Training:   0%|          | 83/55000 [18:13<185:13:41, 12.14s/it, Loss=11.4407, Denoising=11.2711]Training:   0%|          | 84/55000 [18:24<184:11:56, 12.08s/it, Loss=11.4407, Denoising=11.2711]Training:   0%|          | 84/55000 [18:25<184:11:56, 12.08s/it, Loss=11.4611, Denoising=11.2904]Training:   0%|          | 85/55000 [18:37<188:00:29, 12.33s/it, Loss=11.4611, Denoising=11.2904]Training:   0%|          | 85/55000 [18:38<188:00:29, 12.33s/it, Loss=11.3702, Denoising=11.1999]Training:   0%|          | 86/55000 [18:52<198:24:47, 13.01s/it, Loss=11.3702, Denoising=11.1999]Training:   0%|          | 86/55000 [18:52<198:24:47, 13.01s/it, Loss=11.2931, Denoising=11.1272]Training:   0%|          | 87/55000 [19:06<203:53:07, 13.37s/it, Loss=11.2931, Denoising=11.1272]Training:   0%|          | 87/55000 [19:06<203:53:07, 13.37s/it, Loss=11.3429, Denoising=11.1730]Training:   0%|          | 88/55000 [19:20<207:10:25, 13.58s/it, Loss=11.3429, Denoising=11.1730]Training:   0%|          | 88/55000 [19:20<207:10:25, 13.58s/it, Loss=11.3022, Denoising=11.1349]Training:   0%|          | 89/55000 [19:33<201:47:27, 13.23s/it, Loss=11.3022, Denoising=11.1349]Training:   0%|          | 89/55000 [19:33<201:47:27, 13.23s/it, Loss=11.2717, Denoising=11.0995]Training:   0%|          | 90/55000 [19:46<204:24:53, 13.40s/it, Loss=11.2717, Denoising=11.0995]Training:   0%|          | 90/55000 [19:47<204:24:53, 13.40s/it, Loss=11.3940, Denoising=11.2278]Training:   0%|          | 91/55000 [19:59<200:42:50, 13.16s/it, Loss=11.3940, Denoising=11.2278]Training:   0%|          | 91/55000 [19:59<200:42:50, 13.16s/it, Loss=11.3737, Denoising=11.1970]Training:   0%|          | 92/55000 [20:13<203:40:50, 13.35s/it, Loss=11.3737, Denoising=11.1970]Training:   0%|          | 92/55000 [20:13<203:40:50, 13.35s/it, Loss=11.2112, Denoising=11.0316]Training:   0%|          | 93/55000 [20:26<204:20:00, 13.40s/it, Loss=11.2112, Denoising=11.0316]Training:   0%|          | 93/55000 [20:27<204:20:00, 13.40s/it, Loss=11.4520, Denoising=11.2949]Training:   0%|          | 94/55000 [20:41<209:51:27, 13.76s/it, Loss=11.4520, Denoising=11.2949]Training:   0%|          | 94/55000 [20:41<209:51:27, 13.76s/it, Loss=11.2927, Denoising=11.1229]Training:   0%|          | 95/55000 [20:53<202:01:48, 13.25s/it, Loss=11.2927, Denoising=11.1229]Training:   0%|          | 95/55000 [20:53<202:01:48, 13.25s/it, Loss=11.4456, Denoising=11.2738]Training:   0%|          | 96/55000 [21:06<199:35:00, 13.09s/it, Loss=11.4456, Denoising=11.2738]Training:   0%|          | 96/55000 [21:06<199:35:00, 13.09s/it, Loss=11.5994, Denoising=11.4332]Training:   0%|          | 97/55000 [21:16<186:59:07, 12.26s/it, Loss=11.5994, Denoising=11.4332]Training:   0%|          | 97/55000 [21:16<186:59:07, 12.26s/it, Loss=11.4728, Denoising=11.3058]Training:   0%|          | 98/55000 [21:30<194:03:26, 12.72s/it, Loss=11.4728, Denoising=11.3058]Training:   0%|          | 98/55000 [21:30<194:03:26, 12.72s/it, Loss=11.3658, Denoising=11.1986]Training:   0%|          | 99/55000 [21:44<200:49:16, 13.17s/it, Loss=11.3658, Denoising=11.1986]Training:   0%|          | 99/55000 [21:44<200:49:16, 13.17s/it, Loss=11.3167, Denoising=11.1404]Training:   0%|          | 100/55000 [21:56<196:39:37, 12.90s/it, Loss=11.3167, Denoising=11.1404]Training:   0%|          | 100/55000 [21:56<196:39:37, 12.90s/it, Loss=11.2855, Denoising=11.1223]
--- PREVIEW (Step 100 | t=356) ---
Logit Range: [-0.38, 1.01]
Target: ### User:
Improve the following code to handle an input which is an empty list or a list containing only negative numbers. Additionally, update the code to handle the case when the input list contains...
Predict: ### User:
Improve the following code to handle an input which is an empty list or a list containing only negative numbers. Additionally, update the code to handle the case when the input list contains...
--------------------------------------

Training:   0%|          | 101/55000 [22:10<200:29:41, 13.15s/it, Loss=11.2855, Denoising=11.1223]Training:   0%|          | 101/55000 [22:10<200:29:41, 13.15s/it, Loss=11.2423, Denoising=11.0745]Training:   0%|          | 102/55000 [22:23<201:40:08, 13.22s/it, Loss=11.2423, Denoising=11.0745]Training:   0%|          | 102/55000 [22:24<201:40:08, 13.22s/it, Loss=11.3627, Denoising=11.2042]Training:   0%|          | 103/55000 [22:37<202:27:23, 13.28s/it, Loss=11.3627, Denoising=11.2042]Training:   0%|          | 103/55000 [22:37<202:27:23, 13.28s/it, Loss=11.5079, Denoising=11.3403]Training:   0%|          | 104/55000 [22:49<198:43:24, 13.03s/it, Loss=11.5079, Denoising=11.3403]Training:   0%|          | 104/55000 [22:49<198:43:24, 13.03s/it, Loss=11.2888, Denoising=11.1269]Training:   0%|          | 105/55000 [23:01<191:32:33, 12.56s/it, Loss=11.2888, Denoising=11.1269]Training:   0%|          | 105/55000 [23:01<191:32:33, 12.56s/it, Loss=11.2237, Denoising=11.0574]Training:   0%|          | 106/55000 [23:13<190:17:42, 12.48s/it, Loss=11.2237, Denoising=11.0574]Training:   0%|          | 106/55000 [23:13<190:17:42, 12.48s/it, Loss=11.2162, Denoising=11.0522]Training:   0%|          | 107/55000 [23:27<195:50:57, 12.84s/it, Loss=11.2162, Denoising=11.0522]Training:   0%|          | 107/55000 [23:27<195:50:57, 12.84s/it, Loss=11.1874, Denoising=11.0243]Training:   0%|          | 108/55000 [23:42<205:14:31, 13.46s/it, Loss=11.1874, Denoising=11.0243]Training:   0%|          | 108/55000 [23:42<205:14:31, 13.46s/it, Loss=11.2684, Denoising=11.1060]Training:   0%|          | 109/55000 [23:55<206:32:38, 13.55s/it, Loss=11.2684, Denoising=11.1060]Training:   0%|          | 109/55000 [23:56<206:32:38, 13.55s/it, Loss=11.2179, Denoising=11.0478]Training:   0%|          | 110/55000 [24:06<192:50:31, 12.65s/it, Loss=11.2179, Denoising=11.0478]Training:   0%|          | 110/55000 [24:06<192:50:31, 12.65s/it, Loss=11.3659, Denoising=11.2087]Training:   0%|          | 111/55000 [24:21<201:48:17, 13.24s/it, Loss=11.3659, Denoising=11.2087]Training:   0%|          | 111/55000 [24:21<201:48:17, 13.24s/it, Loss=11.2400, Denoising=11.0748]Training:   0%|          | 112/55000 [24:35<207:04:28, 13.58s/it, Loss=11.2400, Denoising=11.0748]Training:   0%|          | 112/55000 [24:35<207:04:28, 13.58s/it, Loss=11.1592, Denoising=10.9881]Training:   0%|          | 113/55000 [24:46<194:11:20, 12.74s/it, Loss=11.1592, Denoising=10.9881]Training:   0%|          | 113/55000 [24:46<194:11:20, 12.74s/it, Loss=11.4942, Denoising=11.3307]Training:   0%|          | 114/55000 [25:00<202:11:39, 13.26s/it, Loss=11.4942, Denoising=11.3307]Training:   0%|          | 114/55000 [25:00<202:11:39, 13.26s/it, Loss=11.3355, Denoising=11.1728]Training:   0%|          | 115/55000 [25:15<208:18:19, 13.66s/it, Loss=11.3355, Denoising=11.1728]Training:   0%|          | 115/55000 [25:15<208:18:19, 13.66s/it, Loss=11.1734, Denoising=11.0012]Training:   0%|          | 116/55000 [25:28<205:06:35, 13.45s/it, Loss=11.1734, Denoising=11.0012]Training:   0%|          | 116/55000 [25:28<205:06:35, 13.45s/it, Loss=11.1152, Denoising=10.9295]Training:   0%|          | 117/55000 [25:41<205:19:20, 13.47s/it, Loss=11.1152, Denoising=10.9295]Training:   0%|          | 117/55000 [25:41<205:19:20, 13.47s/it, Loss=11.3357, Denoising=11.1663]Training:   0%|          | 118/55000 [25:55<205:20:00, 13.47s/it, Loss=11.3357, Denoising=11.1663]Training:   0%|          | 118/55000 [25:55<205:20:00, 13.47s/it, Loss=11.2968, Denoising=11.1212]Training:   0%|          | 119/55000 [26:08<205:19:17, 13.47s/it, Loss=11.2968, Denoising=11.1212]Training:   0%|          | 119/55000 [26:08<205:19:17, 13.47s/it, Loss=11.2446, Denoising=11.0816]Training:   0%|          | 120/55000 [26:21<201:47:46, 13.24s/it, Loss=11.2446, Denoising=11.0816]Training:   0%|          | 120/55000 [26:21<201:47:46, 13.24s/it, Loss=11.1886, Denoising=11.0073]
--- PREVIEW (Step 120 | t=189) ---
Logit Range: [-0.48, 1.41]
Target: ### User:


CONTENTS

1) Introduction

2) A Short History

3) Basic Techniques

4) Abbreviations

5) Knitting â€“ Patterns

6) Crochet â€“ Patterns

7) Acknowledgements
Introduction

Why Protest Knits?

*...
Predict: ### User:


CONTents

1) Introduction

2) A Short History

3) Basic Techniques

4) Abbreviations

5) Knitting â€“ Patterns

6) Crochet â€“ Patterns

7) Acknowledgements
Introduction

Why Protest Knits?

*...
--------------------------------------

Training:   0%|          | 121/55000 [26:35<203:47:10, 13.37s/it, Loss=11.1886, Denoising=11.0073]Training:   0%|          | 121/55000 [26:35<203:47:10, 13.37s/it, Loss=11.2037, Denoising=11.0389]Training:   0%|          | 122/55000 [26:48<205:46:54, 13.50s/it, Loss=11.2037, Denoising=11.0389]Training:   0%|          | 122/55000 [26:49<205:46:54, 13.50s/it, Loss=11.1324, Denoising=10.9658]Training:   0%|          | 123/55000 [27:02<207:10:56, 13.59s/it, Loss=11.1324, Denoising=10.9658]Training:   0%|          | 123/55000 [27:02<207:10:56, 13.59s/it, Loss=11.0906, Denoising=10.9238]Training:   0%|          | 124/55000 [27:15<203:23:51, 13.34s/it, Loss=11.0906, Denoising=10.9238]Training:   0%|          | 124/55000 [27:15<203:23:51, 13.34s/it, Loss=11.2213, Denoising=11.0533]Training:   0%|          | 125/55000 [27:29<204:25:32, 13.41s/it, Loss=11.2213, Denoising=11.0533]Training:   0%|          | 125/55000 [27:29<204:25:32, 13.41s/it, Loss=11.2387, Denoising=11.0645]Training:   0%|          | 126/55000 [27:42<205:07:31, 13.46s/it, Loss=11.2387, Denoising=11.0645]Training:   0%|          | 126/55000 [27:42<205:07:31, 13.46s/it, Loss=11.0652, Denoising=10.8895]Training:   0%|          | 127/55000 [27:54<198:43:51, 13.04s/it, Loss=11.0652, Denoising=10.8895]Training:   0%|          | 127/55000 [27:54<198:43:51, 13.04s/it, Loss=11.0913, Denoising=10.9287]Training:   0%|          | 128/55000 [28:04<185:54:00, 12.20s/it, Loss=11.0913, Denoising=10.9287]Training:   0%|          | 128/55000 [28:05<185:54:00, 12.20s/it, Loss=11.1902, Denoising=11.0217]Training:   0%|          | 129/55000 [28:19<196:55:47, 12.92s/it, Loss=11.1902, Denoising=11.0217]Training:   0%|          | 129/55000 [28:19<196:55:47, 12.92s/it, Loss=11.1298, Denoising=10.9605]Training:   0%|          | 130/55000 [28:33<202:47:09, 13.30s/it, Loss=11.1298, Denoising=10.9605]Training:   0%|          | 130/55000 [28:33<202:47:09, 13.30s/it, Loss=11.1589, Denoising=10.9909]Training:   0%|          | 131/55000 [28:46<201:22:55, 13.21s/it, Loss=11.1589, Denoising=10.9909]Training:   0%|          | 131/55000 [28:46<201:22:55, 13.21s/it, Loss=11.2834, Denoising=11.1118]Training:   0%|          | 132/55000 [29:01<209:33:53, 13.75s/it, Loss=11.2834, Denoising=11.1118]Training:   0%|          | 132/55000 [29:01<209:33:53, 13.75s/it, Loss=11.2421, Denoising=11.0719]Training:   0%|          | 133/55000 [29:16<215:17:42, 14.13s/it, Loss=11.2421, Denoising=11.0719]Training:   0%|          | 133/55000 [29:16<215:17:42, 14.13s/it, Loss=11.1136, Denoising=10.9379]Training:   0%|          | 134/55000 [29:30<213:19:11, 14.00s/it, Loss=11.1136, Denoising=10.9379]Training:   0%|          | 134/55000 [29:30<213:19:11, 14.00s/it, Loss=11.0819, Denoising=10.9195]Training:   0%|          | 135/55000 [29:44<216:04:37, 14.18s/it, Loss=11.0819, Denoising=10.9195]Training:   0%|          | 135/55000 [29:45<216:04:37, 14.18s/it, Loss=11.1119, Denoising=10.9433]Training:   0%|          | 136/55000 [29:58<212:27:57, 13.94s/it, Loss=11.1119, Denoising=10.9433]Training:   0%|          | 136/55000 [29:58<212:27:57, 13.94s/it, Loss=11.1566, Denoising=10.9918]Training:   0%|          | 137/55000 [30:13<215:44:52, 14.16s/it, Loss=11.1566, Denoising=10.9918]Training:   0%|          | 137/55000 [30:13<215:44:52, 14.16s/it, Loss=11.2418, Denoising=11.0763]Training:   0%|          | 138/55000 [30:23<198:28:50, 13.02s/it, Loss=11.2418, Denoising=11.0763]Training:   0%|          | 138/55000 [30:23<198:28:50, 13.02s/it, Loss=11.2248, Denoising=11.0631]Training:   0%|          | 139/55000 [30:37<201:51:14, 13.25s/it, Loss=11.2248, Denoising=11.0631]Training:   0%|          | 139/55000 [30:37<201:51:14, 13.25s/it, Loss=11.2871, Denoising=11.1147]Training:   0%|          | 140/55000 [30:50<202:00:21, 13.26s/it, Loss=11.2871, Denoising=11.1147]Training:   0%|          | 140/55000 [30:50<202:00:21, 13.26s/it, Loss=11.1350, Denoising=10.9702]
--- PREVIEW (Step 140 | t=447) ---
Logit Range: [-0.64, 1.13]
Target: ### User:
John works a job that offers performance bonuses. He makes $80 a day and works for a certain number of hours. He has the option of working hard to earn the performance bonus of an extra $20 ...
Predict:   :
 John works a job that offers performance bonuses. He  80 a day and works for a certain number of hours. He has the option of working hard to earn the performance bonus of an extra $20 a day, but ...
--------------------------------------

Training:   0%|          | 141/55000 [31:04<206:51:24, 13.57s/it, Loss=11.1350, Denoising=10.9702]Training:   0%|          | 141/55000 [31:04<206:51:24, 13.57s/it, Loss=11.1051, Denoising=10.9427]Training:   0%|          | 142/55000 [31:17<200:57:10, 13.19s/it, Loss=11.1051, Denoising=10.9427]Training:   0%|          | 142/55000 [31:17<200:57:10, 13.19s/it, Loss=10.8793, Denoising=10.7110]Training:   0%|          | 143/55000 [31:31<205:44:48, 13.50s/it, Loss=10.8793, Denoising=10.7110]Training:   0%|          | 143/55000 [31:31<205:44:48, 13.50s/it, Loss=11.0444, Denoising=10.8840]Training:   0%|          | 144/55000 [31:45<207:05:20, 13.59s/it, Loss=11.0444, Denoising=10.8840]Training:   0%|          | 144/55000 [31:45<207:05:20, 13.59s/it, Loss=11.0459, Denoising=10.8782]Training:   0%|          | 145/55000 [31:59<209:53:04, 13.77s/it, Loss=11.0459, Denoising=10.8782]Training:   0%|          | 145/55000 [31:59<209:53:04, 13.77s/it, Loss=11.2655, Denoising=11.1009]Training:   0%|          | 146/55000 [32:12<206:42:10, 13.57s/it, Loss=11.2655, Denoising=11.1009]Training:   0%|          | 146/55000 [32:12<206:42:10, 13.57s/it, Loss=11.3200, Denoising=11.1406]Training:   0%|          | 147/55000 [32:24<201:24:48, 13.22s/it, Loss=11.3200, Denoising=11.1406]Training:   0%|          | 147/55000 [32:24<201:24:48, 13.22s/it, Loss=10.9771, Denoising=10.8106]Training:   0%|          | 148/55000 [32:37<199:10:43, 13.07s/it, Loss=10.9771, Denoising=10.8106]Training:   0%|          | 148/55000 [32:37<199:10:43, 13.07s/it, Loss=11.0182, Denoising=10.8498]Training:   0%|          | 149/55000 [32:51<205:35:32, 13.49s/it, Loss=11.0182, Denoising=10.8498]Training:   0%|          | 149/55000 [32:52<205:35:32, 13.49s/it, Loss=10.9469, Denoising=10.7754]Training:   0%|          | 150/55000 [33:05<205:09:27, 13.47s/it, Loss=10.9469, Denoising=10.7754]Training:   0%|          | 150/55000 [33:05<205:09:27, 13.47s/it, Loss=10.8695, Denoising=10.7000]Training:   0%|          | 151/55000 [33:17<201:13:08, 13.21s/it, Loss=10.8695, Denoising=10.7000]Training:   0%|          | 151/55000 [33:18<201:13:08, 13.21s/it, Loss=10.8730, Denoising=10.7082]Training:   0%|          | 152/55000 [33:30<198:28:24, 13.03s/it, Loss=10.8730, Denoising=10.7082]Training:   0%|          | 152/55000 [33:30<198:28:24, 13.03s/it, Loss=10.9872, Denoising=10.8169]Training:   0%|          | 153/55000 [33:43<198:58:18, 13.06s/it, Loss=10.9872, Denoising=10.8169]Training:   0%|          | 153/55000 [33:43<198:58:18, 13.06s/it, Loss=10.8511, Denoising=10.6848]Training:   0%|          | 154/55000 [33:55<191:23:30, 12.56s/it, Loss=10.8511, Denoising=10.6848]Training:   0%|          | 154/55000 [33:55<191:23:30, 12.56s/it, Loss=11.1948, Denoising=11.0226]Training:   0%|          | 155/55000 [34:07<192:40:03, 12.65s/it, Loss=11.1948, Denoising=11.0226]Training:   0%|          | 155/55000 [34:08<192:40:03, 12.65s/it, Loss=10.8614, Denoising=10.6901]Training:   0%|          | 156/55000 [34:21<195:39:32, 12.84s/it, Loss=10.8614, Denoising=10.6901]Training:   0%|          | 156/55000 [34:21<195:39:32, 12.84s/it, Loss=10.9876, Denoising=10.8142]Training:   0%|          | 157/55000 [34:35<200:00:27, 13.13s/it, Loss=10.9876, Denoising=10.8142]Training:   0%|          | 157/55000 [34:35<200:00:27, 13.13s/it, Loss=11.0060, Denoising=10.8369]Training:   0%|          | 158/55000 [34:48<200:36:31, 13.17s/it, Loss=11.0060, Denoising=10.8369]Training:   0%|          | 158/55000 [34:48<200:36:31, 13.17s/it, Loss=10.9627, Denoising=10.8018]Training:   0%|          | 159/55000 [35:02<207:09:40, 13.60s/it, Loss=10.9627, Denoising=10.8018]Training:   0%|          | 159/55000 [35:03<207:09:40, 13.60s/it, Loss=11.0578, Denoising=10.9008]Training:   0%|          | 160/55000 [35:15<203:24:31, 13.35s/it, Loss=11.0578, Denoising=10.9008]Training:   0%|          | 160/55000 [35:15<203:24:31, 13.35s/it, Loss=10.9587, Denoising=10.7921]
--- PREVIEW (Step 160 | t=360) ---
Logit Range: [-0.70, 1.27]
Target: ### User:
<p>I am very much lost here and could really use some help.</p>
<p>I'm working on an Honours project for next year that involves a physics simulation using Bullet and Vulkan for rendering. A...
Predict:   :
  I am very much lost here and could really use some help p, I  working on an Honours project for next, involves a physics simulation using Bullet and Vulkan for rendering. After a few months of w...
--------------------------------------

Training:   0%|          | 161/55000 [35:28<202:48:56, 13.31s/it, Loss=10.9587, Denoising=10.7921]Training:   0%|          | 161/55000 [35:29<202:48:56, 13.31s/it, Loss=11.1433, Denoising=10.9854]Training:   0%|          | 162/55000 [35:41<199:00:24, 13.06s/it, Loss=11.1433, Denoising=10.9854]Training:   0%|          | 162/55000 [35:41<199:00:24, 13.06s/it, Loss=11.0930, Denoising=10.9312]Training:   0%|          | 163/55000 [35:54<198:02:14, 13.00s/it, Loss=11.0930, Denoising=10.9312]Training:   0%|          | 163/55000 [35:54<198:02:14, 13.00s/it, Loss=11.1825, Denoising=11.0202]Training:   0%|          | 164/55000 [36:07<199:24:54, 13.09s/it, Loss=11.1825, Denoising=11.0202]Training:   0%|          | 164/55000 [36:07<199:24:54, 13.09s/it, Loss=10.7874, Denoising=10.6204]Training:   0%|          | 165/55000 [36:20<197:24:16, 12.96s/it, Loss=10.7874, Denoising=10.6204]Training:   0%|          | 165/55000 [36:20<197:24:16, 12.96s/it, Loss=11.0289, Denoising=10.8562]Training:   0%|          | 166/55000 [36:33<199:21:13, 13.09s/it, Loss=11.0289, Denoising=10.8562]Training:   0%|          | 166/55000 [36:33<199:21:13, 13.09s/it, Loss=11.0493, Denoising=10.8890]Training:   0%|          | 167/55000 [36:47<201:33:48, 13.23s/it, Loss=11.0493, Denoising=10.8890]Training:   0%|          | 167/55000 [36:47<201:33:48, 13.23s/it, Loss=11.1523, Denoising=10.9836]Training:   0%|          | 168/55000 [37:00<199:55:39, 13.13s/it, Loss=11.1523, Denoising=10.9836]Training:   0%|          | 168/55000 [37:00<199:55:39, 13.13s/it, Loss=10.8800, Denoising=10.7009]Training:   0%|          | 169/55000 [37:11<194:04:02, 12.74s/it, Loss=10.8800, Denoising=10.7009]Training:   0%|          | 169/55000 [37:12<194:04:02, 12.74s/it, Loss=10.7958, Denoising=10.6100]Training:   0%|          | 170/55000 [37:26<202:26:24, 13.29s/it, Loss=10.7958, Denoising=10.6100]Training:   0%|          | 170/55000 [37:26<202:26:24, 13.29s/it, Loss=10.9540, Denoising=10.7942]Training:   0%|          | 171/55000 [37:40<204:44:36, 13.44s/it, Loss=10.9540, Denoising=10.7942]Training:   0%|          | 171/55000 [37:40<204:44:36, 13.44s/it, Loss=11.0899, Denoising=10.9207]Training:   0%|          | 172/55000 [37:54<206:20:47, 13.55s/it, Loss=11.0899, Denoising=10.9207]Training:   0%|          | 172/55000 [37:54<206:20:47, 13.55s/it, Loss=10.9122, Denoising=10.7379]Training:   0%|          | 173/55000 [38:06<200:03:10, 13.14s/it, Loss=10.9122, Denoising=10.7379]Training:   0%|          | 173/55000 [38:06<200:03:10, 13.14s/it, Loss=10.9266, Denoising=10.7599]Training:   0%|          | 174/55000 [38:19<202:33:42, 13.30s/it, Loss=10.9266, Denoising=10.7599]Training:   0%|          | 174/55000 [38:20<202:33:42, 13.30s/it, Loss=10.6870, Denoising=10.5141]Training:   0%|          | 175/55000 [38:33<203:03:31, 13.33s/it, Loss=10.6870, Denoising=10.5141]Training:   0%|          | 175/55000 [38:33<203:03:31, 13.33s/it, Loss=11.2216, Denoising=11.0654]Training:   0%|          | 176/55000 [38:44<195:00:22, 12.81s/it, Loss=11.2216, Denoising=11.0654]Training:   0%|          | 176/55000 [38:45<195:00:22, 12.81s/it, Loss=11.0665, Denoising=10.8908]Training:   0%|          | 177/55000 [38:57<195:31:34, 12.84s/it, Loss=11.0665, Denoising=10.8908]Training:   0%|          | 177/55000 [38:58<195:31:34, 12.84s/it, Loss=11.0455, Denoising=10.8692]Training:   0%|          | 178/55000 [39:12<201:42:05, 13.25s/it, Loss=11.0455, Denoising=10.8692]Training:   0%|          | 178/55000 [39:12<201:42:05, 13.25s/it, Loss=11.0381, Denoising=10.8630]Training:   0%|          | 179/55000 [39:24<199:07:33, 13.08s/it, Loss=11.0381, Denoising=10.8630]Training:   0%|          | 179/55000 [39:24<199:07:33, 13.08s/it, Loss=10.8853, Denoising=10.7115]Training:   0%|          | 180/55000 [39:37<196:50:25, 12.93s/it, Loss=10.8853, Denoising=10.7115]Training:   0%|          | 180/55000 [39:37<196:50:25, 12.93s/it, Loss=11.0257, Denoising=10.8553]
--- PREVIEW (Step 180 | t=93) ---
Logit Range: [-0.81, 1.41]
Target: ### User:
Produce an article summary of the following news article: It has been 10 years since the Tuck Rule came to life.

You remember. Charles Woodson navigated through a Nor' easter blizzard, barr...
Predict:   :
Produce an article summary of the following news article:,  10  since the Tuck Rule came to life,, remember.  son navigated through a Nor' easter,izzard, barreled in on a blitz and blasted, former...
--------------------------------------

Training:   0%|          | 181/55000 [39:51<200:56:38, 13.20s/it, Loss=11.0257, Denoising=10.8553]Training:   0%|          | 181/55000 [39:51<200:56:38, 13.20s/it, Loss=10.9373, Denoising=10.7702]Training:   0%|          | 182/55000 [40:04<201:02:28, 13.20s/it, Loss=10.9373, Denoising=10.7702]Training:   0%|          | 182/55000 [40:04<201:02:28, 13.20s/it, Loss=10.9827, Denoising=10.8184]Training:   0%|          | 183/55000 [40:17<201:07:53, 13.21s/it, Loss=10.9827, Denoising=10.8184]Training:   0%|          | 183/55000 [40:17<201:07:53, 13.21s/it, Loss=10.8021, Denoising=10.6349]Training:   0%|          | 184/55000 [40:31<205:38:41, 13.51s/it, Loss=10.8021, Denoising=10.6349]Training:   0%|          | 184/55000 [40:31<205:38:41, 13.51s/it, Loss=10.7339, Denoising=10.5708]Training:   0%|          | 185/55000 [40:45<208:47:53, 13.71s/it, Loss=10.7339, Denoising=10.5708]Training:   0%|          | 185/55000 [40:46<208:47:53, 13.71s/it, Loss=11.1020, Denoising=10.9314]Training:   0%|          | 186/55000 [40:58<205:02:11, 13.47s/it, Loss=11.1020, Denoising=10.9314]Training:   0%|          | 186/55000 [40:59<205:02:11, 13.47s/it, Loss=10.7246, Denoising=10.5577]Training:   0%|          | 187/55000 [41:12<206:31:58, 13.56s/it, Loss=10.7246, Denoising=10.5577]Training:   0%|          | 187/55000 [41:12<206:31:58, 13.56s/it, Loss=10.7540, Denoising=10.5904]Training:   0%|          | 188/55000 [41:25<202:22:56, 13.29s/it, Loss=10.7540, Denoising=10.5904]Training:   0%|          | 188/55000 [41:25<202:22:56, 13.29s/it, Loss=10.8659, Denoising=10.7033]Training:   0%|          | 189/55000 [41:39<208:18:38, 13.68s/it, Loss=10.8659, Denoising=10.7033]Training:   0%|          | 189/55000 [41:40<208:18:38, 13.68s/it, Loss=10.7473, Denoising=10.5776]Training:   0%|          | 190/55000 [41:54<212:27:26, 13.95s/it, Loss=10.7473, Denoising=10.5776]Training:   0%|          | 190/55000 [41:54<212:27:26, 13.95s/it, Loss=10.7119, Denoising=10.5450]Training:   0%|          | 191/55000 [42:08<211:42:51, 13.91s/it, Loss=10.7119, Denoising=10.5450]Training:   0%|          | 191/55000 [42:08<211:42:51, 13.91s/it, Loss=10.9077, Denoising=10.7464]Training:   0%|          | 192/55000 [42:21<206:27:22, 13.56s/it, Loss=10.9077, Denoising=10.7464]Training:   0%|          | 192/55000 [42:21<206:27:22, 13.56s/it, Loss=10.9386, Denoising=10.7711]Training:   0%|          | 193/55000 [42:33<203:11:19, 13.35s/it, Loss=10.9386, Denoising=10.7711]Training:   0%|          | 193/55000 [42:34<203:11:19, 13.35s/it, Loss=10.8084, Denoising=10.6363]Training:   0%|          | 194/55000 [42:47<203:22:26, 13.36s/it, Loss=10.8084, Denoising=10.6363]Training:   0%|          | 194/55000 [42:47<203:22:26, 13.36s/it, Loss=10.8946, Denoising=10.7220]Training:   0%|          | 195/55000 [43:01<206:50:21, 13.59s/it, Loss=10.8946, Denoising=10.7220]Training:   0%|          | 195/55000 [43:01<206:50:21, 13.59s/it, Loss=10.9461, Denoising=10.7844]Training:   0%|          | 196/55000 [43:14<205:52:29, 13.52s/it, Loss=10.9461, Denoising=10.7844]Training:   0%|          | 196/55000 [43:14<205:52:29, 13.52s/it, Loss=10.8708, Denoising=10.7022]Training:   0%|          | 197/55000 [43:26<198:00:06, 13.01s/it, Loss=10.8708, Denoising=10.7022]Training:   0%|          | 197/55000 [43:26<198:00:06, 13.01s/it, Loss=10.8641, Denoising=10.7040]Training:   0%|          | 198/55000 [43:39<198:18:35, 13.03s/it, Loss=10.8641, Denoising=10.7040]Training:   0%|          | 198/55000 [43:39<198:18:35, 13.03s/it, Loss=10.8950, Denoising=10.7335]Training:   0%|          | 199/55000 [43:52<196:27:45, 12.91s/it, Loss=10.8950, Denoising=10.7335]Training:   0%|          | 199/55000 [43:52<196:27:45, 12.91s/it, Loss=10.8316, Denoising=10.6687]Training:   0%|          | 200/55000 [44:05<199:45:10, 13.12s/it, Loss=10.8316, Denoising=10.6687]Training:   0%|          | 200/55000 [44:06<199:45:10, 13.12s/it, Loss=10.7420, Denoising=10.5627]
--- PREVIEW (Step 200 | t=686) ---
Logit Range: [-0.89, 1.46]
Target: ### User:
the path out of print.
Half an inch from the south shore, a line is cast from nowhere, black dots, black dashes, almost north, almost parallel to the line of the Humber Bridge, red on green,...
Predict: , , the  out of,, a, the , a,,, , , ,,  to the  of the Humber,,,,  a  to the,.   is  off by the,ance,   and   in a  ,,  out of the ings,   in  space, A , ,  and,   in a short, and  end .      from the...
--------------------------------------

âš¡ Thunder PrefixLM: Diffusion layers and custom embeddings saved to ./thunder_prefixlm_llama/checkpoint-200

âš¡ Checkpoint saved to ./thunder_prefixlm_llama/checkpoint-200
Training:   0%|          | 201/55000 [44:21<209:23:10, 13.76s/it, Loss=10.7420, Denoising=10.5627]Training:   0%|          | 201/55000 [44:21<209:23:10, 13.76s/it, Loss=10.7647, Denoising=10.6034]Training:   0%|          | 202/55000 [44:33<201:49:07, 13.26s/it, Loss=10.7647, Denoising=10.6034]Training:   0%|          | 202/55000 [44:33<201:49:07, 13.26s/it, Loss=11.0177, Denoising=10.8434]Training:   0%|          | 203/55000 [44:48<209:43:52, 13.78s/it, Loss=11.0177, Denoising=10.8434]Training:   0%|          | 203/55000 [44:48<209:43:52, 13.78s/it, Loss=10.9064, Denoising=10.7312]Training:   0%|          | 204/55000 [45:01<207:56:55, 13.66s/it, Loss=10.9064, Denoising=10.7312]Training:   0%|          | 204/55000 [45:01<207:56:55, 13.66s/it, Loss=10.9637, Denoising=10.7877]Training:   0%|          | 205/55000 [45:13<200:35:32, 13.18s/it, Loss=10.9637, Denoising=10.7877]Training:   0%|          | 205/55000 [45:13<200:35:32, 13.18s/it, Loss=10.7342, Denoising=10.5583]Training:   0%|          | 206/55000 [45:27<203:22:58, 13.36s/it, Loss=10.7342, Denoising=10.5583]Training:   0%|          | 206/55000 [45:27<203:22:58, 13.36s/it, Loss=10.7387, Denoising=10.5773]Training:   0%|          | 207/55000 [45:40<201:19:49, 13.23s/it, Loss=10.7387, Denoising=10.5773]Training:   0%|          | 207/55000 [45:40<201:19:49, 13.23s/it, Loss=10.8764, Denoising=10.7206]Training:   0%|          | 208/55000 [45:55<209:23:36, 13.76s/it, Loss=10.8764, Denoising=10.7206]Training:   0%|          | 208/55000 [45:55<209:23:36, 13.76s/it, Loss=10.8617, Denoising=10.6933]Training:   0%|          | 209/55000 [46:09<209:33:40, 13.77s/it, Loss=10.8617, Denoising=10.6933]Training:   0%|          | 209/55000 [46:09<209:33:40, 13.77s/it, Loss=10.8547, Denoising=10.6759]Training:   0%|          | 210/55000 [46:23<211:29:17, 13.90s/it, Loss=10.8547, Denoising=10.6759]Training:   0%|          | 210/55000 [46:23<211:29:17, 13.90s/it, Loss=10.9074, Denoising=10.7409]Training:   0%|          | 211/55000 [46:37<212:48:22, 13.98s/it, Loss=10.9074, Denoising=10.7409]Training:   0%|          | 211/55000 [46:37<212:48:22, 13.98s/it, Loss=10.7792, Denoising=10.6050]Training:   0%|          | 212/55000 [46:51<211:54:08, 13.92s/it, Loss=10.7792, Denoising=10.6050]Training:   0%|          | 212/55000 [46:51<211:54:08, 13.92s/it, Loss=10.8472, Denoising=10.6796]Training:   0%|          | 213/55000 [47:01<195:19:57, 12.84s/it, Loss=10.8472, Denoising=10.6796]Training:   0%|          | 213/55000 [47:01<195:19:57, 12.84s/it, Loss=11.0980, Denoising=10.9300]Training:   0%|          | 214/55000 [47:15<201:30:51, 13.24s/it, Loss=11.0980, Denoising=10.9300]Training:   0%|          | 214/55000 [47:15<201:30:51, 13.24s/it, Loss=10.9411, Denoising=10.7682]Training:   0%|          | 215/55000 [47:30<207:39:00, 13.64s/it, Loss=10.9411, Denoising=10.7682]Training:   0%|          | 215/55000 [47:30<207:39:00, 13.64s/it, Loss=10.9106, Denoising=10.7437]Training:   0%|          | 216/55000 [47:44<211:58:17, 13.93s/it, Loss=10.9106, Denoising=10.7437]Training:   0%|          | 216/55000 [47:45<211:58:17, 13.93s/it, Loss=10.9323, Denoising=10.7682]Training:   0%|          | 217/55000 [47:57<207:09:41, 13.61s/it, Loss=10.9323, Denoising=10.7682]Training:   0%|          | 217/55000 [47:58<207:09:41, 13.61s/it, Loss=10.9339, Denoising=10.7650]Training:   0%|          | 218/55000 [48:11<207:17:27, 13.62s/it, Loss=10.9339, Denoising=10.7650]Training:   0%|          | 218/55000 [48:11<207:17:27, 13.62s/it, Loss=10.7200, Denoising=10.5461]Training:   0%|          | 219/55000 [48:22<196:36:39, 12.92s/it, Loss=10.7200, Denoising=10.5461]Training:   0%|          | 219/55000 [48:22<196:36:39, 12.92s/it, Loss=10.8231, Denoising=10.6412]Training:   0%|          | 220/55000 [48:34<191:04:11, 12.56s/it, Loss=10.8231, Denoising=10.6412]Training:   0%|          | 220/55000 [48:34<191:04:11, 12.56s/it, Loss=10.9491, Denoising=10.7810]
--- PREVIEW (Step 220 | t=780) ---
Logit Range: [-0.91, 1.67]
Target: ### User:
# language: Python
#!/usr/bin/env python

"""
Dan Klein, Itay Marom
"""
from __future__ import print_function

import collections
import subprocess
import inspect
import cmd
import json
impo...
Predict: ,  :
  language: 
     
  Dan, ay Marom
  from  future__ import print 
  
  
  
  
  
  
  random
  
  
  
  
 , ios
    Lock
   import, partial
  
  atexit
  
if     :
   " ex  must be  as a     (1  ...
--------------------------------------

Training:   0%|          | 221/55000 [48:49<200:28:07, 13.17s/it, Loss=10.9491, Denoising=10.7810]Training:   0%|          | 221/55000 [48:49<200:28:07, 13.17s/it, Loss=10.9388, Denoising=10.7746]Training:   0%|          | 222/55000 [49:03<206:57:10, 13.60s/it, Loss=10.9388, Denoising=10.7746]Training:   0%|          | 222/55000 [49:03<206:57:10, 13.60s/it, Loss=10.9910, Denoising=10.8171]Training:   0%|          | 223/55000 [49:13<188:52:58, 12.41s/it, Loss=10.9910, Denoising=10.8171]Training:   0%|          | 223/55000 [49:13<188:52:58, 12.41s/it, Loss=10.5468, Denoising=10.3831]Training:   0%|          | 224/55000 [49:25<185:54:55, 12.22s/it, Loss=10.5468, Denoising=10.3831]Training:   0%|          | 224/55000 [49:25<185:54:55, 12.22s/it, Loss=10.8260, Denoising=10.6492]Training:   0%|          | 225/55000 [49:38<190:15:42, 12.50s/it, Loss=10.8260, Denoising=10.6492]Training:   0%|          | 225/55000 [49:38<190:15:42, 12.50s/it, Loss=10.7734, Denoising=10.5894]Training:   0%|          | 226/55000 [49:50<188:39:04, 12.40s/it, Loss=10.7734, Denoising=10.5894]Training:   0%|          | 226/55000 [49:50<188:39:04, 12.40s/it, Loss=10.6370, Denoising=10.4721]Training:   0%|          | 227/55000 [50:03<190:25:31, 12.52s/it, Loss=10.6370, Denoising=10.4721]Training:   0%|          | 227/55000 [50:03<190:25:31, 12.52s/it, Loss=10.7938, Denoising=10.6161]Training:   0%|          | 228/55000 [50:15<190:20:14, 12.51s/it, Loss=10.7938, Denoising=10.6161]Training:   0%|          | 228/55000 [50:15<190:20:14, 12.51s/it, Loss=10.6504, Denoising=10.4830]Training:   0%|          | 229/55000 [50:29<194:39:23, 12.79s/it, Loss=10.6504, Denoising=10.4830]Training:   0%|          | 229/55000 [50:29<194:39:23, 12.79s/it, Loss=10.7786, Denoising=10.6115]Training:   0%|          | 230/55000 [50:42<196:49:49, 12.94s/it, Loss=10.7786, Denoising=10.6115]Training:   0%|          | 230/55000 [50:42<196:49:49, 12.94s/it, Loss=10.7924, Denoising=10.6162]Training:   0%|          | 231/55000 [50:53<190:10:07, 12.50s/it, Loss=10.7924, Denoising=10.6162]Training:   0%|          | 231/55000 [50:54<190:10:07, 12.50s/it, Loss=11.0948, Denoising=10.9299]Training:   0%|          | 232/55000 [51:07<195:04:31, 12.82s/it, Loss=11.0948, Denoising=10.9299]Training:   0%|          | 232/55000 [51:07<195:04:31, 12.82s/it, Loss=10.8929, Denoising=10.7293]Training:   0%|          | 233/55000 [51:19<190:58:18, 12.55s/it, Loss=10.8929, Denoising=10.7293]Training:   0%|          | 233/55000 [51:19<190:58:18, 12.55s/it, Loss=10.5213, Denoising=10.3483]Training:   0%|          | 234/55000 [51:31<190:34:53, 12.53s/it, Loss=10.5213, Denoising=10.3483]Training:   0%|          | 234/55000 [51:32<190:34:53, 12.53s/it, Loss=10.7629, Denoising=10.5838]Training:   0%|          | 235/55000 [51:45<195:06:19, 12.83s/it, Loss=10.7629, Denoising=10.5838]Training:   0%|          | 235/55000 [51:45<195:06:19, 12.83s/it, Loss=10.7999, Denoising=10.6381]Training:   0%|          | 236/55000 [51:58<195:46:17, 12.87s/it, Loss=10.7999, Denoising=10.6381]Training:   0%|          | 236/55000 [51:58<195:46:17, 12.87s/it, Loss=10.9493, Denoising=10.7792]Training:   0%|          | 237/55000 [52:12<203:37:28, 13.39s/it, Loss=10.9493, Denoising=10.7792]Training:   0%|          | 237/55000 [52:13<203:37:28, 13.39s/it, Loss=10.6367, Denoising=10.4662]Training:   0%|          | 238/55000 [52:25<198:48:19, 13.07s/it, Loss=10.6367, Denoising=10.4662]Training:   0%|          | 238/55000 [52:25<198:48:19, 13.07s/it, Loss=10.7232, Denoising=10.5595]Training:   0%|          | 239/55000 [52:36<191:56:29, 12.62s/it, Loss=10.7232, Denoising=10.5595]Training:   0%|          | 239/55000 [52:37<191:56:29, 12.62s/it, Loss=10.9479, Denoising=10.7832]Training:   0%|          | 240/55000 [52:51<200:54:09, 13.21s/it, Loss=10.9479, Denoising=10.7832]Training:   0%|          | 240/55000 [52:51<200:54:09, 13.21s/it, Loss=10.8109, Denoising=10.6540]
--- PREVIEW (Step 240 | t=691) ---
Logit Range: [-1.00, 1.74]
Target: ### Assistant:
You are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. While performing the task think step-by-step and justify your steps.
...
Predict:    Assistant:
, an .  will    a task.  goal is to complete the task as  as  can.   the task  step by step and  your steps.  :
A   is a paid  partner in a partner.     to  with their customers on a  by...
--------------------------------------

Training:   0%|          | 241/55000 [53:02<189:21:53, 12.45s/it, Loss=10.8109, Denoising=10.6540]Training:   0%|          | 241/55000 [53:02<189:21:53, 12.45s/it, Loss=10.5538, Denoising=10.3878]Training:   0%|          | 242/55000 [53:16<196:52:15, 12.94s/it, Loss=10.5538, Denoising=10.3878]Training:   0%|          | 242/55000 [53:16<196:52:15, 12.94s/it, Loss=10.7749, Denoising=10.6067]Training:   0%|          | 243/55000 [53:29<197:47:21, 13.00s/it, Loss=10.7749, Denoising=10.6067]Training:   0%|          | 243/55000 [53:29<197:47:21, 13.00s/it, Loss=11.0335, Denoising=10.8672]Training:   0%|          | 244/55000 [53:39<186:10:14, 12.24s/it, Loss=11.0335, Denoising=10.8672]Training:   0%|          | 244/55000 [53:40<186:10:14, 12.24s/it, Loss=10.8838, Denoising=10.7250]Training:   0%|          | 245/55000 [53:52<188:48:26, 12.41s/it, Loss=10.8838, Denoising=10.7250]Training:   0%|          | 245/55000 [53:52<188:48:26, 12.41s/it, Loss=11.0240, Denoising=10.8518]Training:   0%|          | 246/55000 [54:06<195:04:56, 12.83s/it, Loss=11.0240, Denoising=10.8518]Training:   0%|          | 246/55000 [54:06<195:04:56, 12.83s/it, Loss=11.0537, Denoising=10.8931]Training:   0%|          | 247/55000 [54:19<196:12:36, 12.90s/it, Loss=11.0537, Denoising=10.8931]Training:   0%|          | 247/55000 [54:19<196:12:36, 12.90s/it, Loss=10.7835, Denoising=10.6094]Training:   0%|          | 248/55000 [54:33<199:25:46, 13.11s/it, Loss=10.7835, Denoising=10.6094]Training:   0%|          | 248/55000 [54:33<199:25:46, 13.11s/it, Loss=10.8091, Denoising=10.6379]Training:   0%|          | 249/55000 [54:46<202:30:48, 13.32s/it, Loss=10.8091, Denoising=10.6379]Training:   0%|          | 249/55000 [54:47<202:30:48, 13.32s/it, Loss=10.4900, Denoising=10.3187]
[WARNING] NaN loss detected! Skipping batch.
Training:   0%|          | 250/55000 [54:58<193:30:36, 12.72s/it, Loss=10.4900, Denoising=10.3187]Training:   0%|          | 250/55000 [54:58<193:30:36, 12.72s/it, Loss=11.0510, Denoising=10.8966]Training:   0%|          | 251/55000 [55:09<188:19:33, 12.38s/it, Loss=11.0510, Denoising=10.8966]Training:   0%|          | 251/55000 [55:10<188:19:33, 12.38s/it, Loss=10.9758, Denoising=10.8067]Training:   0%|          | 252/55000 [55:22<191:04:21, 12.56s/it, Loss=10.9758, Denoising=10.8067]Training:   0%|          | 252/55000 [55:22<191:04:21, 12.56s/it, Loss=10.6355, Denoising=10.4695]Training:   0%|          | 253/55000 [55:36<194:17:49, 12.78s/it, Loss=10.6355, Denoising=10.4695]Training:   0%|          | 253/55000 [55:36<194:17:49, 12.78s/it, Loss=10.5905, Denoising=10.4156]
[WARNING] NaN loss detected! Skipping batch.
Training:   0%|          | 254/55000 [55:47<189:46:37, 12.48s/it, Loss=10.5905, Denoising=10.4156]Training:   0%|          | 254/55000 [55:48<189:46:37, 12.48s/it, Loss=10.7002, Denoising=10.5191]Training:   0%|          | 255/55000 [56:00<189:25:35, 12.46s/it, Loss=10.7002, Denoising=10.5191]Training:   0%|          | 255/55000 [56:00<189:25:35, 12.46s/it, Loss=10.5816, Denoising=10.4205]Training:   0%|          | 256/55000 [56:13<193:02:17, 12.69s/it, Loss=10.5816, Denoising=10.4205]Training:   0%|          | 256/55000 [56:13<193:02:17, 12.69s/it, Loss=10.8907, Denoising=10.7239]Training:   0%|          | 257/55000 [56:26<196:30:55, 12.92s/it, Loss=10.8907, Denoising=10.7239]Training:   0%|          | 257/55000 [56:27<196:30:55, 12.92s/it, Loss=10.8159, Denoising=10.6440]Training:   0%|          | 258/55000 [56:40<200:27:26, 13.18s/it, Loss=10.8159, Denoising=10.6440]Training:   0%|          | 258/55000 [56:40<200:27:26, 13.18s/it, Loss=10.7058, Denoising=10.5347]Training:   0%|          | 259/55000 [56:53<199:21:50, 13.11s/it, Loss=10.7058, Denoising=10.5347]Training:   0%|          | 259/55000 [56:53<199:21:50, 13.11s/it, Loss=10.7022, Denoising=10.5435]Training:   0%|          | 260/55000 [57:08<206:06:19, 13.55s/it, Loss=10.7022, Denoising=10.5435]Training:   0%|          | 260/55000 [57:08<206:06:19, 13.55s/it, Loss=10.8730, Denoising=10.7182]
--- PREVIEW (Step 260 | t=43) ---
Logit Range: [-0.91, 1.62]
Target: ### User:
<p>I am trying to call through a REST request in SOAPUI a WCF service running in localhost from Visual Studio.
My problem is that the request is coming with its properties to null.
Here is t...
Predict: ### User:
<p I am trying to call through a REST request in SOAPUI a WCF service running in localhost from Visual Studio,My problem is that the request is coming with its properties to null,Here is the...
--------------------------------------

Training:   0%|          | 261/55000 [57:21<203:29:40, 13.38s/it, Loss=10.8730, Denoising=10.7182]Training:   0%|          | 261/55000 [57:21<203:29:40, 13.38s/it, Loss=10.7829, Denoising=10.6186]Training:   0%|          | 262/55000 [57:32<193:19:32, 12.71s/it, Loss=10.7829, Denoising=10.6186]Training:   0%|          | 262/55000 [57:32<193:19:32, 12.71s/it, Loss=10.6285, Denoising=10.4666]Training:   0%|          | 263/55000 [57:45<194:39:16, 12.80s/it, Loss=10.6285, Denoising=10.4666]Training:   0%|          | 263/55000 [57:45<194:39:16, 12.80s/it, Loss=10.7340, Denoising=10.5686]Training:   0%|          | 264/55000 [58:00<202:48:29, 13.34s/it, Loss=10.7340, Denoising=10.5686]Training:   0%|          | 264/55000 [58:00<202:48:29, 13.34s/it, Loss=10.8940, Denoising=10.7310]Training:   0%|          | 265/55000 [58:14<206:42:05, 13.60s/it, Loss=10.8940, Denoising=10.7310]Training:   0%|          | 265/55000 [58:14<206:42:05, 13.60s/it, Loss=10.7661, Denoising=10.5941]Training:   0%|          | 266/55000 [58:26<198:44:20, 13.07s/it, Loss=10.7661, Denoising=10.5941]Training:   0%|          | 266/55000 [58:26<198:44:20, 13.07s/it, Loss=11.1033, Denoising=10.9286]Training:   0%|          | 267/55000 [58:39<200:37:25, 13.20s/it, Loss=11.1033, Denoising=10.9286]Training:   0%|          | 267/55000 [58:39<200:37:25, 13.20s/it, Loss=10.5771, Denoising=10.4024]Training:   0%|          | 268/55000 [58:52<198:01:52, 13.03s/it, Loss=10.5771, Denoising=10.4024]Training:   0%|          | 268/55000 [58:52<198:01:52, 13.03s/it, Loss=11.0007, Denoising=10.8358]Training:   0%|          | 269/55000 [59:05<199:21:57, 13.11s/it, Loss=11.0007, Denoising=10.8358]Training:   0%|          | 269/55000 [59:05<199:21:57, 13.11s/it, Loss=10.8775, Denoising=10.7131]Training:   0%|          | 270/55000 [59:17<195:36:35, 12.87s/it, Loss=10.8775, Denoising=10.7131]Training:   0%|          | 270/55000 [59:17<195:36:35, 12.87s/it, Loss=10.6071, Denoising=10.4294]Training:   0%|          | 271/55000 [59:28<185:45:03, 12.22s/it, Loss=10.6071, Denoising=10.4294]Training:   0%|          | 271/55000 [59:28<185:45:03, 12.22s/it, Loss=10.7328, Denoising=10.5556]Training:   0%|          | 272/55000 [59:40<183:54:33, 12.10s/it, Loss=10.7328, Denoising=10.5556]Training:   0%|          | 272/55000 [59:40<183:54:33, 12.10s/it, Loss=10.4578, Denoising=10.2957]Training:   0%|          | 273/55000 [59:51<181:48:59, 11.96s/it, Loss=10.4578, Denoising=10.2957]Training:   0%|          | 273/55000 [59:52<181:48:59, 11.96s/it, Loss=10.6711, Denoising=10.5065]Training:   0%|          | 274/55000 [1:00:05<188:23:31, 12.39s/it, Loss=10.6711, Denoising=10.5065]Training:   0%|          | 274/55000 [1:00:05<188:23:31, 12.39s/it, Loss=10.6615, Denoising=10.4839]Training:   0%|          | 275/55000 [1:00:19<195:37:35, 12.87s/it, Loss=10.6615, Denoising=10.4839]Training:   0%|          | 275/55000 [1:00:19<195:37:35, 12.87s/it, Loss=10.6619, Denoising=10.5012]Training:   1%|          | 276/55000 [1:00:33<201:30:11, 13.26s/it, Loss=10.6619, Denoising=10.5012]Training:   1%|          | 276/55000 [1:00:33<201:30:11, 13.26s/it, Loss=10.7059, Denoising=10.5259]Training:   1%|          | 277/55000 [1:00:46<198:30:15, 13.06s/it, Loss=10.7059, Denoising=10.5259]Training:   1%|          | 277/55000 [1:00:46<198:30:15, 13.06s/it, Loss=10.9995, Denoising=10.8234]Training:   1%|          | 278/55000 [1:01:00<203:37:57, 13.40s/it, Loss=10.9995, Denoising=10.8234]Training:   1%|          | 278/55000 [1:01:00<203:37:57, 13.40s/it, Loss=10.6530, Denoising=10.4827]Training:   1%|          | 279/55000 [1:01:14<205:23:15, 13.51s/it, Loss=10.6530, Denoising=10.4827]Training:   1%|          | 279/55000 [1:01:14<205:23:15, 13.51s/it, Loss=11.0110, Denoising=10.8382]Training:   1%|          | 280/55000 [1:01:25<194:51:56, 12.82s/it, Loss=11.0110, Denoising=10.8382]Training:   1%|          | 280/55000 [1:01:25<194:51:56, 12.82s/it, Loss=10.8029, Denoising=10.6298]
--- PREVIEW (Step 280 | t=372) ---
Logit Range: [-0.93, 1.80]
Target: ### User:
Produce an article summary of the following news article: Sleater-Kinney: No Cities to Love A return to form for the reunited riot grrrl pioneers, filled to capacity with their signature cru...
Predict: ,### user:
Produce a article summary of the following news article: Sleater-Kinney: No Cities to Love A return to form for the reunited riot grrrl pioneers, filled to capacity with their signature cru...
--------------------------------------

Training:   1%|          | 281/55000 [1:01:40<203:51:26, 13.41s/it, Loss=10.8029, Denoising=10.6298]Training:   1%|          | 281/55000 [1:01:40<203:51:26, 13.41s/it, Loss=10.6361, Denoising=10.4705]Training:   1%|          | 282/55000 [1:01:55<212:53:32, 14.01s/it, Loss=10.6361, Denoising=10.4705]Training:   1%|          | 282/55000 [1:01:55<212:53:32, 14.01s/it, Loss=10.8966, Denoising=10.7105]Training:   1%|          | 283/55000 [1:02:09<211:53:33, 13.94s/it, Loss=10.8966, Denoising=10.7105]Training:   1%|          | 283/55000 [1:02:09<211:53:33, 13.94s/it, Loss=10.5608, Denoising=10.3831]Training:   1%|          | 284/55000 [1:02:23<212:37:05, 13.99s/it, Loss=10.5608, Denoising=10.3831]Training:   1%|          | 284/55000 [1:02:23<212:37:05, 13.99s/it, Loss=10.7145, Denoising=10.5418]Training:   1%|          | 285/55000 [1:02:36<207:34:36, 13.66s/it, Loss=10.7145, Denoising=10.5418]Training:   1%|          | 285/55000 [1:02:36<207:34:36, 13.66s/it, Loss=10.7037, Denoising=10.5406]Training:   1%|          | 286/55000 [1:02:47<197:14:54, 12.98s/it, Loss=10.7037, Denoising=10.5406]Training:   1%|          | 286/55000 [1:02:47<197:14:54, 12.98s/it, Loss=10.7485, Denoising=10.5900]Training:   1%|          | 287/55000 [1:03:00<198:00:44, 13.03s/it, Loss=10.7485, Denoising=10.5900]Training:   1%|          | 287/55000 [1:03:00<198:00:44, 13.03s/it, Loss=10.7641, Denoising=10.5972]Training:   1%|          | 288/55000 [1:03:12<194:18:19, 12.79s/it, Loss=10.7641, Denoising=10.5972]Training:   1%|          | 288/55000 [1:03:13<194:18:19, 12.79s/it, Loss=10.7693, Denoising=10.6142]Training:   1%|          | 289/55000 [1:03:24<190:08:47, 12.51s/it, Loss=10.7693, Denoising=10.6142]Training:   1%|          | 289/55000 [1:03:24<190:08:47, 12.51s/it, Loss=10.6135, Denoising=10.4459]Training:   1%|          | 290/55000 [1:03:36<187:28:38, 12.34s/it, Loss=10.6135, Denoising=10.4459]Training:   1%|          | 290/55000 [1:03:36<187:28:38, 12.34s/it, Loss=10.7973, Denoising=10.6266]Training:   1%|          | 291/55000 [1:03:49<191:08:26, 12.58s/it, Loss=10.7973, Denoising=10.6266]Training:   1%|          | 291/55000 [1:03:50<191:08:26, 12.58s/it, Loss=10.6447, Denoising=10.4780]Training:   1%|          | 292/55000 [1:04:01<186:35:04, 12.28s/it, Loss=10.6447, Denoising=10.4780]Training:   1%|          | 292/55000 [1:04:01<186:35:04, 12.28s/it, Loss=10.6072, Denoising=10.4412]Training:   1%|          | 293/55000 [1:04:14<189:54:28, 12.50s/it, Loss=10.6072, Denoising=10.4412]Training:   1%|          | 293/55000 [1:04:14<189:54:28, 12.50s/it, Loss=10.7882, Denoising=10.6203]Training:   1%|          | 294/55000 [1:04:27<192:55:03, 12.70s/it, Loss=10.7882, Denoising=10.6203]Training:   1%|          | 294/55000 [1:04:27<192:55:03, 12.70s/it, Loss=10.7448, Denoising=10.5814]Training:   1%|          | 295/55000 [1:04:38<182:25:53, 12.01s/it, Loss=10.7448, Denoising=10.5814]Training:   1%|          | 295/55000 [1:04:38<182:25:53, 12.01s/it, Loss=10.3948, Denoising=10.2312]Training:   1%|          | 296/55000 [1:04:50<185:33:12, 12.21s/it, Loss=10.3948, Denoising=10.2312]Training:   1%|          | 296/55000 [1:04:50<185:33:12, 12.21s/it, Loss=10.6196, Denoising=10.4543]Training:   1%|          | 297/55000 [1:05:04<192:09:08, 12.65s/it, Loss=10.6196, Denoising=10.4543]Training:   1%|          | 297/55000 [1:05:04<192:09:08, 12.65s/it, Loss=10.7026, Denoising=10.5311]Training:   1%|          | 298/55000 [1:05:15<182:41:27, 12.02s/it, Loss=10.7026, Denoising=10.5311]Training:   1%|          | 298/55000 [1:05:15<182:41:27, 12.02s/it, Loss=11.1575, Denoising=10.9830]Training:   1%|          | 299/55000 [1:05:29<194:23:19, 12.79s/it, Loss=11.1575, Denoising=10.9830]Training:   1%|          | 299/55000 [1:05:29<194:23:19, 12.79s/it, Loss=10.5637, Denoising=10.3906]Training:   1%|          | 300/55000 [1:05:43<200:45:37, 13.21s/it, Loss=10.5637, Denoising=10.3906]Training:   1%|          | 300/55000 [1:05:43<200:45:37, 13.21s/it, Loss=10.8423, Denoising=10.6705]
--- PREVIEW (Step 300 | t=394) ---
Logit Range: [-0.93, 1.71]
Target: ### User:
ä¸œé—¨å››å°‘
ã€Šä¸œé—¨å››å°‘ã€‹æ˜¯ç”±æœ±å»ºé’æ‰§å¯¼ï¼Œæœ±æ°¸æ˜†ç¼–å‰§ï¼Œå¼ é›åã€æˆ¿æ€ç‘œã€æ¨è´µåªšã€æœ±å¾·åˆšã€æ¢æ­£ç¾¤ã€æž—çŽŸè°Šã€é™ˆäº¦é£žä¸»æ¼”çš„å°æ¹¾å®¶åº­è½»å–œå‰§ã€‚è¯¥å‰§è®²è¿°äº†ä¸€é—´ç™¾å¹´ç†Ÿé£Ÿæ‘Šè€æ¿å¨˜æœ±é£˜é¦™ä¸Žå››åå­å¥³ä¹‹é—´ï¼Œäº²æƒ…ã€çˆ±æƒ…ä¸Žå‹æƒ…çš„æ•…äº‹ï¼Œ2012å¹´8æœˆ7æ—¥åœ¨å°è§†é¦–æ’­ ã€‚å‰§æƒ…ç®€ä»‹ ä¸œé—¨å››å°‘ï¼Œä¼ å®¶ä¹‹å®ï¼Œæˆ‘çš„å¹¸ç¦å®¶äººä¸€ä¸ªéƒ½ä¸èƒ½å°‘ã€‚ æœ±å®¶è€ç¥–å®—--æœ±åç­–ï¼Œåœ¨æ¸…æœæ˜¯ä¸€ä¸ªå¾ˆæœ‰åå¾ˆæœ‰åçš„ç§€æ‰ï¼Œå› ä¸ºä»–å‘çŽ°ï¼Œæœ±å®¶çš„ç¥–è°±å·²ç»é—å¤±äº†å¾ˆ...
Predict: ### User:
ä¸œé—¨å››å°‘
ã€Šä¸œé—¨å››å°‘ã€‹æ˜¯ç”±æœ±å»ºé’æ‰§å¯¼,æœ±æ°¸æ˜†ç¼–å‰§,å¼ é›åã€æˆ¿æ€ç‘œã€æ¨è´µåªšã€æœ±å¾·åˆšã€æ¢æ­£ç¾¤ã€æž—çŽŸè°Šã€é™ˆäº¦é£žä¸»æ¼”çš„å°æ¹¾å®¶åº­è½»å–œå‰§ã€‚è¯¥å‰§è®²è¿°äº†ä¸€é—´ç™¾å¹´ç†Ÿé£Ÿæ‘Šè€æ¿å¨˜æœ±é£˜é¦™ä¸Žå››åå­å¥³ä¹‹é—´,äº²æƒ…ã€çˆ±æƒ…ä¸Žå‹æƒ…çš„æ•…äº‹,2012å¹´8æœˆ7æ—¥åœ¨å°è§†é¦–æ’­ ã€‚å‰§æƒ…ç®€ä»‹ ä¸œé—¨å››å°‘,ä¼ å®¶ä¹‹å®,æˆ‘çš„å¹¸ç¦å®¶äººä¸€ä¸ªéƒ½ä¸èƒ½å°‘  æœ±å®¶è€ç¥–å®—--æœ±åç­–ï¼Œåœ¨æ¸…æœæ˜¯ä¸€ä¸ªå¾ˆæœ‰åå¾ˆæœ‰åçš„ç§€æ‰ï¼Œå› ä¸ºä»–å‘çŽ°,æœ±å®¶çš„ç¥–è°±å·²ç»é—å¤±äº†å¾ˆ...
--------------------------------------

Training:   1%|          | 301/55000 [1:05:54<190:51:11, 12.56s/it, Loss=10.8423, Denoising=10.6705]Training:   1%|          | 301/55000 [1:05:55<190:51:11, 12.56s/it, Loss=10.7596, Denoising=10.5904]Training:   1%|          | 302/55000 [1:06:07<193:35:50, 12.74s/it, Loss=10.7596, Denoising=10.5904]Training:   1%|          | 302/55000 [1:06:08<193:35:50, 12.74s/it, Loss=10.9798, Denoising=10.8120]Training:   1%|          | 303/55000 [1:06:19<187:07:05, 12.32s/it, Loss=10.9798, Denoising=10.8120]Training:   1%|          | 303/55000 [1:06:19<187:07:05, 12.32s/it, Loss=10.6038, Denoising=10.4410]Training:   1%|          | 304/55000 [1:06:32<192:40:07, 12.68s/it, Loss=10.6038, Denoising=10.4410]Training:   1%|          | 304/55000 [1:06:33<192:40:07, 12.68s/it, Loss=10.8825, Denoising=10.7212]Training:   1%|          | 305/55000 [1:06:47<203:12:21, 13.37s/it, Loss=10.8825, Denoising=10.7212]Training:   1%|          | 305/55000 [1:06:48<203:12:21, 13.37s/it, Loss=10.5795, Denoising=10.4113]Training:   1%|          | 306/55000 [1:07:01<205:04:16, 13.50s/it, Loss=10.5795, Denoising=10.4113]Training:   1%|          | 306/55000 [1:07:01<205:04:16, 13.50s/it, Loss=10.6457, Denoising=10.4862]Training:   1%|          | 307/55000 [1:07:14<200:08:13, 13.17s/it, Loss=10.6457, Denoising=10.4862]Training:   1%|          | 307/55000 [1:07:14<200:08:13, 13.17s/it, Loss=10.7567, Denoising=10.5690]Training:   1%|          | 308/55000 [1:07:27<203:19:48, 13.38s/it, Loss=10.7567, Denoising=10.5690]Training:   1%|          | 308/55000 [1:07:28<203:19:48, 13.38s/it, Loss=10.9853, Denoising=10.8109]Training:   1%|          | 309/55000 [1:07:41<203:28:23, 13.39s/it, Loss=10.9853, Denoising=10.8109]Training:   1%|          | 309/55000 [1:07:41<203:28:23, 13.39s/it, Loss=10.6590, Denoising=10.4949]Training:   1%|          | 310/55000 [1:07:54<201:22:33, 13.26s/it, Loss=10.6590, Denoising=10.4949]Training:   1%|          | 310/55000 [1:07:54<201:22:33, 13.26s/it, Loss=10.9820, Denoising=10.8160]Training:   1%|          | 311/55000 [1:08:09<209:14:28, 13.77s/it, Loss=10.9820, Denoising=10.8160]Training:   1%|          | 311/55000 [1:08:09<209:14:28, 13.77s/it, Loss=10.6112, Denoising=10.4513]Training:   1%|          | 312/55000 [1:08:24<214:46:58, 14.14s/it, Loss=10.6112, Denoising=10.4513]Training:   1%|          | 312/55000 [1:08:24<214:46:58, 14.14s/it, Loss=10.5549, Denoising=10.3792]Training:   1%|          | 313/55000 [1:08:37<211:22:55, 13.92s/it, Loss=10.5549, Denoising=10.3792]Training:   1%|          | 313/55000 [1:08:37<211:22:55, 13.92s/it, Loss=10.7539, Denoising=10.5844]Training:   1%|          | 314/55000 [1:08:49<204:10:56, 13.44s/it, Loss=10.7539, Denoising=10.5844]Training:   1%|          | 314/55000 [1:08:50<204:10:56, 13.44s/it, Loss=10.5310, Denoising=10.3558]Training:   1%|          | 315/55000 [1:09:04<207:33:41, 13.66s/it, Loss=10.5310, Denoising=10.3558]Training:   1%|          | 315/55000 [1:09:04<207:33:41, 13.66s/it, Loss=10.4472, Denoising=10.2818]Training:   1%|          | 316/55000 [1:09:17<205:41:50, 13.54s/it, Loss=10.4472, Denoising=10.2818]Training:   1%|          | 316/55000 [1:09:17<205:41:50, 13.54s/it, Loss=10.7564, Denoising=10.5825]Training:   1%|          | 317/55000 [1:09:31<208:39:20, 13.74s/it, Loss=10.7564, Denoising=10.5825]Training:   1%|          | 317/55000 [1:09:31<208:39:20, 13.74s/it, Loss=10.7365, Denoising=10.5647]Training:   1%|          | 318/55000 [1:09:44<206:35:53, 13.60s/it, Loss=10.7365, Denoising=10.5647]Training:   1%|          | 318/55000 [1:09:45<206:35:53, 13.60s/it, Loss=10.6341, Denoising=10.4702]Training:   1%|          | 319/55000 [1:09:59<212:55:07, 14.02s/it, Loss=10.6341, Denoising=10.4702]Training:   1%|          | 319/55000 [1:10:00<212:55:07, 14.02s/it, Loss=11.1392, Denoising=10.9619]Training:   1%|          | 320/55000 [1:10:12<208:22:33, 13.72s/it, Loss=11.1392, Denoising=10.9619]Training:   1%|          | 320/55000 [1:10:13<208:22:33, 13.72s/it, Loss=10.9540, Denoising=10.7970]
--- PREVIEW (Step 320 | t=516) ---
Logit Range: [-0.99, 1.81]
Target: ### User:
Implement a modified merge sort algorithm that uses a binary search to find the correct position for each element in the sorted subarray. Additionally, ensure that the algorithm has a time c...
Predict: ,### user:
Implement a modified merge sort algorithm that uses a binary search to find the correct position for each element in the sorted subarray. Additionally, ensure that the algorithm has a time ...
--------------------------------------

Training:   1%|          | 321/55000 [1:10:27<212:30:40, 13.99s/it, Loss=10.9540, Denoising=10.7970]Training:   1%|          | 321/55000 [1:10:27<212:30:40, 13.99s/it, Loss=10.8713, Denoising=10.6931]Training:   1%|          | 322/55000 [1:10:42<215:12:33, 14.17s/it, Loss=10.8713, Denoising=10.6931]Training:   1%|          | 322/55000 [1:10:42<215:12:33, 14.17s/it, Loss=10.4287, Denoising=10.2584]Training:   1%|          | 323/55000 [1:10:55<213:26:13, 14.05s/it, Loss=10.4287, Denoising=10.2584]Training:   1%|          | 323/55000 [1:10:56<213:26:13, 14.05s/it, Loss=10.7914, Denoising=10.6221]Training:   1%|          | 324/55000 [1:11:07<204:32:09, 13.47s/it, Loss=10.7914, Denoising=10.6221]Training:   1%|          | 324/55000 [1:11:08<204:32:09, 13.47s/it, Loss=10.6277, Denoising=10.4656]Training:   1%|          | 325/55000 [1:11:20<200:16:26, 13.19s/it, Loss=10.6277, Denoising=10.4656]Training:   1%|          | 325/55000 [1:11:20<200:16:26, 13.19s/it, Loss=10.6746, Denoising=10.5121]Training:   1%|          | 326/55000 [1:11:34<204:54:34, 13.49s/it, Loss=10.6746, Denoising=10.5121]Training:   1%|          | 326/55000 [1:11:34<204:54:34, 13.49s/it, Loss=10.5429, Denoising=10.3773]Training:   1%|          | 327/55000 [1:11:49<211:42:02, 13.94s/it, Loss=10.5429, Denoising=10.3773]Training:   1%|          | 327/55000 [1:11:49<211:42:02, 13.94s/it, Loss=10.7887, Denoising=10.6252]Training:   1%|          | 328/55000 [1:12:03<210:25:19, 13.86s/it, Loss=10.7887, Denoising=10.6252]Training:   1%|          | 328/55000 [1:12:03<210:25:19, 13.86s/it, Loss=10.6676, Denoising=10.4975]Training:   1%|          | 329/55000 [1:12:16<208:15:51, 13.71s/it, Loss=10.6676, Denoising=10.4975]Training:   1%|          | 329/55000 [1:12:16<208:15:51, 13.71s/it, Loss=10.6332, Denoising=10.4616]Training:   1%|          | 330/55000 [1:12:31<212:15:02, 13.98s/it, Loss=10.6332, Denoising=10.4616]Training:   1%|          | 330/55000 [1:12:31<212:15:02, 13.98s/it, Loss=10.5500, Denoising=10.3858]Training:   1%|          | 331/55000 [1:12:44<210:16:52, 13.85s/it, Loss=10.5500, Denoising=10.3858]Training:   1%|          | 331/55000 [1:12:45<210:16:52, 13.85s/it, Loss=11.0170, Denoising=10.8503]Training:   1%|          | 332/55000 [1:12:59<211:48:18, 13.95s/it, Loss=11.0170, Denoising=10.8503]Training:   1%|          | 332/55000 [1:12:59<211:48:18, 13.95s/it, Loss=10.7319, Denoising=10.5528]Training:   1%|          | 333/55000 [1:13:12<211:03:01, 13.90s/it, Loss=10.7319, Denoising=10.5528]Training:   1%|          | 333/55000 [1:13:13<211:03:01, 13.90s/it, Loss=10.4073, Denoising=10.2408]Training:   1%|          | 334/55000 [1:13:25<204:31:08, 13.47s/it, Loss=10.4073, Denoising=10.2408]Training:   1%|          | 334/55000 [1:13:25<204:31:08, 13.47s/it, Loss=10.6881, Denoising=10.5212]Training:   1%|          | 335/55000 [1:13:36<196:12:55, 12.92s/it, Loss=10.6881, Denoising=10.5212]Training:   1%|          | 335/55000 [1:13:37<196:12:55, 12.92s/it, Loss=11.0500, Denoising=10.8723]Training:   1%|          | 336/55000 [1:13:51<203:25:05, 13.40s/it, Loss=11.0500, Denoising=10.8723]Training:   1%|          | 336/55000 [1:13:51<203:25:05, 13.40s/it, Loss=10.7274, Denoising=10.5555]Training:   1%|          | 337/55000 [1:14:05<204:42:02, 13.48s/it, Loss=10.7274, Denoising=10.5555]Training:   1%|          | 337/55000 [1:14:05<204:42:02, 13.48s/it, Loss=10.6413, Denoising=10.4739]Training:   1%|          | 338/55000 [1:14:18<204:14:42, 13.45s/it, Loss=10.6413, Denoising=10.4739]Training:   1%|          | 338/55000 [1:14:18<204:14:42, 13.45s/it, Loss=10.7178, Denoising=10.5370]Training:   1%|          | 339/55000 [1:14:28<186:43:42, 12.30s/it, Loss=10.7178, Denoising=10.5370]Training:   1%|          | 339/55000 [1:14:28<186:43:42, 12.30s/it, Loss=10.7614, Denoising=10.5853]Training:   1%|          | 340/55000 [1:14:40<184:46:18, 12.17s/it, Loss=10.7614, Denoising=10.5853]Training:   1%|          | 340/55000 [1:14:40<184:46:18, 12.17s/it, Loss=10.4128, Denoising=10.2414]
--- PREVIEW (Step 340 | t=466) ---
Logit Range: [-1.01, 1.81]
Target: ### User:
A simple cycle is a chain where the first and last vertices are connected as well. If you travel along the simple cycle, each vertex of this cycle will be visited exactly once.

### Assistan...
Predict: ,### user:
A simple cycle is a chain where the first and last vertices are connected as well. if you travel along the simple cycle, each vertex of this cycle will be visited exactly once.### Assistant...
--------------------------------------

Training:   1%|          | 341/55000 [1:14:53<188:48:13, 12.44s/it, Loss=10.4128, Denoising=10.2414]Training:   1%|          | 341/55000 [1:14:53<188:48:13, 12.44s/it, Loss=10.5691, Denoising=10.4015]Training:   1%|          | 342/55000 [1:15:05<190:14:44, 12.53s/it, Loss=10.5691, Denoising=10.4015]Training:   1%|          | 342/55000 [1:15:05<190:14:44, 12.53s/it, Loss=10.4329, Denoising=10.2606]Training:   1%|          | 343/55000 [1:15:18<190:28:18, 12.55s/it, Loss=10.4329, Denoising=10.2606]Training:   1%|          | 343/55000 [1:15:18<190:28:18, 12.55s/it, Loss=10.4026, Denoising=10.2337]Training:   1%|          | 344/55000 [1:15:32<197:17:21, 12.99s/it, Loss=10.4026, Denoising=10.2337]Training:   1%|          | 344/55000 [1:15:32<197:17:21, 12.99s/it, Loss=10.4508, Denoising=10.2767]Training:   1%|          | 345/55000 [1:15:42<182:51:52, 12.04s/it, Loss=10.4508, Denoising=10.2767]Training:   1%|          | 345/55000 [1:15:42<182:51:52, 12.04s/it, Loss=10.7714, Denoising=10.6015]Training:   1%|          | 346/55000 [1:15:53<180:08:37, 11.87s/it, Loss=10.7714, Denoising=10.6015]Training:   1%|          | 346/55000 [1:15:53<180:08:37, 11.87s/it, Loss=10.6052, Denoising=10.4458]Training:   1%|          | 347/55000 [1:16:05<178:32:55, 11.76s/it, Loss=10.6052, Denoising=10.4458]Training:   1%|          | 347/55000 [1:16:05<178:32:55, 11.76s/it, Loss=10.4896, Denoising=10.3185]Training:   1%|          | 348/55000 [1:16:20<193:13:57, 12.73s/it, Loss=10.4896, Denoising=10.3185]Training:   1%|          | 348/55000 [1:16:20<193:13:57, 12.73s/it, Loss=10.5385, Denoising=10.3736]Training:   1%|          | 349/55000 [1:16:32<193:21:10, 12.74s/it, Loss=10.5385, Denoising=10.3736]Training:   1%|          | 349/55000 [1:16:33<193:21:10, 12.74s/it, Loss=10.7726, Denoising=10.5959]
[WARNING] NaN loss detected! Skipping batch.
Training:   1%|          | 350/55000 [1:16:45<191:32:53, 12.62s/it, Loss=10.7726, Denoising=10.5959]Training:   1%|          | 350/55000 [1:16:45<191:32:53, 12.62s/it, Loss=11.0037, Denoising=10.8345]Training:   1%|          | 351/55000 [1:16:58<192:01:43, 12.65s/it, Loss=11.0037, Denoising=10.8345]Training:   1%|          | 351/55000 [1:16:58<192:01:43, 12.65s/it, Loss=10.4500, Denoising=10.2764]Training:   1%|          | 352/55000 [1:17:12<199:37:50, 13.15s/it, Loss=10.4500, Denoising=10.2764]Training:   1%|          | 352/55000 [1:17:12<199:37:50, 13.15s/it, Loss=10.6941, Denoising=10.5216]Training:   1%|          | 353/55000 [1:17:26<205:57:00, 13.57s/it, Loss=10.6941, Denoising=10.5216]Training:   1%|          | 353/55000 [1:17:27<205:57:00, 13.57s/it, Loss=10.6845, Denoising=10.5196]Training:   1%|          | 354/55000 [1:17:38<197:23:25, 13.00s/it, Loss=10.6845, Denoising=10.5196]Training:   1%|          | 354/55000 [1:17:38<197:23:25, 13.00s/it, Loss=10.8080, Denoising=10.6350]Training:   1%|          | 355/55000 [1:17:50<193:35:51, 12.75s/it, Loss=10.8080, Denoising=10.6350]Training:   1%|          | 355/55000 [1:17:50<193:35:51, 12.75s/it, Loss=10.4977, Denoising=10.3308]Training:   1%|          | 356/55000 [1:18:03<193:08:18, 12.72s/it, Loss=10.4977, Denoising=10.3308]Training:   1%|          | 356/55000 [1:18:03<193:08:18, 12.72s/it, Loss=10.5236, Denoising=10.3563]Training:   1%|          | 357/55000 [1:18:15<189:03:41, 12.46s/it, Loss=10.5236, Denoising=10.3563]Training:   1%|          | 357/55000 [1:18:15<189:03:41, 12.46s/it, Loss=10.7751, Denoising=10.6053]Training:   1%|          | 358/55000 [1:18:27<188:03:51, 12.39s/it, Loss=10.7751, Denoising=10.6053]Training:   1%|          | 358/55000 [1:18:27<188:03:51, 12.39s/it, Loss=11.0869, Denoising=10.9211]Training:   1%|          | 359/55000 [1:18:42<198:05:16, 13.05s/it, Loss=11.0869, Denoising=10.9211]Training:   1%|          | 359/55000 [1:18:42<198:05:16, 13.05s/it, Loss=10.8274, Denoising=10.6580]Training:   1%|          | 360/55000 [1:18:55<197:42:45, 13.03s/it, Loss=10.8274, Denoising=10.6580]Training:   1%|          | 360/55000 [1:18:55<197:42:45, 13.03s/it, Loss=10.9929, Denoising=10.8358]
--- PREVIEW (Step 360 | t=997) ---
Logit Range: [-0.99, 1.79]
Target: ### Assistant:
You are a helpful assistant, who always provide explanation. Think like you are answering to a five year old.

### User:
Solve 414*p = 5353 + 4997 for p.

### Assistant:
Alright buddy, ...
Predict:  ### Assistant:
You are a helpful assistant, who always provide explanation. Think like you are answering to a five year old.### user:
,olve 414*p = 5353 +  7 for p.### Assistant:
Alright buddy, imagi...
--------------------------------------

Training:   1%|          | 361/55000 [1:19:09<202:41:54, 13.36s/it, Loss=10.9929, Denoising=10.8358]Training:   1%|          | 361/55000 [1:19:09<202:41:54, 13.36s/it, Loss=10.8074, Denoising=10.6492]Training:   1%|          | 362/55000 [1:19:21<199:31:27, 13.15s/it, Loss=10.8074, Denoising=10.6492]Training:   1%|          | 362/55000 [1:19:21<199:31:27, 13.15s/it, Loss=10.4848, Denoising=10.3166]Training:   1%|          | 363/55000 [1:19:36<207:25:44, 13.67s/it, Loss=10.4848, Denoising=10.3166]Training:   1%|          | 363/55000 [1:19:36<207:25:44, 13.67s/it, Loss=10.5445, Denoising=10.3822]Training:   1%|          | 364/55000 [1:19:49<205:37:36, 13.55s/it, Loss=10.5445, Denoising=10.3822]Training:   1%|          | 364/55000 [1:19:50<205:37:36, 13.55s/it, Loss=10.3386, Denoising=10.1715]Training:   1%|          | 365/55000 [1:20:01<197:20:45, 13.00s/it, Loss=10.3386, Denoising=10.1715]Training:   1%|          | 365/55000 [1:20:01<197:20:45, 13.00s/it, Loss=10.5507, Denoising=10.3796]Training:   1%|          | 366/55000 [1:20:15<202:43:42, 13.36s/it, Loss=10.5507, Denoising=10.3796]Training:   1%|          | 366/55000 [1:20:16<202:43:42, 13.36s/it, Loss=10.5620, Denoising=10.3992]Training:   1%|          | 367/55000 [1:20:28<198:24:27, 13.07s/it, Loss=10.5620, Denoising=10.3992]Training:   1%|          | 367/55000 [1:20:28<198:24:27, 13.07s/it, Loss=10.5507, Denoising=10.3868]Training:   1%|          | 368/55000 [1:20:33<164:48:56, 10.86s/it, Loss=10.5507, Denoising=10.3868]Training:   1%|          | 368/55000 [1:20:34<164:48:56, 10.86s/it, Loss=10.7772, Denoising=10.6219]Training:   1%|          | 369/55000 [1:20:44<163:06:51, 10.75s/it, Loss=10.7772, Denoising=10.6219]Training:   1%|          | 369/55000 [1:20:44<163:06:51, 10.75s/it, Loss=10.6452, Denoising=10.4840]Training:   1%|          | 370/55000 [1:20:58<178:19:21, 11.75s/it, Loss=10.6452, Denoising=10.4840]Training:   1%|          | 370/55000 [1:20:58<178:19:21, 11.75s/it, Loss=10.8342, Denoising=10.6598]Training:   1%|          | 371/55000 [1:21:10<180:13:13, 11.88s/it, Loss=10.8342, Denoising=10.6598]Training:   1%|          | 371/55000 [1:21:10<180:13:13, 11.88s/it, Loss=10.4933, Denoising=10.3245]Training:   1%|          | 372/55000 [1:21:25<193:47:15, 12.77s/it, Loss=10.4933, Denoising=10.3245]Training:   1%|          | 372/55000 [1:21:25<193:47:15, 12.77s/it, Loss=10.4904, Denoising=10.3231]Training:   1%|          | 373/55000 [1:21:39<197:54:29, 13.04s/it, Loss=10.4904, Denoising=10.3231]Training:   1%|          | 373/55000 [1:21:39<197:54:29, 13.04s/it, Loss=10.5613, Denoising=10.3961]Training:   1%|          | 374/55000 [1:21:51<193:56:00, 12.78s/it, Loss=10.5613, Denoising=10.3961]Training:   1%|          | 374/55000 [1:21:51<193:56:00, 12.78s/it, Loss=10.8727, Denoising=10.7153]
[WARNING] NaN loss detected! Skipping batch.
Training:   1%|          | 375/55000 [1:22:17<253:38:00, 16.72s/it, Loss=10.8727, Denoising=10.7153]Training:   1%|          | 375/55000 [1:22:17<253:38:00, 16.72s/it, Loss=10.5284, Denoising=10.3491]Training:   1%|          | 376/55000 [1:22:28<227:05:52, 14.97s/it, Loss=10.5284, Denoising=10.3491]Training:   1%|          | 376/55000 [1:22:28<227:05:52, 14.97s/it, Loss=10.7447, Denoising=10.5715]Training:   1%|          | 377/55000 [1:22:40<214:58:47, 14.17s/it, Loss=10.7447, Denoising=10.5715]Training:   1%|          | 377/55000 [1:22:40<214:58:47, 14.17s/it, Loss=10.6513, Denoising=10.4768]Training:   1%|          | 378/55000 [1:22:53<208:09:26, 13.72s/it, Loss=10.6513, Denoising=10.4768]Training:   1%|          | 378/55000 [1:22:53<208:09:26, 13.72s/it, Loss=10.7001, Denoising=10.5269]Training:   1%|          | 379/55000 [1:23:07<212:08:20, 13.98s/it, Loss=10.7001, Denoising=10.5269]Training:   1%|          | 379/55000 [1:23:07<212:08:20, 13.98s/it, Loss=10.6855, Denoising=10.5161]Training:   1%|          | 380/55000 [1:23:21<213:04:05, 14.04s/it, Loss=10.6855, Denoising=10.5161]Training:   1%|          | 380/55000 [1:23:22<213:04:05, 14.04s/it, Loss=10.6074, Denoising=10.4375]
--- PREVIEW (Step 380 | t=422) ---
Logit Range: [-0.96, 1.70]
Target: ### User:
<p>I know VB.Net does not allow implicit interface implementation like C#. And thus code like the following has no direct VB.Net correlation:</p>

<pre><code>public interface IBackgroundWork...
Predict: ,### User:
<p>I know VB.Net does not allow implicit interface implementation like C#. and thus code like the following has no direct VB.Net correlation:</p>

<pre><code> public interface I backgroundW...
--------------------------------------

Training:   1%|          | 381/55000 [1:23:33<202:16:47, 13.33s/it, Loss=10.6074, Denoising=10.4375]Training:   1%|          | 381/55000 [1:23:33<202:16:47, 13.33s/it, Loss=10.7030, Denoising=10.5277]Training:   1%|          | 382/55000 [1:23:47<204:21:18, 13.47s/it, Loss=10.7030, Denoising=10.5277]Training:   1%|          | 382/55000 [1:23:47<204:21:18, 13.47s/it, Loss=10.5694, Denoising=10.3979]Training:   1%|          | 383/55000 [1:24:00<203:32:43, 13.42s/it, Loss=10.5694, Denoising=10.3979]Training:   1%|          | 383/55000 [1:24:00<203:32:43, 13.42s/it, Loss=11.0021, Denoising=10.8433]Training:   1%|          | 384/55000 [1:24:14<206:29:47, 13.61s/it, Loss=11.0021, Denoising=10.8433]Training:   1%|          | 384/55000 [1:24:14<206:29:47, 13.61s/it, Loss=10.6987, Denoising=10.5406]Training:   1%|          | 385/55000 [1:24:28<207:38:29, 13.69s/it, Loss=10.6987, Denoising=10.5406]Training:   1%|          | 385/55000 [1:24:28<207:38:29, 13.69s/it, Loss=10.6998, Denoising=10.5346]Training:   1%|          | 386/55000 [1:24:42<207:23:46, 13.67s/it, Loss=10.6998, Denoising=10.5346]Training:   1%|          | 386/55000 [1:24:42<207:23:46, 13.67s/it, Loss=10.6780, Denoising=10.5133]Training:   1%|          | 387/55000 [1:24:55<204:04:12, 13.45s/it, Loss=10.6780, Denoising=10.5133]Training:   1%|          | 387/55000 [1:24:55<204:04:12, 13.45s/it, Loss=10.8110, Denoising=10.6451]Training:   1%|          | 388/55000 [1:25:07<198:36:05, 13.09s/it, Loss=10.8110, Denoising=10.6451]Training:   1%|          | 388/55000 [1:25:07<198:36:05, 13.09s/it, Loss=10.5908, Denoising=10.4167]Training:   1%|          | 389/55000 [1:25:22<209:06:35, 13.78s/it, Loss=10.5908, Denoising=10.4167]Training:   1%|          | 389/55000 [1:25:23<209:06:35, 13.78s/it, Loss=11.1800, Denoising=11.0101]Training:   1%|          | 390/55000 [1:25:35<202:32:18, 13.35s/it, Loss=11.1800, Denoising=11.0101]Training:   1%|          | 390/55000 [1:25:35<202:32:18, 13.35s/it, Loss=10.5804, Denoising=10.4128]Training:   1%|          | 391/55000 [1:25:49<206:20:44, 13.60s/it, Loss=10.5804, Denoising=10.4128]Training:   1%|          | 391/55000 [1:25:49<206:20:44, 13.60s/it, Loss=10.7668, Denoising=10.6045]Training:   1%|          | 392/55000 [1:26:03<208:58:33, 13.78s/it, Loss=10.7668, Denoising=10.6045]Training:   1%|          | 392/55000 [1:26:03<208:58:33, 13.78s/it, Loss=10.9281, Denoising=10.7638]Training:   1%|          | 393/55000 [1:26:16<205:00:20, 13.52s/it, Loss=10.9281, Denoising=10.7638]Training:   1%|          | 393/55000 [1:26:16<205:00:20, 13.52s/it, Loss=10.7108, Denoising=10.5528]Training:   1%|          | 394/55000 [1:26:27<193:51:23, 12.78s/it, Loss=10.7108, Denoising=10.5528]Training:   1%|          | 394/55000 [1:26:27<193:51:23, 12.78s/it, Loss=10.8650, Denoising=10.6846]
[WARNING] NaN loss detected! Skipping batch.
Training:   1%|          | 395/55000 [1:26:41<198:46:30, 13.10s/it, Loss=10.8650, Denoising=10.6846]Training:   1%|          | 395/55000 [1:26:41<198:46:30, 13.10s/it, Loss=10.6141, Denoising=10.4531]Training:   1%|          | 396/55000 [1:26:55<204:44:30, 13.50s/it, Loss=10.6141, Denoising=10.4531]Training:   1%|          | 396/55000 [1:26:55<204:44:30, 13.50s/it, Loss=10.5529, Denoising=10.3882]Training:   1%|          | 397/55000 [1:27:07<196:08:54, 12.93s/it, Loss=10.5529, Denoising=10.3882]Training:   1%|          | 397/55000 [1:27:07<196:08:54, 12.93s/it, Loss=10.4734, Denoising=10.3062]Training:   1%|          | 398/55000 [1:27:21<201:50:48, 13.31s/it, Loss=10.4734, Denoising=10.3062]Training:   1%|          | 398/55000 [1:27:21<201:50:48, 13.31s/it, Loss=10.6217, Denoising=10.4638]Training:   1%|          | 399/55000 [1:27:35<204:00:05, 13.45s/it, Loss=10.6217, Denoising=10.4638]Training:   1%|          | 399/55000 [1:27:35<204:00:05, 13.45s/it, Loss=10.4473, Denoising=10.2822]Training:   1%|          | 400/55000 [1:27:49<207:21:06, 13.67s/it, Loss=10.4473, Denoising=10.2822]Training:   1%|          | 400/55000 [1:27:49<207:21:06, 13.67s/it, Loss=10.3325, Denoising=10.1635]
--- PREVIEW (Step 400 | t=4) ---
Logit Range: [-0.97, 1.89]
Target: ### User:
Change of Subject: Big smackdown on 'Little G'
Â« Testing my new voice | Main | Yelpscam Part Deux Â»
Big smackdown on 'Little G'
My former colleague John Fountain has a very powerful column i...
Predict: ### User:
Change of Subject: Big smackdown on 'Little G'
Â« testing my new voice | Main | Yelpscam Part Deux Â»
Big smackdown on 'Little G'
My former colleague John Fountain has a very powerful column i...
--------------------------------------

âš¡ Thunder PrefixLM: Diffusion layers and custom embeddings saved to ./thunder_prefixlm_llama/checkpoint-400

âš¡ Checkpoint saved to ./thunder_prefixlm_llama/checkpoint-400
Training:   1%|          | 401/55000 [1:28:04<213:10:55, 14.06s/it, Loss=10.3325, Denoising=10.1635]Training:   1%|          | 401/55000 [1:28:04<213:10:55, 14.06s/it, Loss=10.6179, Denoising=10.4383]Training:   1%|          | 402/55000 [1:28:18<212:56:31, 14.04s/it, Loss=10.6179, Denoising=10.4383]Training:   1%|          | 402/55000 [1:28:18<212:56:31, 14.04s/it, Loss=10.5883, Denoising=10.4214]Training:   1%|          | 403/55000 [1:28:30<202:28:42, 13.35s/it, Loss=10.5883, Denoising=10.4214]Training:   1%|          | 403/55000 [1:28:30<202:28:42, 13.35s/it, Loss=10.3597, Denoising=10.1909]Training:   1%|          | 404/55000 [1:28:41<193:36:22, 12.77s/it, Loss=10.3597, Denoising=10.1909]Training:   1%|          | 404/55000 [1:28:41<193:36:22, 12.77s/it, Loss=10.8099, Denoising=10.6482]Training:   1%|          | 405/55000 [1:28:56<201:25:48, 13.28s/it, Loss=10.8099, Denoising=10.6482]Training:   1%|          | 405/55000 [1:28:56<201:25:48, 13.28s/it, Loss=10.5102, Denoising=10.3460]Training:   1%|          | 406/55000 [1:29:09<199:37:04, 13.16s/it, Loss=10.5102, Denoising=10.3460]Training:   1%|          | 406/55000 [1:29:09<199:37:04, 13.16s/it, Loss=10.4934, Denoising=10.3272]Training:   1%|          | 407/55000 [1:29:22<200:35:53, 13.23s/it, Loss=10.4934, Denoising=10.3272]Training:   1%|          | 407/55000 [1:29:22<200:35:53, 13.23s/it, Loss=10.6133, Denoising=10.4425]Training:   1%|          | 408/55000 [1:29:35<197:36:59, 13.03s/it, Loss=10.6133, Denoising=10.4425]Training:   1%|          | 408/55000 [1:29:35<197:36:59, 13.03s/it, Loss=10.7446, Denoising=10.5858]Training:   1%|          | 409/55000 [1:29:48<198:17:20, 13.08s/it, Loss=10.7446, Denoising=10.5858]Training:   1%|          | 409/55000 [1:29:48<198:17:20, 13.08s/it, Loss=10.7346, Denoising=10.5696]Training:   1%|          | 410/55000 [1:30:01<200:32:04, 13.22s/it, Loss=10.7346, Denoising=10.5696]Training:   1%|          | 410/55000 [1:30:01<200:32:04, 13.22s/it, Loss=10.5318, Denoising=10.3641]Training:   1%|          | 411/55000 [1:30:15<203:05:09, 13.39s/it, Loss=10.5318, Denoising=10.3641]Training:   1%|          | 411/55000 [1:30:15<203:05:09, 13.39s/it, Loss=10.4265, Denoising=10.2656]Training:   1%|          | 412/55000 [1:30:26<192:11:16, 12.67s/it, Loss=10.4265, Denoising=10.2656]Training:   1%|          | 412/55000 [1:30:26<192:11:16, 12.67s/it, Loss=10.6796, Denoising=10.5064]Training:   1%|          | 413/55000 [1:30:37<185:37:36, 12.24s/it, Loss=10.6796, Denoising=10.5064]Training:   1%|          | 413/55000 [1:30:38<185:37:36, 12.24s/it, Loss=10.7081, Denoising=10.5491]Training:   1%|          | 414/55000 [1:30:50<186:32:02, 12.30s/it, Loss=10.7081, Denoising=10.5491]Training:   1%|          | 414/55000 [1:30:50<186:32:02, 12.30s/it, Loss=10.8793, Denoising=10.7183]Training:   1%|          | 415/55000 [1:31:04<196:56:37, 12.99s/it, Loss=10.8793, Denoising=10.7183]Training:   1%|          | 415/55000 [1:31:05<196:56:37, 12.99s/it, Loss=10.5456, Denoising=10.3836]Training:   1%|          | 416/55000 [1:31:18<198:42:11, 13.11s/it, Loss=10.5456, Denoising=10.3836]Training:   1%|          | 416/55000 [1:31:18<198:42:11, 13.11s/it, Loss=10.5454, Denoising=10.3832]Training:   1%|          | 417/55000 [1:31:32<201:47:58, 13.31s/it, Loss=10.5454, Denoising=10.3832]Training:   1%|          | 417/55000 [1:31:32<201:47:58, 13.31s/it, Loss=10.6427, Denoising=10.4698]Training:   1%|          | 418/55000 [1:31:43<195:13:47, 12.88s/it, Loss=10.6427, Denoising=10.4698]Training:   1%|          | 418/55000 [1:31:44<195:13:47, 12.88s/it, Loss=10.4389, Denoising=10.2763]Training:   1%|          | 419/55000 [1:31:57<199:20:37, 13.15s/it, Loss=10.4389, Denoising=10.2763]Training:   1%|          | 419/55000 [1:31:57<199:20:37, 13.15s/it, Loss=10.4105, Denoising=10.2410]
[WARNING] NaN loss detected! Skipping batch.
Training:   1%|          | 420/55000 [1:32:24<263:23:37, 17.37s/it, Loss=10.4105, Denoising=10.2410]Training:   1%|          | 420/55000 [1:32:25<263:23:37, 17.37s/it, Loss=10.9687, Denoising=10.8021]
--- PREVIEW (Step 420 | t=286) ---
Logit Range: [-0.97, 1.88]
Target: ### User:
<p>I've followed below link and tried to construct a table grid which includes row selection.</p>

<p><a href="https://codesandbox.io/embed/github/tannerlinsley/react-table/tree/master/examp...
Predict: ,### User:
<p>I've followed below link and tried to construct a table grid which includes row selection.</p>

<p><a href "https://codesandbox.io/embed/github/tannerlinsley/react-table/tree/master/exam...
--------------------------------------

Training:   1%|          | 421/55000 [1:32:35<230:33:56, 15.21s/it, Loss=10.9687, Denoising=10.8021]Training:   1%|          | 421/55000 [1:32:35<230:33:56, 15.21s/it, Loss=10.4797, Denoising=10.3096]Training:   1%|          | 422/55000 [1:32:49<225:33:20, 14.88s/it, Loss=10.4797, Denoising=10.3096]Training:   1%|          | 422/55000 [1:32:49<225:33:20, 14.88s/it, Loss=10.9022, Denoising=10.7240]Training:   1%|          | 423/55000 [1:33:00<208:29:52, 13.75s/it, Loss=10.9022, Denoising=10.7240]Training:   1%|          | 423/55000 [1:33:00<208:29:52, 13.75s/it, Loss=10.4133, Denoising=10.2484]Training:   1%|          | 424/55000 [1:33:15<213:39:40, 14.09s/it, Loss=10.4133, Denoising=10.2484]Training:   1%|          | 424/55000 [1:33:15<213:39:40, 14.09s/it, Loss=10.5255, Denoising=10.3493]Training:   1%|          | 425/55000 [1:33:27<204:02:48, 13.46s/it, Loss=10.5255, Denoising=10.3493]Training:   1%|          | 425/55000 [1:33:27<204:02:48, 13.46s/it, Loss=10.5712, Denoising=10.4130]Training:   1%|          | 426/55000 [1:33:39<198:09:55, 13.07s/it, Loss=10.5712, Denoising=10.4130]Training:   1%|          | 426/55000 [1:33:39<198:09:55, 13.07s/it, Loss=10.6858, Denoising=10.5181]Training:   1%|          | 427/55000 [1:33:54<208:40:05, 13.77s/it, Loss=10.6858, Denoising=10.5181]Training:   1%|          | 427/55000 [1:33:54<208:40:05, 13.77s/it, Loss=10.4386, Denoising=10.2751]Training:   1%|          | 428/55000 [1:34:06<201:41:17, 13.30s/it, Loss=10.4386, Denoising=10.2751]Training:   1%|          | 428/55000 [1:34:07<201:41:17, 13.30s/it, Loss=10.6657, Denoising=10.5001]Training:   1%|          | 429/55000 [1:34:18<193:32:15, 12.77s/it, Loss=10.6657, Denoising=10.5001]Training:   1%|          | 429/55000 [1:34:18<193:32:15, 12.77s/it, Loss=10.5536, Denoising=10.3775]Training:   1%|          | 430/55000 [1:34:31<193:58:05, 12.80s/it, Loss=10.5536, Denoising=10.3775]Training:   1%|          | 430/55000 [1:34:31<193:58:05, 12.80s/it, Loss=10.6621, Denoising=10.4910]Training:   1%|          | 431/55000 [1:34:43<191:20:04, 12.62s/it, Loss=10.6621, Denoising=10.4910]Training:   1%|          | 431/55000 [1:34:43<191:20:04, 12.62s/it, Loss=10.6206, Denoising=10.4605]Training:   1%|          | 432/55000 [1:34:54<184:02:51, 12.14s/it, Loss=10.6206, Denoising=10.4605]Training:   1%|          | 432/55000 [1:34:54<184:02:51, 12.14s/it, Loss=10.5116, Denoising=10.3493]Training:   1%|          | 433/55000 [1:35:06<183:58:39, 12.14s/it, Loss=10.5116, Denoising=10.3493]Training:   1%|          | 433/55000 [1:35:06<183:58:39, 12.14s/it, Loss=10.4849, Denoising=10.3163]Training:   1%|          | 434/55000 [1:35:19<185:32:30, 12.24s/it, Loss=10.4849, Denoising=10.3163]Training:   1%|          | 434/55000 [1:35:19<185:32:30, 12.24s/it, Loss=10.5889, Denoising=10.4231]Training:   1%|          | 435/55000 [1:35:29<177:26:49, 11.71s/it, Loss=10.5889, Denoising=10.4231]Training:   1%|          | 435/55000 [1:35:29<177:26:49, 11.71s/it, Loss=10.4645, Denoising=10.3038]Training:   1%|          | 436/55000 [1:35:42<183:53:00, 12.13s/it, Loss=10.4645, Denoising=10.3038]Training:   1%|          | 436/55000 [1:35:42<183:53:00, 12.13s/it, Loss=10.4651, Denoising=10.2970]Training:   1%|          | 437/55000 [1:35:57<196:32:10, 12.97s/it, Loss=10.4651, Denoising=10.2970]Training:   1%|          | 437/55000 [1:35:57<196:32:10, 12.97s/it, Loss=10.6207, Denoising=10.4620]Training:   1%|          | 438/55000 [1:36:11<198:53:13, 13.12s/it, Loss=10.6207, Denoising=10.4620]Training:   1%|          | 438/55000 [1:36:11<198:53:13, 13.12s/it, Loss=10.6160, Denoising=10.4447]Training:   1%|          | 439/55000 [1:36:24<201:33:37, 13.30s/it, Loss=10.6160, Denoising=10.4447]Training:   1%|          | 439/55000 [1:36:25<201:33:37, 13.30s/it, Loss=10.5844, Denoising=10.4155]Training:   1%|          | 440/55000 [1:36:39<205:33:59, 13.56s/it, Loss=10.5844, Denoising=10.4155]Training:   1%|          | 440/55000 [1:36:39<205:33:59, 13.56s/it, Loss=10.7229, Denoising=10.5542]
--- PREVIEW (Step 440 | t=359) ---
Logit Range: [-1.09, 1.87]
Target: ### User:
Evaluate \begin{align*} (5a^2 - 13a + 4)(2a - 3) \end{align*} for $a = 1\frac12$.

### Assistant:
We have $a = 1\frac{1}{2} = \frac{3}{2}$.  When $a=\frac{3}{2}$, we find $2a-3=2\cdot\frac{3...
Predict: ,### user:
Evaluate begin{align*} (5a^2 - 13a + 4)2a - 3) end{align } for $a = 1\frac12$.### Assistant:
We have $a = 1,frac{1}{2} = frac{3}{2}$.  when $a=\frac{3}{2 $, we find $2a-3 2   frac{3}{2} - 3...
--------------------------------------

Training:   1%|          | 441/55000 [1:36:52<202:48:46, 13.38s/it, Loss=10.7229, Denoising=10.5542]Training:   1%|          | 441/55000 [1:36:52<202:48:46, 13.38s/it, Loss=10.5164, Denoising=10.3491]Training:   1%|          | 442/55000 [1:37:06<209:37:30, 13.83s/it, Loss=10.5164, Denoising=10.3491]Training:   1%|          | 442/55000 [1:37:07<209:37:30, 13.83s/it, Loss=10.9738, Denoising=10.8020]Training:   1%|          | 443/55000 [1:37:19<205:24:09, 13.55s/it, Loss=10.9738, Denoising=10.8020]Training:   1%|          | 443/55000 [1:37:19<205:24:09, 13.55s/it, Loss=10.5081, Denoising=10.3401]Training:   1%|          | 444/55000 [1:37:32<200:49:09, 13.25s/it, Loss=10.5081, Denoising=10.3401]Training:   1%|          | 444/55000 [1:37:32<200:49:09, 13.25s/it, Loss=10.4640, Denoising=10.3042]Training:   1%|          | 445/55000 [1:37:46<206:58:57, 13.66s/it, Loss=10.4640, Denoising=10.3042]Training:   1%|          | 445/55000 [1:37:47<206:58:57, 13.66s/it, Loss=10.3755, Denoising=10.2041]Training:   1%|          | 446/55000 [1:38:00<207:32:12, 13.70s/it, Loss=10.3755, Denoising=10.2041]Training:   1%|          | 446/55000 [1:38:00<207:32:12, 13.70s/it, Loss=10.6859, Denoising=10.5160]Training:   1%|          | 447/55000 [1:38:15<211:35:01, 13.96s/it, Loss=10.6859, Denoising=10.5160]Training:   1%|          | 447/55000 [1:38:15<211:35:01, 13.96s/it, Loss=10.5865, Denoising=10.4176]Training:   1%|          | 448/55000 [1:38:28<207:29:39, 13.69s/it, Loss=10.5865, Denoising=10.4176]Training:   1%|          | 448/55000 [1:38:28<207:29:39, 13.69s/it, Loss=10.6321, Denoising=10.4542]Training:   1%|          | 449/55000 [1:38:41<206:04:18, 13.60s/it, Loss=10.6321, Denoising=10.4542]Training:   1%|          | 449/55000 [1:38:41<206:04:18, 13.60s/it, Loss=10.3462, Denoising=10.1772]Training:   1%|          | 450/55000 [1:38:55<208:38:56, 13.77s/it, Loss=10.3462, Denoising=10.1772]Training:   1%|          | 450/55000 [1:38:56<208:38:56, 13.77s/it, Loss=10.7242, Denoising=10.5411]Training:   1%|          | 451/55000 [1:39:08<202:28:07, 13.36s/it, Loss=10.7242, Denoising=10.5411]Training:   1%|          | 451/55000 [1:39:08<202:28:07, 13.36s/it, Loss=10.3921, Denoising=10.2312]Training:   1%|          | 452/55000 [1:39:20<198:21:46, 13.09s/it, Loss=10.3921, Denoising=10.2312]Training:   1%|          | 452/55000 [1:39:20<198:21:46, 13.09s/it, Loss=10.5385, Denoising=10.3743]Training:   1%|          | 453/55000 [1:39:34<200:50:12, 13.25s/it, Loss=10.5385, Denoising=10.3743]Training:   1%|          | 453/55000 [1:39:34<200:50:12, 13.25s/it, Loss=10.5027, Denoising=10.3319]Training:   1%|          | 454/55000 [1:39:45<192:22:40, 12.70s/it, Loss=10.5027, Denoising=10.3319]Training:   1%|          | 454/55000 [1:39:45<192:22:40, 12.70s/it, Loss=10.7296, Denoising=10.5719]Training:   1%|          | 455/55000 [1:39:59<196:37:10, 12.98s/it, Loss=10.7296, Denoising=10.5719]Training:   1%|          | 455/55000 [1:39:59<196:37:10, 12.98s/it, Loss=11.0186, Denoising=10.8547]Training:   1%|          | 456/55000 [1:40:11<194:28:25, 12.84s/it, Loss=11.0186, Denoising=10.8547]Training:   1%|          | 456/55000 [1:40:12<194:28:25, 12.84s/it, Loss=10.8488, Denoising=10.6842]Training:   1%|          | 457/55000 [1:40:26<200:34:21, 13.24s/it, Loss=10.8488, Denoising=10.6842]Training:   1%|          | 457/55000 [1:40:26<200:34:21, 13.24s/it, Loss=10.7314, Denoising=10.5627]Training:   1%|          | 458/55000 [1:40:37<193:25:17, 12.77s/it, Loss=10.7314, Denoising=10.5627]Training:   1%|          | 458/55000 [1:40:37<193:25:17, 12.77s/it, Loss=10.3359, Denoising=10.1701]Training:   1%|          | 459/55000 [1:40:52<201:39:31, 13.31s/it, Loss=10.3359, Denoising=10.1701]Training:   1%|          | 459/55000 [1:40:52<201:39:31, 13.31s/it, Loss=10.6567, Denoising=10.4924]Training:   1%|          | 460/55000 [1:41:06<207:25:54, 13.69s/it, Loss=10.6567, Denoising=10.4924]Training:   1%|          | 460/55000 [1:41:07<207:25:54, 13.69s/it, Loss=10.6435, Denoising=10.4712]
--- PREVIEW (Step 460 | t=457) ---
Logit Range: [-1.09, 1.88]
Target: ### User:
Solve the equation $|y-6| + 2y = 9$ for $y$.

### Assistant:
We consider two cases, $y\ge 6$ and $y < 6$.

Case 1: $y \ge 6:$  If $y \ge 6$, then $|y-6| = y-6$ and our equation is $y-6+2y=9$...
Predict: ,### user:
Solve the equation $|y-6| + 2y = 9$ for $y$.### Assistant:
We consider two cases, $y\ge 6$ and $y < 6$.

Case 1: $y ge 6:$  if $y ge 6$ then $|y-6| = y-6$ and our equation is $y-6+2y=9$.  S...
--------------------------------------

Training:   1%|          | 461/55000 [1:41:19<201:53:25, 13.33s/it, Loss=10.6435, Denoising=10.4712]Training:   1%|          | 461/55000 [1:41:19<201:53:25, 13.33s/it, Loss=10.8468, Denoising=10.6778]Training:   1%|          | 462/55000 [1:41:34<209:26:03, 13.82s/it, Loss=10.8468, Denoising=10.6778]Training:   1%|          | 462/55000 [1:41:34<209:26:03, 13.82s/it, Loss=10.3897, Denoising=10.2148]Training:   1%|          | 463/55000 [1:41:46<203:00:22, 13.40s/it, Loss=10.3897, Denoising=10.2148]Training:   1%|          | 463/55000 [1:41:46<203:00:22, 13.40s/it, Loss=10.3856, Denoising=10.2266]Training:   1%|          | 464/55000 [1:41:59<201:21:49, 13.29s/it, Loss=10.3856, Denoising=10.2266]Training:   1%|          | 464/55000 [1:41:59<201:21:49, 13.29s/it, Loss=10.4369, Denoising=10.2651]Training:   1%|          | 465/55000 [1:42:12<199:22:39, 13.16s/it, Loss=10.4369, Denoising=10.2651]Training:   1%|          | 465/55000 [1:42:12<199:22:39, 13.16s/it, Loss=10.3793, Denoising=10.2161]Training:   1%|          | 466/55000 [1:42:26<202:52:10, 13.39s/it, Loss=10.3793, Denoising=10.2161]Training:   1%|          | 466/55000 [1:42:26<202:52:10, 13.39s/it, Loss=10.5072, Denoising=10.3407]Training:   1%|          | 467/55000 [1:42:40<206:27:18, 13.63s/it, Loss=10.5072, Denoising=10.3407]Training:   1%|          | 467/55000 [1:42:41<206:27:18, 13.63s/it, Loss=10.5377, Denoising=10.3708]Training:   1%|          | 468/55000 [1:42:55<210:39:51, 13.91s/it, Loss=10.5377, Denoising=10.3708]Training:   1%|          | 468/55000 [1:42:55<210:39:51, 13.91s/it, Loss=10.5514, Denoising=10.3851]Training:   1%|          | 469/55000 [1:43:07<201:07:39, 13.28s/it, Loss=10.5514, Denoising=10.3851]Training:   1%|          | 469/55000 [1:43:07<201:07:39, 13.28s/it, Loss=10.7814, Denoising=10.6101]Training:   1%|          | 470/55000 [1:43:21<207:04:05, 13.67s/it, Loss=10.7814, Denoising=10.6101]Training:   1%|          | 470/55000 [1:43:21<207:04:05, 13.67s/it, Loss=10.4705, Denoising=10.3110]Training:   1%|          | 471/55000 [1:43:31<190:58:46, 12.61s/it, Loss=10.4705, Denoising=10.3110]Training:   1%|          | 471/55000 [1:43:32<190:58:46, 12.61s/it, Loss=10.9128, Denoising=10.7369]Training:   1%|          | 472/55000 [1:43:46<199:55:24, 13.20s/it, Loss=10.9128, Denoising=10.7369]Training:   1%|          | 472/55000 [1:43:46<199:55:24, 13.20s/it, Loss=10.6053, Denoising=10.4349]Training:   1%|          | 473/55000 [1:43:58<192:57:32, 12.74s/it, Loss=10.6053, Denoising=10.4349]Training:   1%|          | 473/55000 [1:43:58<192:57:32, 12.74s/it, Loss=10.4045, Denoising=10.2414]Training:   1%|          | 474/55000 [1:44:12<199:03:32, 13.14s/it, Loss=10.4045, Denoising=10.2414]Training:   1%|          | 474/55000 [1:44:12<199:03:32, 13.14s/it, Loss=10.7774, Denoising=10.6031]Training:   1%|          | 475/55000 [1:44:25<200:02:11, 13.21s/it, Loss=10.7774, Denoising=10.6031]Training:   1%|          | 475/55000 [1:44:25<200:02:11, 13.21s/it, Loss=10.7529, Denoising=10.5833]Training:   1%|          | 476/55000 [1:44:40<208:06:25, 13.74s/it, Loss=10.7529, Denoising=10.5833]Training:   1%|          | 476/55000 [1:44:40<208:06:25, 13.74s/it, Loss=10.4173, Denoising=10.2491]Training:   1%|          | 477/55000 [1:44:54<208:18:25, 13.75s/it, Loss=10.4173, Denoising=10.2491]Training:   1%|          | 477/55000 [1:44:54<208:18:25, 13.75s/it, Loss=10.6921, Denoising=10.5348]Training:   1%|          | 478/55000 [1:45:06<202:19:37, 13.36s/it, Loss=10.6921, Denoising=10.5348]Training:   1%|          | 478/55000 [1:45:07<202:19:37, 13.36s/it, Loss=10.7698, Denoising=10.6022]Training:   1%|          | 479/55000 [1:45:19<197:24:08, 13.03s/it, Loss=10.7698, Denoising=10.6022]Training:   1%|          | 479/55000 [1:45:19<197:24:08, 13.03s/it, Loss=10.6238, Denoising=10.4571]Training:   1%|          | 480/55000 [1:45:33<202:08:01, 13.35s/it, Loss=10.6238, Denoising=10.4571]Training:   1%|          | 480/55000 [1:45:33<202:08:01, 13.35s/it, Loss=10.8026, Denoising=10.6297]
--- PREVIEW (Step 480 | t=157) ---
Logit Range: [-1.10, 1.89]
Target: ### Assistant:
You are an AI assistant that follows instruction extremely well. Help as much as you can.

### User:
Given the question: Please answer the following question about this movie plot. If i...
Predict: ,### Assistant:
You are an AI assistant that follows instruction extremely well. Help as much as you can.### user:
 given the question: Please answer the following question about this movie plot. If i...
--------------------------------------

Training:   1%|          | 481/55000 [1:45:47<207:06:22, 13.68s/it, Loss=10.8026, Denoising=10.6297]Training:   1%|          | 481/55000 [1:45:47<207:06:22, 13.68s/it, Loss=10.5769, Denoising=10.4079]Training:   1%|          | 482/55000 [1:46:00<203:42:55, 13.45s/it, Loss=10.5769, Denoising=10.4079]Training:   1%|          | 482/55000 [1:46:00<203:42:55, 13.45s/it, Loss=10.4813, Denoising=10.3098]Training:   1%|          | 483/55000 [1:46:14<205:13:56, 13.55s/it, Loss=10.4813, Denoising=10.3098]Training:   1%|          | 483/55000 [1:46:14<205:13:56, 13.55s/it, Loss=10.8518, Denoising=10.6782]Training:   1%|          | 484/55000 [1:46:26<198:42:39, 13.12s/it, Loss=10.8518, Denoising=10.6782]Training:   1%|          | 484/55000 [1:46:26<198:42:39, 13.12s/it, Loss=10.5272, Denoising=10.3521]Training:   1%|          | 485/55000 [1:46:40<202:45:13, 13.39s/it, Loss=10.5272, Denoising=10.3521]Training:   1%|          | 485/55000 [1:46:40<202:45:13, 13.39s/it, Loss=10.9008, Denoising=10.7280]Training:   1%|          | 486/55000 [1:46:54<205:31:57, 13.57s/it, Loss=10.9008, Denoising=10.7280]Training:   1%|          | 486/55000 [1:46:54<205:31:57, 13.57s/it, Loss=10.4794, Denoising=10.3144]Training:   1%|          | 487/55000 [1:47:07<204:22:50, 13.50s/it, Loss=10.4794, Denoising=10.3144]Training:   1%|          | 487/55000 [1:47:07<204:22:50, 13.50s/it, Loss=10.7005, Denoising=10.5300]Training:   1%|          | 488/55000 [1:47:21<205:50:09, 13.59s/it, Loss=10.7005, Denoising=10.5300]Training:   1%|          | 488/55000 [1:47:21<205:50:09, 13.59s/it, Loss=10.3772, Denoising=10.2135]Training:   1%|          | 489/55000 [1:47:35<206:11:10, 13.62s/it, Loss=10.3772, Denoising=10.2135]Training:   1%|          | 489/55000 [1:47:35<206:11:10, 13.62s/it, Loss=10.8707, Denoising=10.7004]Training:   1%|          | 490/55000 [1:47:48<202:52:22, 13.40s/it, Loss=10.8707, Denoising=10.7004]Training:   1%|          | 490/55000 [1:47:48<202:52:22, 13.40s/it, Loss=10.7609, Denoising=10.5948]Training:   1%|          | 491/55000 [1:48:03<210:06:45, 13.88s/it, Loss=10.7609, Denoising=10.5948]Training:   1%|          | 491/55000 [1:48:03<210:06:45, 13.88s/it, Loss=10.5309, Denoising=10.3698]Training:   1%|          | 492/55000 [1:48:16<207:22:58, 13.70s/it, Loss=10.5309, Denoising=10.3698]Training:   1%|          | 492/55000 [1:48:16<207:22:58, 13.70s/it, Loss=10.6439, Denoising=10.4657]Training:   1%|          | 493/55000 [1:48:30<207:44:17, 13.72s/it, Loss=10.6439, Denoising=10.4657]Training:   1%|          | 493/55000 [1:48:30<207:44:17, 13.72s/it, Loss=10.3367, Denoising=10.1660]Training:   1%|          | 494/55000 [1:48:42<202:30:07, 13.37s/it, Loss=10.3367, Denoising=10.1660]Training:   1%|          | 494/55000 [1:48:42<202:30:07, 13.37s/it, Loss=10.7315, Denoising=10.5756]Training:   1%|          | 495/55000 [1:48:55<200:15:43, 13.23s/it, Loss=10.7315, Denoising=10.5756]Training:   1%|          | 495/55000 [1:48:55<200:15:43, 13.23s/it, Loss=10.4769, Denoising=10.3102]Training:   1%|          | 496/55000 [1:49:08<197:46:44, 13.06s/it, Loss=10.4769, Denoising=10.3102]Training:   1%|          | 496/55000 [1:49:08<197:46:44, 13.06s/it, Loss=10.8668, Denoising=10.6949]Training:   1%|          | 497/55000 [1:49:20<195:22:21, 12.90s/it, Loss=10.8668, Denoising=10.6949]Training:   1%|          | 497/55000 [1:49:21<195:22:21, 12.90s/it, Loss=10.5124, Denoising=10.3340]Training:   1%|          | 498/55000 [1:49:33<193:56:29, 12.81s/it, Loss=10.5124, Denoising=10.3340]Training:   1%|          | 498/55000 [1:49:33<193:56:29, 12.81s/it, Loss=10.6970, Denoising=10.5318]
[WARNING] NaN loss detected! Skipping batch.
Training:   1%|          | 499/55000 [1:49:46<195:03:17, 12.88s/it, Loss=10.6970, Denoising=10.5318]Training:   1%|          | 499/55000 [1:49:46<195:03:17, 12.88s/it, Loss=10.5730, Denoising=10.4041]Training:   1%|          | 500/55000 [1:50:00<198:36:42, 13.12s/it, Loss=10.5730, Denoising=10.4041]Training:   1%|          | 500/55000 [1:50:00<198:36:42, 13.12s/it, Loss=10.5664, Denoising=10.3998]
--- PREVIEW (Step 500 | t=145) ---
Logit Range: [-0.97, 1.91]
Target: ### User:
<p>i'm trying to bind jquery autocomplete result to dynamically created textboxes, i have searched internet and forums but couldn't found any appropriate solution, i'm sharing my code</p>

<...
Predict: ### User:
<p>i'm trying to bind jquery autocomplete result to dynamically created textboxes, i have searched internet and forums but couldn't found any appropriate solution, i'm sharing my code</p>

<...
--------------------------------------

Training:   1%|          | 501/55000 [1:50:14<203:32:41, 13.45s/it, Loss=10.5664, Denoising=10.3998]Training:   1%|          | 501/55000 [1:50:14<203:32:41, 13.45s/it, Loss=10.7270, Denoising=10.5638]Training:   1%|          | 502/55000 [1:50:28<206:05:10, 13.61s/it, Loss=10.7270, Denoising=10.5638]Training:   1%|          | 502/55000 [1:50:28<206:05:10, 13.61s/it, Loss=10.3613, Denoising=10.1976]Training:   1%|          | 503/55000 [1:50:42<206:33:05, 13.64s/it, Loss=10.3613, Denoising=10.1976]Training:   1%|          | 503/55000 [1:50:42<206:33:05, 13.64s/it, Loss=10.7705, Denoising=10.6020]Training:   1%|          | 504/55000 [1:50:57<212:39:33, 14.05s/it, Loss=10.7705, Denoising=10.6020]Training:   1%|          | 504/55000 [1:50:57<212:39:33, 14.05s/it, Loss=10.4438, Denoising=10.2761]Training:   1%|          | 505/55000 [1:51:11<215:04:13, 14.21s/it, Loss=10.4438, Denoising=10.2761]Training:   1%|          | 505/55000 [1:51:11<215:04:13, 14.21s/it, Loss=10.6434, Denoising=10.4685]Training:   1%|          | 506/55000 [1:51:25<212:53:45, 14.06s/it, Loss=10.6434, Denoising=10.4685]Training:   1%|          | 506/55000 [1:51:25<212:53:45, 14.06s/it, Loss=10.7064, Denoising=10.5390]Training:   1%|          | 507/55000 [1:51:40<215:15:52, 14.22s/it, Loss=10.7064, Denoising=10.5390]Training:   1%|          | 507/55000 [1:51:40<215:15:52, 14.22s/it, Loss=10.7414, Denoising=10.5735]Training:   1%|          | 508/55000 [1:51:54<216:52:12, 14.33s/it, Loss=10.7414, Denoising=10.5735]Training:   1%|          | 508/55000 [1:51:54<216:52:12, 14.33s/it, Loss=11.0301, Denoising=10.8476]Training:   1%|          | 509/55000 [1:52:07<212:34:52, 14.04s/it, Loss=11.0301, Denoising=10.8476]Training:   1%|          | 509/55000 [1:52:08<212:34:52, 14.04s/it, Loss=10.9274, Denoising=10.7614]Training:   1%|          | 510/55000 [1:52:21<209:33:59, 13.85s/it, Loss=10.9274, Denoising=10.7614]Training:   1%|          | 510/55000 [1:52:21<209:33:59, 13.85s/it, Loss=10.3791, Denoising=10.2104]Training:   1%|          | 511/55000 [1:52:35<211:04:05, 13.94s/it, Loss=10.3791, Denoising=10.2104]Training:   1%|          | 511/55000 [1:52:35<211:04:05, 13.94s/it, Loss=10.7297, Denoising=10.5606]Training:   1%|          | 512/55000 [1:52:48<208:31:14, 13.78s/it, Loss=10.7297, Denoising=10.5606]Training:   1%|          | 512/55000 [1:52:49<208:31:14, 13.78s/it, Loss=10.4627, Denoising=10.2980]Training:   1%|          | 513/55000 [1:52:59<192:41:28, 12.73s/it, Loss=10.4627, Denoising=10.2980]Training:   1%|          | 513/55000 [1:52:59<192:41:28, 12.73s/it, Loss=10.6480, Denoising=10.4753]Training:   1%|          | 514/55000 [1:53:12<194:30:10, 12.85s/it, Loss=10.6480, Denoising=10.4753]Training:   1%|          | 514/55000 [1:53:12<194:30:10, 12.85s/it, Loss=10.4364, Denoising=10.2670]Training:   1%|          | 515/55000 [1:53:24<190:02:37, 12.56s/it, Loss=10.4364, Denoising=10.2670]Training:   1%|          | 515/55000 [1:53:24<190:02:37, 12.56s/it, Loss=10.6749, Denoising=10.5035]Training:   1%|          | 516/55000 [1:53:37<191:57:35, 12.68s/it, Loss=10.6749, Denoising=10.5035]Training:   1%|          | 516/55000 [1:53:37<191:57:35, 12.68s/it, Loss=10.8487, Denoising=10.6779]Training:   1%|          | 517/55000 [1:53:50<196:57:30, 13.01s/it, Loss=10.8487, Denoising=10.6779]Training:   1%|          | 517/55000 [1:53:51<196:57:30, 13.01s/it, Loss=10.6684, Denoising=10.4980]Training:   1%|          | 518/55000 [1:54:04<200:27:23, 13.25s/it, Loss=10.6684, Denoising=10.4980]Training:   1%|          | 518/55000 [1:54:04<200:27:23, 13.25s/it, Loss=10.6197, Denoising=10.4503]Training:   1%|          | 519/55000 [1:54:17<196:54:58, 13.01s/it, Loss=10.6197, Denoising=10.4503]Training:   1%|          | 519/55000 [1:54:17<196:54:58, 13.01s/it, Loss=10.4553, Denoising=10.2913]Training:   1%|          | 520/55000 [1:54:28<189:20:19, 12.51s/it, Loss=10.4553, Denoising=10.2913]Training:   1%|          | 520/55000 [1:54:28<189:20:19, 12.51s/it, Loss=10.4293, Denoising=10.2610]
--- PREVIEW (Step 520 | t=473) ---
Logit Range: [-1.00, 1.91]
Target: ### Assistant:
You are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. While performing the task think step-by-step and justify your steps.
...
Predict: ,### Assistant:
You are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. while performing the task think step by step and justify your steps....
--------------------------------------

Training:   1%|          | 521/55000 [1:54:38<178:14:08, 11.78s/it, Loss=10.4293, Denoising=10.2610]Training:   1%|          | 521/55000 [1:54:38<178:14:08, 11.78s/it, Loss=10.6738, Denoising=10.5043]Training:   1%|          | 522/55000 [1:54:51<182:39:55, 12.07s/it, Loss=10.6738, Denoising=10.5043]Training:   1%|          | 522/55000 [1:54:51<182:39:55, 12.07s/it, Loss=10.6909, Denoising=10.5242]Training:   1%|          | 523/55000 [1:55:05<190:24:54, 12.58s/it, Loss=10.6909, Denoising=10.5242]Training:   1%|          | 523/55000 [1:55:05<190:24:54, 12.58s/it, Loss=10.7348, Denoising=10.5608]Training:   1%|          | 524/55000 [1:55:20<201:16:08, 13.30s/it, Loss=10.7348, Denoising=10.5608]Training:   1%|          | 524/55000 [1:55:20<201:16:08, 13.30s/it, Loss=10.7209, Denoising=10.5406]Training:   1%|          | 525/55000 [1:55:33<203:25:47, 13.44s/it, Loss=10.7209, Denoising=10.5406]Training:   1%|          | 525/55000 [1:55:34<203:25:47, 13.44s/it, Loss=10.5059, Denoising=10.3444]Training:   1%|          | 526/55000 [1:55:47<205:06:11, 13.55s/it, Loss=10.5059, Denoising=10.3444]Training:   1%|          | 526/55000 [1:55:47<205:06:11, 13.55s/it, Loss=10.5695, Denoising=10.4043]Training:   1%|          | 527/55000 [1:56:00<201:58:59, 13.35s/it, Loss=10.5695, Denoising=10.4043]Training:   1%|          | 527/55000 [1:56:00<201:58:59, 13.35s/it, Loss=10.4260, Denoising=10.2585]Training:   1%|          | 528/55000 [1:56:15<207:02:48, 13.68s/it, Loss=10.4260, Denoising=10.2585]Training:   1%|          | 528/55000 [1:56:15<207:02:48, 13.68s/it, Loss=10.5384, Denoising=10.3708]Training:   1%|          | 529/55000 [1:56:28<207:20:50, 13.70s/it, Loss=10.5384, Denoising=10.3708]Training:   1%|          | 529/55000 [1:56:28<207:20:50, 13.70s/it, Loss=10.8534, Denoising=10.6806]Training:   1%|          | 530/55000 [1:56:41<204:20:47, 13.51s/it, Loss=10.8534, Denoising=10.6806]Training:   1%|          | 530/55000 [1:56:42<204:20:47, 13.51s/it, Loss=10.6798, Denoising=10.5158]Training:   1%|          | 531/55000 [1:56:56<210:49:22, 13.93s/it, Loss=10.6798, Denoising=10.5158]Training:   1%|          | 531/55000 [1:56:56<210:49:22, 13.93s/it, Loss=10.4633, Denoising=10.3012]Training:   1%|          | 532/55000 [1:57:09<206:43:33, 13.66s/it, Loss=10.4633, Denoising=10.3012]Training:   1%|          | 532/55000 [1:57:10<206:43:33, 13.66s/it, Loss=10.5556, Denoising=10.3823]Training:   1%|          | 533/55000 [1:57:22<201:20:14, 13.31s/it, Loss=10.5556, Denoising=10.3823]Training:   1%|          | 533/55000 [1:57:22<201:20:14, 13.31s/it, Loss=10.4646, Denoising=10.2876]Training:   1%|          | 534/55000 [1:57:36<205:18:44, 13.57s/it, Loss=10.4646, Denoising=10.2876]Training:   1%|          | 534/55000 [1:57:36<205:18:44, 13.57s/it, Loss=10.4504, Denoising=10.2799]Training:   1%|          | 535/55000 [1:57:48<199:42:56, 13.20s/it, Loss=10.4504, Denoising=10.2799]Training:   1%|          | 535/55000 [1:57:49<199:42:56, 13.20s/it, Loss=10.6495, Denoising=10.4859]Training:   1%|          | 536/55000 [1:58:00<192:01:50, 12.69s/it, Loss=10.6495, Denoising=10.4859]Training:   1%|          | 536/55000 [1:58:00<192:01:50, 12.69s/it, Loss=10.4929, Denoising=10.3280]Training:   1%|          | 537/55000 [1:58:13<195:11:39, 12.90s/it, Loss=10.4929, Denoising=10.3280]Training:   1%|          | 537/55000 [1:58:13<195:11:39, 12.90s/it, Loss=10.5621, Denoising=10.3908]Training:   1%|          | 538/55000 [1:58:25<189:54:30, 12.55s/it, Loss=10.5621, Denoising=10.3908]Training:   1%|          | 538/55000 [1:58:25<189:54:30, 12.55s/it, Loss=10.4431, Denoising=10.2755]Training:   1%|          | 539/55000 [1:58:39<196:03:00, 12.96s/it, Loss=10.4431, Denoising=10.2755]Training:   1%|          | 539/55000 [1:58:39<196:03:00, 12.96s/it, Loss=10.5880, Denoising=10.4209]Training:   1%|          | 540/55000 [1:58:50<189:54:53, 12.55s/it, Loss=10.5880, Denoising=10.4209]Training:   1%|          | 540/55000 [1:58:51<189:54:53, 12.55s/it, Loss=10.5549, Denoising=10.3951]
--- PREVIEW (Step 540 | t=832) ---
Logit Range: [-1.02, 1.86]
Target: ### User:
What is the sum of the solutions of the equation $(3x+5)(2x-9) = 0$? Express your answer as a common fraction.

### Assistant:
Expanding the left hand side of the given equation, we have $6x...
Predict: ,### user:
 what is the sum of the solutions of the equation $(3x+5)2x-9) = 0$? Express your answer as a common fraction.

### Assistant:
Expanding the left hand side of the given equation, we have $6...
--------------------------------------

Training:   1%|          | 541/55000 [1:59:05<196:47:28, 13.01s/it, Loss=10.5549, Denoising=10.3951]Training:   1%|          | 541/55000 [1:59:05<196:47:28, 13.01s/it, Loss=10.6914, Denoising=10.5219]Training:   1%|          | 542/55000 [1:59:19<202:05:47, 13.36s/it, Loss=10.6914, Denoising=10.5219]Training:   1%|          | 542/55000 [1:59:19<202:05:47, 13.36s/it, Loss=11.2947, Denoising=11.1294]Training:   1%|          | 543/55000 [1:59:32<200:02:57, 13.22s/it, Loss=11.2947, Denoising=11.1294]Training:   1%|          | 543/55000 [1:59:32<200:02:57, 13.22s/it, Loss=10.7665, Denoising=10.6021]Training:   1%|          | 544/55000 [1:59:45<199:07:11, 13.16s/it, Loss=10.7665, Denoising=10.6021]Training:   1%|          | 544/55000 [1:59:45<199:07:11, 13.16s/it, Loss=10.4318, Denoising=10.2733]Training:   1%|          | 545/55000 [1:59:59<205:31:11, 13.59s/it, Loss=10.4318, Denoising=10.2733]Training:   1%|          | 545/55000 [1:59:59<205:31:11, 13.59s/it, Loss=10.5565, Denoising=10.3816]Training:   1%|          | 546/55000 [2:00:13<208:10:17, 13.76s/it, Loss=10.5565, Denoising=10.3816]Training:   1%|          | 546/55000 [2:00:14<208:10:17, 13.76s/it, Loss=10.4137, Denoising=10.2434]Training:   1%|          | 547/55000 [2:00:27<208:13:48, 13.77s/it, Loss=10.4137, Denoising=10.2434]Training:   1%|          | 547/55000 [2:00:27<208:13:48, 13.77s/it, Loss=10.3916, Denoising=10.2229]Training:   1%|          | 548/55000 [2:00:41<210:06:40, 13.89s/it, Loss=10.3916, Denoising=10.2229]Training:   1%|          | 548/55000 [2:00:42<210:06:40, 13.89s/it, Loss=10.8047, Denoising=10.6331]Training:   1%|          | 549/55000 [2:00:55<208:04:35, 13.76s/it, Loss=10.8047, Denoising=10.6331]Training:   1%|          | 549/55000 [2:00:55<208:04:35, 13.76s/it, Loss=10.5268, Denoising=10.3663]Training:   1%|          | 550/55000 [2:01:09<208:33:55, 13.79s/it, Loss=10.5268, Denoising=10.3663]Training:   1%|          | 550/55000 [2:01:09<208:33:55, 13.79s/it, Loss=10.5501, Denoising=10.3833]Training:   1%|          | 551/55000 [2:01:23<210:00:14, 13.88s/it, Loss=10.5501, Denoising=10.3833]Training:   1%|          | 551/55000 [2:01:23<210:00:14, 13.88s/it, Loss=10.4978, Denoising=10.3277]Training:   1%|          | 552/55000 [2:01:38<215:00:09, 14.22s/it, Loss=10.4978, Denoising=10.3277]Training:   1%|          | 552/55000 [2:01:38<215:00:09, 14.22s/it, Loss=10.9077, Denoising=10.7364]Training:   1%|          | 553/55000 [2:01:49<200:59:43, 13.29s/it, Loss=10.9077, Denoising=10.7364]Training:   1%|          | 553/55000 [2:01:49<200:59:43, 13.29s/it, Loss=10.5009, Denoising=10.3333]Training:   1%|          | 554/55000 [2:02:02<199:35:20, 13.20s/it, Loss=10.5009, Denoising=10.3333]Training:   1%|          | 554/55000 [2:02:02<199:35:20, 13.20s/it, Loss=10.4454, Denoising=10.2680]Training:   1%|          | 555/55000 [2:02:15<200:25:36, 13.25s/it, Loss=10.4454, Denoising=10.2680]Training:   1%|          | 555/55000 [2:02:15<200:25:36, 13.25s/it, Loss=10.5677, Denoising=10.4040]Training:   1%|          | 556/55000 [2:02:28<197:56:43, 13.09s/it, Loss=10.5677, Denoising=10.4040]Training:   1%|          | 556/55000 [2:02:28<197:56:43, 13.09s/it, Loss=10.4748, Denoising=10.3047]Training:   1%|          | 557/55000 [2:02:41<197:12:16, 13.04s/it, Loss=10.4748, Denoising=10.3047]Training:   1%|          | 557/55000 [2:02:41<197:12:16, 13.04s/it, Loss=10.7539, Denoising=10.5804]Training:   1%|          | 558/55000 [2:02:53<193:39:41, 12.81s/it, Loss=10.7539, Denoising=10.5804]Training:   1%|          | 558/55000 [2:02:53<193:39:41, 12.81s/it, Loss=10.4842, Denoising=10.3243]Training:   1%|          | 559/55000 [2:03:08<201:15:53, 13.31s/it, Loss=10.4842, Denoising=10.3243]Training:   1%|          | 559/55000 [2:03:08<201:15:53, 13.31s/it, Loss=10.7664, Denoising=10.5898]Training:   1%|          | 560/55000 [2:03:20<196:01:03, 12.96s/it, Loss=10.7664, Denoising=10.5898]Training:   1%|          | 560/55000 [2:03:20<196:01:03, 12.96s/it, Loss=10.4140, Denoising=10.2516]
--- PREVIEW (Step 560 | t=163) ---
Logit Range: [-0.97, 1.92]
Target: ### User:
Stochastic epidemics in growing populations

Tom Britton and Pieter Trapman

plus1pt minus1pt

Introduction

Consider a population in which an infectious disease is introduced. The question ...
Predict: ,### user:
Stochastic epidemics in growing populations

 Tom Britton and Pieter Trapman

plus1pt minus1pt

Introduction

Consider a population in which an infectious disease is introduced. The questio...
--------------------------------------

Training:   1%|          | 561/55000 [2:03:33<197:31:24, 13.06s/it, Loss=10.4140, Denoising=10.2516]Training:   1%|          | 561/55000 [2:03:33<197:31:24, 13.06s/it, Loss=10.8133, Denoising=10.6522]Training:   1%|          | 562/55000 [2:03:46<196:43:01, 13.01s/it, Loss=10.8133, Denoising=10.6522]Training:   1%|          | 562/55000 [2:03:46<196:43:01, 13.01s/it, Loss=10.4905, Denoising=10.3040]Training:   1%|          | 563/55000 [2:03:59<197:25:39, 13.06s/it, Loss=10.4905, Denoising=10.3040]Training:   1%|          | 563/55000 [2:03:59<197:25:39, 13.06s/it, Loss=10.4635, Denoising=10.2964]Training:   1%|          | 564/55000 [2:04:14<207:35:37, 13.73s/it, Loss=10.4635, Denoising=10.2964]Training:   1%|          | 564/55000 [2:04:15<207:35:37, 13.73s/it, Loss=10.6224, Denoising=10.4577]Training:   1%|          | 565/55000 [2:04:28<208:54:01, 13.82s/it, Loss=10.6224, Denoising=10.4577]Training:   1%|          | 565/55000 [2:04:29<208:54:01, 13.82s/it, Loss=10.8965, Denoising=10.7249]Training:   1%|          | 566/55000 [2:04:42<206:53:19, 13.68s/it, Loss=10.8965, Denoising=10.7249]Training:   1%|          | 566/55000 [2:04:42<206:53:19, 13.68s/it, Loss=10.5229, Denoising=10.3598]Training:   1%|          | 567/55000 [2:04:56<207:20:04, 13.71s/it, Loss=10.5229, Denoising=10.3598]Training:   1%|          | 567/55000 [2:04:56<207:20:04, 13.71s/it, Loss=10.3477, Denoising=10.1791]Training:   1%|          | 568/55000 [2:05:09<205:17:59, 13.58s/it, Loss=10.3477, Denoising=10.1791]Training:   1%|          | 568/55000 [2:05:09<205:17:59, 13.58s/it, Loss=10.7250, Denoising=10.5496]Training:   1%|          | 569/55000 [2:05:24<211:41:16, 14.00s/it, Loss=10.7250, Denoising=10.5496]Training:   1%|          | 569/55000 [2:05:24<211:41:16, 14.00s/it, Loss=10.6643, Denoising=10.4838]Training:   1%|          | 570/55000 [2:05:36<204:59:17, 13.56s/it, Loss=10.6643, Denoising=10.4838]Training:   1%|          | 570/55000 [2:05:37<204:59:17, 13.56s/it, Loss=10.3556, Denoising=10.1903]Training:   1%|          | 571/55000 [2:05:51<209:38:35, 13.87s/it, Loss=10.3556, Denoising=10.1903]Training:   1%|          | 571/55000 [2:05:51<209:38:35, 13.87s/it, Loss=10.4602, Denoising=10.2898]Training:   1%|          | 572/55000 [2:06:03<199:19:52, 13.18s/it, Loss=10.4602, Denoising=10.2898]Training:   1%|          | 572/55000 [2:06:03<199:19:52, 13.18s/it, Loss=10.4003, Denoising=10.2290]Training:   1%|          | 573/55000 [2:06:15<197:34:19, 13.07s/it, Loss=10.4003, Denoising=10.2290]Training:   1%|          | 573/55000 [2:06:16<197:34:19, 13.07s/it, Loss=10.8316, Denoising=10.6597]Training:   1%|          | 574/55000 [2:06:29<198:03:42, 13.10s/it, Loss=10.8316, Denoising=10.6597]Training:   1%|          | 574/55000 [2:06:29<198:03:42, 13.10s/it, Loss=10.4326, Denoising=10.2752]Training:   1%|          | 575/55000 [2:06:43<202:32:42, 13.40s/it, Loss=10.4326, Denoising=10.2752]Training:   1%|          | 575/55000 [2:06:43<202:32:42, 13.40s/it, Loss=10.5077, Denoising=10.3385]Training:   1%|          | 576/55000 [2:06:55<198:44:09, 13.15s/it, Loss=10.5077, Denoising=10.3385]Training:   1%|          | 576/55000 [2:06:55<198:44:09, 13.15s/it, Loss=10.4743, Denoising=10.3031]Training:   1%|          | 577/55000 [2:07:08<199:19:50, 13.19s/it, Loss=10.4743, Denoising=10.3031]Training:   1%|          | 577/55000 [2:07:09<199:19:50, 13.19s/it, Loss=10.3518, Denoising=10.1838]Training:   1%|          | 578/55000 [2:07:21<197:29:47, 13.06s/it, Loss=10.3518, Denoising=10.1838]Training:   1%|          | 578/55000 [2:07:21<197:29:47, 13.06s/it, Loss=11.0538, Denoising=10.8809]
[WARNING] NaN loss detected! Skipping batch.
Training:   1%|          | 579/55000 [2:07:34<193:52:32, 12.83s/it, Loss=11.0538, Denoising=10.8809]Training:   1%|          | 579/55000 [2:07:34<193:52:32, 12.83s/it, Loss=10.5107, Denoising=10.3472]Training:   1%|          | 580/55000 [2:07:47<197:18:44, 13.05s/it, Loss=10.5107, Denoising=10.3472]Training:   1%|          | 580/55000 [2:07:47<197:18:44, 13.05s/it, Loss=10.5099, Denoising=10.3463]
--- PREVIEW (Step 580 | t=13) ---
Logit Range: [-1.10, 1.95]
Target: ### User:
Summarize the following proposed legislation (bill): SECTION 1. SHORT TITLE.

    This Act may be cited as the ``Standardization of Collegiate 
Oversight of Revenues and Expenditures Act'' o...
Predict: ### user:
Summarize the following proposed legislation (bill): section 1. short title.

    This Act may be cited as the `` standardization of Collegiate 
Oversight of Revenues and Expenditures Act'' ...
--------------------------------------

Training:   1%|          | 581/55000 [2:07:59<193:09:02, 12.78s/it, Loss=10.5099, Denoising=10.3463]Training:   1%|          | 581/55000 [2:07:59<193:09:02, 12.78s/it, Loss=10.4181, Denoising=10.2485]Training:   1%|          | 582/55000 [2:08:15<204:56:17, 13.56s/it, Loss=10.4181, Denoising=10.2485]Training:   1%|          | 582/55000 [2:08:15<204:56:17, 13.56s/it, Loss=10.3900, Denoising=10.2167]Training:   1%|          | 583/55000 [2:08:27<200:53:07, 13.29s/it, Loss=10.3900, Denoising=10.2167]Training:   1%|          | 583/55000 [2:08:27<200:53:07, 13.29s/it, Loss=10.9054, Denoising=10.7316]Training:   1%|          | 584/55000 [2:08:41<204:55:43, 13.56s/it, Loss=10.9054, Denoising=10.7316]Training:   1%|          | 584/55000 [2:08:42<204:55:43, 13.56s/it, Loss=10.8241, Denoising=10.6530]Training:   1%|          | 585/55000 [2:08:51<186:47:05, 12.36s/it, Loss=10.8241, Denoising=10.6530]Training:   1%|          | 585/55000 [2:08:51<186:47:05, 12.36s/it, Loss=10.5919, Denoising=10.4287]Training:   1%|          | 586/55000 [2:09:05<195:01:30, 12.90s/it, Loss=10.5919, Denoising=10.4287]Training:   1%|          | 586/55000 [2:09:05<195:01:30, 12.90s/it, Loss=10.4822, Denoising=10.3104]Training:   1%|          | 587/55000 [2:09:20<202:41:29, 13.41s/it, Loss=10.4822, Denoising=10.3104]Training:   1%|          | 587/55000 [2:09:20<202:41:29, 13.41s/it, Loss=10.8704, Denoising=10.6913]Training:   1%|          | 588/55000 [2:09:32<196:18:43, 12.99s/it, Loss=10.8704, Denoising=10.6913]Training:   1%|          | 588/55000 [2:09:32<196:18:43, 12.99s/it, Loss=10.3815, Denoising=10.2089]Training:   1%|          | 589/55000 [2:09:46<201:41:37, 13.34s/it, Loss=10.3815, Denoising=10.2089]Training:   1%|          | 589/55000 [2:09:46<201:41:37, 13.34s/it, Loss=10.6195, Denoising=10.4542]Training:   1%|          | 590/55000 [2:10:01<207:16:56, 13.71s/it, Loss=10.6195, Denoising=10.4542]Training:   1%|          | 590/55000 [2:10:01<207:16:56, 13.71s/it, Loss=10.6031, Denoising=10.4374]Training:   1%|          | 591/55000 [2:10:14<204:25:34, 13.53s/it, Loss=10.6031, Denoising=10.4374]Training:   1%|          | 591/55000 [2:10:14<204:25:34, 13.53s/it, Loss=10.4742, Denoising=10.3030]Training:   1%|          | 592/55000 [2:10:28<210:34:20, 13.93s/it, Loss=10.4742, Denoising=10.3030]Training:   1%|          | 592/55000 [2:10:29<210:34:20, 13.93s/it, Loss=10.5540, Denoising=10.4034]Training:   1%|          | 593/55000 [2:10:41<202:09:19, 13.38s/it, Loss=10.5540, Denoising=10.4034]Training:   1%|          | 593/55000 [2:10:41<202:09:19, 13.38s/it, Loss=10.7465, Denoising=10.5657]Training:   1%|          | 594/55000 [2:10:52<194:35:18, 12.88s/it, Loss=10.7465, Denoising=10.5657]Training:   1%|          | 594/55000 [2:10:52<194:35:18, 12.88s/it, Loss=10.7882, Denoising=10.6253]Training:   1%|          | 595/55000 [2:11:05<195:52:44, 12.96s/it, Loss=10.7882, Denoising=10.6253]Training:   1%|          | 595/55000 [2:11:06<195:52:44, 12.96s/it, Loss=10.4786, Denoising=10.3139]Training:   1%|          | 596/55000 [2:11:17<190:42:11, 12.62s/it, Loss=10.4786, Denoising=10.3139]Training:   1%|          | 596/55000 [2:11:17<190:42:11, 12.62s/it, Loss=10.4272, Denoising=10.2580]Training:   1%|          | 597/55000 [2:11:31<197:46:57, 13.09s/it, Loss=10.4272, Denoising=10.2580]Training:   1%|          | 597/55000 [2:11:32<197:46:57, 13.09s/it, Loss=10.4602, Denoising=10.2947]Training:   1%|          | 598/55000 [2:11:45<198:52:58, 13.16s/it, Loss=10.4602, Denoising=10.2947]Training:   1%|          | 598/55000 [2:11:45<198:52:58, 13.16s/it, Loss=10.3586, Denoising=10.1985]Training:   1%|          | 599/55000 [2:11:58<197:01:54, 13.04s/it, Loss=10.3586, Denoising=10.1985]Training:   1%|          | 599/55000 [2:11:58<197:01:54, 13.04s/it, Loss=10.7062, Denoising=10.5337]Training:   1%|          | 600/55000 [2:12:13<205:49:57, 13.62s/it, Loss=10.7062, Denoising=10.5337]Training:   1%|          | 600/55000 [2:12:13<205:49:57, 13.62s/it, Loss=11.0402, Denoising=10.8582]
--- PREVIEW (Step 600 | t=924) ---
Logit Range: [-1.09, 1.91]
Target: ### User:
The capacity of Karson's home library is 400 books. If he currently has 120 books, how many more books does he have to buy to make his library 90% full?

### Assistant Thinking:
Let me work ...
Predict:  ### user:
 The capacity of Karson's home library is 400 books. if he currently has 120 books, how many more books does he have to buy to make his library 90% full?

### Assistant thinking:
 Let me wo...
--------------------------------------

âš¡ Thunder PrefixLM: Diffusion layers and custom embeddings saved to ./thunder_prefixlm_llama/checkpoint-600

âš¡ Checkpoint saved to ./thunder_prefixlm_llama/checkpoint-600
Training:   1%|          | 601/55000 [2:12:28<213:34:38, 14.13s/it, Loss=11.0402, Denoising=10.8582]Training:   1%|          | 601/55000 [2:12:28<213:34:38, 14.13s/it, Loss=10.6996, Denoising=10.5236]Training:   1%|          | 602/55000 [2:12:39<198:48:48, 13.16s/it, Loss=10.6996, Denoising=10.5236]Training:   1%|          | 602/55000 [2:12:39<198:48:48, 13.16s/it, Loss=10.5578, Denoising=10.3914]Training:   1%|          | 603/55000 [2:12:52<201:36:37, 13.34s/it, Loss=10.5578, Denoising=10.3914]Training:   1%|          | 603/55000 [2:12:53<201:36:37, 13.34s/it, Loss=10.5635, Denoising=10.4093]Training:   1%|          | 604/55000 [2:13:06<202:57:33, 13.43s/it, Loss=10.5635, Denoising=10.4093]Training:   1%|          | 604/55000 [2:13:06<202:57:33, 13.43s/it, Loss=10.3181, Denoising=10.1611]Training:   1%|          | 605/55000 [2:13:20<204:11:55, 13.51s/it, Loss=10.3181, Denoising=10.1611]Training:   1%|          | 605/55000 [2:13:20<204:11:55, 13.51s/it, Loss=10.4079, Denoising=10.2353]Training:   1%|          | 606/55000 [2:13:31<193:03:41, 12.78s/it, Loss=10.4079, Denoising=10.2353]Training:   1%|          | 606/55000 [2:13:31<193:03:41, 12.78s/it, Loss=10.4636, Denoising=10.3056]Training:   1%|          | 607/55000 [2:13:45<199:27:44, 13.20s/it, Loss=10.4636, Denoising=10.3056]Training:   1%|          | 607/55000 [2:13:45<199:27:44, 13.20s/it, Loss=10.7311, Denoising=10.5680]Training:   1%|          | 608/55000 [2:14:00<205:45:50, 13.62s/it, Loss=10.7311, Denoising=10.5680]Training:   1%|          | 608/55000 [2:14:00<205:45:50, 13.62s/it, Loss=10.6729, Denoising=10.4968]Training:   1%|          | 609/55000 [2:14:12<199:51:36, 13.23s/it, Loss=10.6729, Denoising=10.4968]Training:   1%|          | 609/55000 [2:14:12<199:51:36, 13.23s/it, Loss=10.6614, Denoising=10.4916]Training:   1%|          | 610/55000 [2:14:25<199:49:31, 13.23s/it, Loss=10.6614, Denoising=10.4916]Training:   1%|          | 610/55000 [2:14:25<199:49:31, 13.23s/it, Loss=10.8161, Denoising=10.6432]Training:   1%|          | 611/55000 [2:14:37<193:22:03, 12.80s/it, Loss=10.8161, Denoising=10.6432]Training:   1%|          | 611/55000 [2:14:37<193:22:03, 12.80s/it, Loss=10.5870, Denoising=10.4182]Training:   1%|          | 612/55000 [2:14:50<192:12:36, 12.72s/it, Loss=10.5870, Denoising=10.4182]Training:   1%|          | 612/55000 [2:14:50<192:12:36, 12.72s/it, Loss=10.4405, Denoising=10.2730]Training:   1%|          | 613/55000 [2:15:03<195:11:56, 12.92s/it, Loss=10.4405, Denoising=10.2730]Training:   1%|          | 613/55000 [2:15:03<195:11:56, 12.92s/it, Loss=10.5298, Denoising=10.3656]Training:   1%|          | 614/55000 [2:15:14<187:41:28, 12.42s/it, Loss=10.5298, Denoising=10.3656]Training:   1%|          | 614/55000 [2:15:14<187:41:28, 12.42s/it, Loss=10.5125, Denoising=10.3466]Training:   1%|          | 615/55000 [2:15:27<190:46:44, 12.63s/it, Loss=10.5125, Denoising=10.3466]Training:   1%|          | 615/55000 [2:15:28<190:46:44, 12.63s/it, Loss=10.2979, Denoising=10.1244]Training:   1%|          | 616/55000 [2:15:41<195:57:34, 12.97s/it, Loss=10.2979, Denoising=10.1244]Training:   1%|          | 616/55000 [2:15:41<195:57:34, 12.97s/it, Loss=10.2955, Denoising=10.1211]Training:   1%|          | 617/55000 [2:15:55<199:37:38, 13.21s/it, Loss=10.2955, Denoising=10.1211]Training:   1%|          | 617/55000 [2:15:55<199:37:38, 13.21s/it, Loss=10.4809, Denoising=10.3113]Training:   1%|          | 618/55000 [2:16:09<202:05:15, 13.38s/it, Loss=10.4809, Denoising=10.3113]Training:   1%|          | 618/55000 [2:16:09<202:05:15, 13.38s/it, Loss=10.4875, Denoising=10.3160]Training:   1%|          | 619/55000 [2:16:22<201:16:17, 13.32s/it, Loss=10.4875, Denoising=10.3160]Training:   1%|          | 619/55000 [2:16:22<201:16:17, 13.32s/it, Loss=10.6186, Denoising=10.4535]Training:   1%|          | 620/55000 [2:16:34<198:13:38, 13.12s/it, Loss=10.6186, Denoising=10.4535]Training:   1%|          | 620/55000 [2:16:35<198:13:38, 13.12s/it, Loss=10.3044, Denoising=10.1320]
--- PREVIEW (Step 620 | t=314) ---
Logit Range: [-0.98, 1.94]
Target: ### User:
Produce an article summary of the following news article: Hello, trifecta. After scoring the largest midnight debut and opening day, "Harry Potter and the Deathly Hallows -- Part 2" also lan...
Predict: ,### user:
Produce an article summary of the following news article: Hello, trifecta. after scoring the largest midnight debut and opening day, " Harry Potter and the Deathly Hallows -- Part 2" also l...
--------------------------------------

Training:   1%|          | 621/55000 [2:16:49<206:42:13, 13.68s/it, Loss=10.3044, Denoising=10.1320]Training:   1%|          | 621/55000 [2:16:50<206:42:13, 13.68s/it, Loss=10.8669, Denoising=10.7088]Training:   1%|          | 622/55000 [2:17:03<207:21:44, 13.73s/it, Loss=10.8669, Denoising=10.7088]Training:   1%|          | 622/55000 [2:17:03<207:21:44, 13.73s/it, Loss=10.4007, Denoising=10.2264]Training:   1%|          | 623/55000 [2:17:17<209:21:37, 13.86s/it, Loss=10.4007, Denoising=10.2264]Training:   1%|          | 623/55000 [2:17:18<209:21:37, 13.86s/it, Loss=10.2976, Denoising=10.1288]Training:   1%|          | 624/55000 [2:17:32<211:06:46, 13.98s/it, Loss=10.2976, Denoising=10.1288]Training:   1%|          | 624/55000 [2:17:32<211:06:46, 13.98s/it, Loss=10.3361, Denoising=10.1611]Training:   1%|          | 625/55000 [2:17:44<203:20:10, 13.46s/it, Loss=10.3361, Denoising=10.1611]Training:   1%|          | 625/55000 [2:17:44<203:20:10, 13.46s/it, Loss=10.3643, Denoising=10.1938]Training:   1%|          | 626/55000 [2:17:56<198:50:11, 13.16s/it, Loss=10.3643, Denoising=10.1938]Training:   1%|          | 626/55000 [2:17:57<198:50:11, 13.16s/it, Loss=10.3514, Denoising=10.1785]Training:   1%|          | 627/55000 [2:18:10<198:41:20, 13.16s/it, Loss=10.3514, Denoising=10.1785]Training:   1%|          | 627/55000 [2:18:10<198:41:20, 13.16s/it, Loss=10.3754, Denoising=10.2074]Training:   1%|          | 628/55000 [2:18:24<205:08:08, 13.58s/it, Loss=10.3754, Denoising=10.2074]Training:   1%|          | 628/55000 [2:18:24<205:08:08, 13.58s/it, Loss=10.8416, Denoising=10.6808]Training:   1%|          | 629/55000 [2:18:37<202:16:52, 13.39s/it, Loss=10.8416, Denoising=10.6808]Training:   1%|          | 629/55000 [2:18:37<202:16:52, 13.39s/it, Loss=10.2690, Denoising=10.0967]Training:   1%|          | 630/55000 [2:18:50<199:32:19, 13.21s/it, Loss=10.2690, Denoising=10.0967]Training:   1%|          | 630/55000 [2:18:50<199:32:19, 13.21s/it, Loss=10.4117, Denoising=10.2526]Training:   1%|          | 631/55000 [2:19:02<196:13:51, 12.99s/it, Loss=10.4117, Denoising=10.2526]Training:   1%|          | 631/55000 [2:19:03<196:13:51, 12.99s/it, Loss=10.5970, Denoising=10.4300]Training:   1%|          | 632/55000 [2:19:15<194:15:45, 12.86s/it, Loss=10.5970, Denoising=10.4300]Training:   1%|          | 632/55000 [2:19:15<194:15:45, 12.86s/it, Loss=10.5311, Denoising=10.3665]Training:   1%|          | 633/55000 [2:19:27<188:43:58, 12.50s/it, Loss=10.5311, Denoising=10.3665]Training:   1%|          | 633/55000 [2:19:27<188:43:58, 12.50s/it, Loss=10.4213, Denoising=10.2525]Training:   1%|          | 634/55000 [2:19:41<199:33:46, 13.21s/it, Loss=10.4213, Denoising=10.2525]Training:   1%|          | 634/55000 [2:19:42<199:33:46, 13.21s/it, Loss=10.4386, Denoising=10.2664]Training:   1%|          | 635/55000 [2:19:54<197:08:12, 13.05s/it, Loss=10.4386, Denoising=10.2664]Training:   1%|          | 635/55000 [2:19:54<197:08:12, 13.05s/it, Loss=10.4930, Denoising=10.3287]Training:   1%|          | 636/55000 [2:20:07<193:50:59, 12.84s/it, Loss=10.4930, Denoising=10.3287]Training:   1%|          | 636/55000 [2:20:07<193:50:59, 12.84s/it, Loss=10.3301, Denoising=10.1632]Training:   1%|          | 637/55000 [2:20:16<180:10:00, 11.93s/it, Loss=10.3301, Denoising=10.1632]Training:   1%|          | 637/55000 [2:20:16<180:10:00, 11.93s/it, Loss=10.5052, Denoising=10.3321]Training:   1%|          | 638/55000 [2:20:30<189:34:59, 12.55s/it, Loss=10.5052, Denoising=10.3321]Training:   1%|          | 638/55000 [2:20:31<189:34:59, 12.55s/it, Loss=10.5793, Denoising=10.4117]
[WARNING] NaN loss detected! Skipping batch.
Training:   1%|          | 639/55000 [2:20:42<186:19:25, 12.34s/it, Loss=10.5793, Denoising=10.4117]Training:   1%|          | 639/55000 [2:20:42<186:19:25, 12.34s/it, Loss=10.6492, Denoising=10.4730]Training:   1%|          | 640/55000 [2:20:53<179:53:04, 11.91s/it, Loss=10.6492, Denoising=10.4730]Training:   1%|          | 640/55000 [2:20:53<179:53:04, 11.91s/it, Loss=10.5621, Denoising=10.4040]
--- PREVIEW (Step 640 | t=739) ---
Logit Range: [-1.04, 1.92]
Target: ### User:
Compute the range of $y=|x+7|-|x-2|$.

### Assistant:
If $x<-7$, both $x+7$ and $x-2$ are negative.  So  $$y=-(x+7)-(-x+2)=-9.$$ If $x\geq 2$, both $x+7$ and $x-2$ are nonnegative.  So  $$y=...
Predict: ,### user:
Compute the range of $y =|x+7|-|x-2|$.

### Assistant:
 if $x<-7$ both $x+7$ and $x-2$ are negative.  So  $y =-x+7)-(-x+2)=-9.$$ if $x\geq 2$ both $x+7$ and $x-2$ are non negative.  so  $y=...
--------------------------------------

Training:   1%|          | 641/55000 [2:21:06<183:34:50, 12.16s/it, Loss=10.5621, Denoising=10.4040]Training:   1%|          | 641/55000 [2:21:06<183:34:50, 12.16s/it, Loss=10.4063, Denoising=10.2351]Training:   1%|          | 642/55000 [2:21:19<190:25:28, 12.61s/it, Loss=10.4063, Denoising=10.2351]Training:   1%|          | 642/55000 [2:21:20<190:25:28, 12.61s/it, Loss=10.7194, Denoising=10.5435]Training:   1%|          | 643/55000 [2:21:34<198:22:24, 13.14s/it, Loss=10.7194, Denoising=10.5435]Training:   1%|          | 643/55000 [2:21:34<198:22:24, 13.14s/it, Loss=10.6742, Denoising=10.4974]Training:   1%|          | 644/55000 [2:21:48<203:02:36, 13.45s/it, Loss=10.6742, Denoising=10.4974]Training:   1%|          | 644/55000 [2:21:48<203:02:36, 13.45s/it, Loss=10.6138, Denoising=10.4489]Training:   1%|          | 645/55000 [2:22:02<203:19:34, 13.47s/it, Loss=10.6138, Denoising=10.4489]Training:   1%|          | 645/55000 [2:22:02<203:19:34, 13.47s/it, Loss=10.4541, Denoising=10.2827]Training:   1%|          | 646/55000 [2:22:14<199:56:56, 13.24s/it, Loss=10.4541, Denoising=10.2827]Training:   1%|          | 646/55000 [2:22:14<199:56:56, 13.24s/it, Loss=10.6693, Denoising=10.5131]Training:   1%|          | 647/55000 [2:22:27<195:51:44, 12.97s/it, Loss=10.6693, Denoising=10.5131]Training:   1%|          | 647/55000 [2:22:27<195:51:44, 12.97s/it, Loss=11.2797, Denoising=11.1065]Training:   1%|          | 648/55000 [2:22:40<198:56:54, 13.18s/it, Loss=11.2797, Denoising=11.1065]Training:   1%|          | 648/55000 [2:22:40<198:56:54, 13.18s/it, Loss=10.4912, Denoising=10.3220]Training:   1%|          | 649/55000 [2:22:51<186:49:01, 12.37s/it, Loss=10.4912, Denoising=10.3220]Training:   1%|          | 649/55000 [2:22:51<186:49:01, 12.37s/it, Loss=10.3791, Denoising=10.2165]Training:   1%|          | 650/55000 [2:23:04<189:06:48, 12.53s/it, Loss=10.3791, Denoising=10.2165]Training:   1%|          | 650/55000 [2:23:04<189:06:48, 12.53s/it, Loss=10.6330, Denoising=10.4575]Training:   1%|          | 651/55000 [2:23:16<189:19:41, 12.54s/it, Loss=10.6330, Denoising=10.4575]Training:   1%|          | 651/55000 [2:23:16<189:19:41, 12.54s/it, Loss=10.2556, Denoising=10.0861]Training:   1%|          | 652/55000 [2:23:30<194:50:23, 12.91s/it, Loss=10.2556, Denoising=10.0861]Training:   1%|          | 652/55000 [2:23:30<194:50:23, 12.91s/it, Loss=10.8316, Denoising=10.6750]Training:   1%|          | 653/55000 [2:23:42<190:43:33, 12.63s/it, Loss=10.8316, Denoising=10.6750]Training:   1%|          | 653/55000 [2:23:42<190:43:33, 12.63s/it, Loss=10.4853, Denoising=10.3252]Training:   1%|          | 654/55000 [2:23:55<191:27:30, 12.68s/it, Loss=10.4853, Denoising=10.3252]Training:   1%|          | 654/55000 [2:23:55<191:27:30, 12.68s/it, Loss=10.3464, Denoising=10.1793]Training:   1%|          | 655/55000 [2:24:08<192:53:35, 12.78s/it, Loss=10.3464, Denoising=10.1793]Training:   1%|          | 655/55000 [2:24:08<192:53:35, 12.78s/it, Loss=10.3380, Denoising=10.1773]Training:   1%|          | 656/55000 [2:24:17<177:02:33, 11.73s/it, Loss=10.3380, Denoising=10.1773]Training:   1%|          | 656/55000 [2:24:17<177:02:33, 11.73s/it, Loss=10.3291, Denoising=10.1689]Training:   1%|          | 657/55000 [2:24:31<187:34:15, 12.43s/it, Loss=10.3291, Denoising=10.1689]Training:   1%|          | 657/55000 [2:24:31<187:34:15, 12.43s/it, Loss=10.8851, Denoising=10.7078]Training:   1%|          | 658/55000 [2:24:44<187:53:48, 12.45s/it, Loss=10.8851, Denoising=10.7078]Training:   1%|          | 658/55000 [2:24:44<187:53:48, 12.45s/it, Loss=10.4663, Denoising=10.2998]Training:   1%|          | 659/55000 [2:24:57<191:12:36, 12.67s/it, Loss=10.4663, Denoising=10.2998]Training:   1%|          | 659/55000 [2:24:57<191:12:36, 12.67s/it, Loss=10.4025, Denoising=10.2248]Training:   1%|          | 660/55000 [2:25:11<197:32:51, 13.09s/it, Loss=10.4025, Denoising=10.2248]Training:   1%|          | 660/55000 [2:25:11<197:32:51, 13.09s/it, Loss=10.4236, Denoising=10.2528]
--- PREVIEW (Step 660 | t=193) ---
Logit Range: [-1.10, 1.77]
Target: ### User:
Q: If I tell you that Gravity pulls objects toward celestial bodies, and ask you the question "what does gravity pull objects closer to?", is the correct answer "something to move"?

Options...
Predict: ,### user:
Q: if I tell you that Gravity pull objects toward celestial bodies, and ask you the question " what does gravity pull objects closer to?", is the correct answer " something to move"?

 opti...
--------------------------------------

Training:   1%|          | 661/55000 [2:25:24<200:05:08, 13.26s/it, Loss=10.4236, Denoising=10.2528]Training:   1%|          | 661/55000 [2:25:25<200:05:08, 13.26s/it, Loss=10.6306, Denoising=10.4491]Training:   1%|          | 662/55000 [2:25:36<193:31:01, 12.82s/it, Loss=10.6306, Denoising=10.4491]Training:   1%|          | 662/55000 [2:25:36<193:31:01, 12.82s/it, Loss=10.7415, Denoising=10.5487]Training:   1%|          | 663/55000 [2:25:50<199:38:49, 13.23s/it, Loss=10.7415, Denoising=10.5487]Training:   1%|          | 663/55000 [2:25:51<199:38:49, 13.23s/it, Loss=10.4878, Denoising=10.3150]Training:   1%|          | 664/55000 [2:26:01<188:40:18, 12.50s/it, Loss=10.4878, Denoising=10.3150]Training:   1%|          | 664/55000 [2:26:01<188:40:18, 12.50s/it, Loss=10.3837, Denoising=10.2108]Training:   1%|          | 665/55000 [2:26:15<196:16:16, 13.00s/it, Loss=10.3837, Denoising=10.2108]Training:   1%|          | 665/55000 [2:26:16<196:16:16, 13.00s/it, Loss=10.4328, Denoising=10.2629]Training:   1%|          | 666/55000 [2:26:29<196:30:55, 13.02s/it, Loss=10.4328, Denoising=10.2629]Training:   1%|          | 666/55000 [2:26:29<196:30:55, 13.02s/it, Loss=10.7154, Denoising=10.5385]Training:   1%|          | 667/55000 [2:26:40<190:31:35, 12.62s/it, Loss=10.7154, Denoising=10.5385]Training:   1%|          | 667/55000 [2:26:40<190:31:35, 12.62s/it, Loss=10.9234, Denoising=10.7550]Training:   1%|          | 668/55000 [2:26:53<189:33:33, 12.56s/it, Loss=10.9234, Denoising=10.7550]Training:   1%|          | 668/55000 [2:26:53<189:33:33, 12.56s/it, Loss=11.0536, Denoising=10.8723]
[WARNING] NaN loss detected! Skipping batch.
Training:   1%|          | 669/55000 [2:27:05<190:50:41, 12.65s/it, Loss=11.0536, Denoising=10.8723]Training:   1%|          | 669/55000 [2:27:06<190:50:41, 12.65s/it, Loss=10.4844, Denoising=10.3154]Training:   1%|          | 670/55000 [2:27:18<189:46:28, 12.57s/it, Loss=10.4844, Denoising=10.3154]Training:   1%|          | 670/55000 [2:27:18<189:46:28, 12.57s/it, Loss=10.3390, Denoising=10.1709]Training:   1%|          | 671/55000 [2:27:29<183:35:15, 12.17s/it, Loss=10.3390, Denoising=10.1709]Training:   1%|          | 671/55000 [2:27:29<183:35:15, 12.17s/it, Loss=10.4550, Denoising=10.2885]Training:   1%|          | 672/55000 [2:27:43<190:29:11, 12.62s/it, Loss=10.4550, Denoising=10.2885]Training:   1%|          | 672/55000 [2:27:43<190:29:11, 12.62s/it, Loss=10.4751, Denoising=10.3063]Training:   1%|          | 673/55000 [2:27:56<193:16:56, 12.81s/it, Loss=10.4751, Denoising=10.3063]Training:   1%|          | 673/55000 [2:27:56<193:16:56, 12.81s/it, Loss=10.5100, Denoising=10.3392]Training:   1%|          | 674/55000 [2:28:07<184:53:49, 12.25s/it, Loss=10.5100, Denoising=10.3392]Training:   1%|          | 674/55000 [2:28:07<184:53:49, 12.25s/it, Loss=10.7025, Denoising=10.5309]Training:   1%|          | 675/55000 [2:28:20<189:15:21, 12.54s/it, Loss=10.7025, Denoising=10.5309]Training:   1%|          | 675/55000 [2:28:20<189:15:21, 12.54s/it, Loss=10.5465, Denoising=10.3803]Training:   1%|          | 676/55000 [2:28:35<200:15:29, 13.27s/it, Loss=10.5465, Denoising=10.3803]Training:   1%|          | 676/55000 [2:28:35<200:15:29, 13.27s/it, Loss=10.5541, Denoising=10.3867]Training:   1%|          | 677/55000 [2:28:47<192:39:07, 12.77s/it, Loss=10.5541, Denoising=10.3867]Training:   1%|          | 677/55000 [2:28:47<192:39:07, 12.77s/it, Loss=10.3782, Denoising=10.1974]Training:   1%|          | 678/55000 [2:28:59<192:33:27, 12.76s/it, Loss=10.3782, Denoising=10.1974]Training:   1%|          | 678/55000 [2:29:00<192:33:27, 12.76s/it, Loss=10.3964, Denoising=10.2174]Training:   1%|          | 679/55000 [2:29:14<202:35:53, 13.43s/it, Loss=10.3964, Denoising=10.2174]Training:   1%|          | 679/55000 [2:29:15<202:35:53, 13.43s/it, Loss=10.8054, Denoising=10.6361]Training:   1%|          | 680/55000 [2:29:28<201:05:02, 13.33s/it, Loss=10.8054, Denoising=10.6361]Training:   1%|          | 680/55000 [2:29:28<201:05:02, 13.33s/it, Loss=10.5145, Denoising=10.3478]
--- PREVIEW (Step 680 | t=404) ---
Logit Range: [-1.09, 1.95]
Target: ### Assistant:
You are an AI assistant. You will be given a task. You must generate a detailed and long answer.

### User:
Multi-choice question: Same meaning?
Descendant of many other people, his fat...
Predict: ,### Assistant:
You are an AI assistant. You will be given a task. You must generate a detailed and long answer.

### user:
 multi choice question: same meaning?
Descendant of many other people, his f...
--------------------------------------

Training:   1%|          | 681/55000 [2:29:42<203:55:22, 13.52s/it, Loss=10.5145, Denoising=10.3478]Training:   1%|          | 681/55000 [2:29:42<203:55:22, 13.52s/it, Loss=10.5651, Denoising=10.4023]Training:   1%|          | 682/55000 [2:29:52<188:48:59, 12.51s/it, Loss=10.5651, Denoising=10.4023]Training:   1%|          | 682/55000 [2:29:52<188:48:59, 12.51s/it, Loss=10.4406, Denoising=10.2764]Training:   1%|          | 683/55000 [2:30:05<193:59:40, 12.86s/it, Loss=10.4406, Denoising=10.2764]Training:   1%|          | 683/55000 [2:30:06<193:59:40, 12.86s/it, Loss=10.2662, Denoising=10.1063]Training:   1%|          | 684/55000 [2:30:20<200:01:40, 13.26s/it, Loss=10.2662, Denoising=10.1063]Training:   1%|          | 684/55000 [2:30:20<200:01:40, 13.26s/it, Loss=10.7124, Denoising=10.5369]Training:   1%|          | 685/55000 [2:30:33<199:31:02, 13.22s/it, Loss=10.7124, Denoising=10.5369]Training:   1%|          | 685/55000 [2:30:33<199:31:02, 13.22s/it, Loss=10.5884, Denoising=10.4269]Training:   1%|          | 686/55000 [2:30:46<199:47:44, 13.24s/it, Loss=10.5884, Denoising=10.4269]Training:   1%|          | 686/55000 [2:30:46<199:47:44, 13.24s/it, Loss=10.4350, Denoising=10.2702]Training:   1%|          | 687/55000 [2:31:01<208:51:40, 13.84s/it, Loss=10.4350, Denoising=10.2702]Training:   1%|          | 687/55000 [2:31:01<208:51:40, 13.84s/it, Loss=10.6843, Denoising=10.5160]Training:   1%|â–         | 688/55000 [2:31:14<204:16:07, 13.54s/it, Loss=10.6843, Denoising=10.5160]Training:   1%|â–         | 688/55000 [2:31:14<204:16:07, 13.54s/it, Loss=10.4332, Denoising=10.2620]Training:   1%|â–         | 689/55000 [2:31:28<207:08:34, 13.73s/it, Loss=10.4332, Denoising=10.2620]Training:   1%|â–         | 689/55000 [2:31:28<207:08:34, 13.73s/it, Loss=10.5288, Denoising=10.3632]Training:   1%|â–         | 690/55000 [2:31:39<192:44:12, 12.78s/it, Loss=10.5288, Denoising=10.3632]Training:   1%|â–         | 690/55000 [2:31:39<192:44:12, 12.78s/it, Loss=10.3781, Denoising=10.2114]Training:   1%|â–         | 691/55000 [2:31:52<195:26:27, 12.96s/it, Loss=10.3781, Denoising=10.2114]Training:   1%|â–         | 691/55000 [2:31:52<195:26:27, 12.96s/it, Loss=10.2989, Denoising=10.1279]Training:   1%|â–         | 692/55000 [2:32:06<200:56:34, 13.32s/it, Loss=10.2989, Denoising=10.1279]Training:   1%|â–         | 692/55000 [2:32:07<200:56:34, 13.32s/it, Loss=10.5467, Denoising=10.3892]Training:   1%|â–         | 693/55000 [2:32:19<199:49:54, 13.25s/it, Loss=10.5467, Denoising=10.3892]Training:   1%|â–         | 693/55000 [2:32:20<199:49:54, 13.25s/it, Loss=10.4745, Denoising=10.3111]Training:   1%|â–         | 694/55000 [2:32:33<202:54:51, 13.45s/it, Loss=10.4745, Denoising=10.3111]Training:   1%|â–         | 694/55000 [2:32:34<202:54:51, 13.45s/it, Loss=10.6841, Denoising=10.5148]Training:   1%|â–         | 695/55000 [2:32:46<199:34:51, 13.23s/it, Loss=10.6841, Denoising=10.5148]Training:   1%|â–         | 695/55000 [2:32:46<199:34:51, 13.23s/it, Loss=10.3823, Denoising=10.2155]Training:   1%|â–         | 696/55000 [2:32:58<192:51:54, 12.79s/it, Loss=10.3823, Denoising=10.2155]Training:   1%|â–         | 696/55000 [2:32:58<192:51:54, 12.79s/it, Loss=10.4457, Denoising=10.2719]Training:   1%|â–         | 697/55000 [2:33:09<186:08:58, 12.34s/it, Loss=10.4457, Denoising=10.2719]Training:   1%|â–         | 697/55000 [2:33:09<186:08:58, 12.34s/it, Loss=10.3678, Denoising=10.1959]Training:   1%|â–         | 698/55000 [2:33:23<191:29:54, 12.70s/it, Loss=10.3678, Denoising=10.1959]Training:   1%|â–         | 698/55000 [2:33:23<191:29:54, 12.70s/it, Loss=10.6177, Denoising=10.4387]Training:   1%|â–         | 699/55000 [2:33:35<188:36:54, 12.50s/it, Loss=10.6177, Denoising=10.4387]Training:   1%|â–         | 699/55000 [2:33:35<188:36:54, 12.50s/it, Loss=10.5953, Denoising=10.4317]Training:   1%|â–         | 700/55000 [2:33:47<185:32:20, 12.30s/it, Loss=10.5953, Denoising=10.4317]Training:   1%|â–         | 700/55000 [2:33:47<185:32:20, 12.30s/it, Loss=10.4491, Denoising=10.2882]
--- PREVIEW (Step 700 | t=821) ---
Logit Range: [-1.00, 1.94]
Target: ### User:
Summarize the following proposed legislation (bill): SECTION 1. SHORT TITLE.

    This Act may be cited as the ``Computer Security Enhancement Act of 
1997''.

SEC. 2. FINDINGS AND PURPOSES....
Predict:  ### user:
 Summarize the following proposed legislation (bill): section 1. short title.

    This Act may be cited as the ``Computer security Enhancement Act of 
1997''.

SEC. 2. FINDings AND purpose...
--------------------------------------

Training:   1%|â–         | 701/55000 [2:34:02<197:44:00, 13.11s/it, Loss=10.4491, Denoising=10.2882]Training:   1%|â–         | 701/55000 [2:34:02<197:44:00, 13.11s/it, Loss=10.5837, Denoising=10.4154]Training:   1%|â–         | 702/55000 [2:34:14<197:06:51, 13.07s/it, Loss=10.5837, Denoising=10.4154]Training:   1%|â–         | 702/55000 [2:34:15<197:06:51, 13.07s/it, Loss=10.6907, Denoising=10.5224]Training:   1%|â–         | 703/55000 [2:34:28<198:18:35, 13.15s/it, Loss=10.6907, Denoising=10.5224]Training:   1%|â–         | 703/55000 [2:34:28<198:18:35, 13.15s/it, Loss=10.5029, Denoising=10.3275]Training:   1%|â–         | 704/55000 [2:34:41<200:43:59, 13.31s/it, Loss=10.5029, Denoising=10.3275]Training:   1%|â–         | 704/55000 [2:34:42<200:43:59, 13.31s/it, Loss=10.4520, Denoising=10.2799]Training:   1%|â–         | 705/55000 [2:34:55<202:58:59, 13.46s/it, Loss=10.4520, Denoising=10.2799]Training:   1%|â–         | 705/55000 [2:34:55<202:58:59, 13.46s/it, Loss=10.3507, Denoising=10.1889]Training:   1%|â–         | 706/55000 [2:35:07<193:58:45, 12.86s/it, Loss=10.3507, Denoising=10.1889]Training:   1%|â–         | 706/55000 [2:35:07<193:58:45, 12.86s/it, Loss=10.6124, Denoising=10.4495]Training:   1%|â–         | 707/55000 [2:35:18<185:04:34, 12.27s/it, Loss=10.6124, Denoising=10.4495]Training:   1%|â–         | 707/55000 [2:35:18<185:04:34, 12.27s/it, Loss=10.4097, Denoising=10.2347]Training:   1%|â–         | 708/55000 [2:35:30<184:14:25, 12.22s/it, Loss=10.4097, Denoising=10.2347]Training:   1%|â–         | 708/55000 [2:35:30<184:14:25, 12.22s/it, Loss=10.3790, Denoising=10.2053]Training:   1%|â–         | 709/55000 [2:35:43<189:30:03, 12.57s/it, Loss=10.3790, Denoising=10.2053]Training:   1%|â–         | 709/55000 [2:35:43<189:30:03, 12.57s/it, Loss=10.4802, Denoising=10.3098]Training:   1%|â–         | 710/55000 [2:35:57<195:08:38, 12.94s/it, Loss=10.4802, Denoising=10.3098]Training:   1%|â–         | 710/55000 [2:35:57<195:08:38, 12.94s/it, Loss=10.5720, Denoising=10.3979]Training:   1%|â–         | 711/55000 [2:36:10<193:38:24, 12.84s/it, Loss=10.5720, Denoising=10.3979]Training:   1%|â–         | 711/55000 [2:36:10<193:38:24, 12.84s/it, Loss=10.6652, Denoising=10.4856]Training:   1%|â–         | 712/55000 [2:36:21<185:13:54, 12.28s/it, Loss=10.6652, Denoising=10.4856]Training:   1%|â–         | 712/55000 [2:36:21<185:13:54, 12.28s/it, Loss=10.6913, Denoising=10.5220]Training:   1%|â–         | 713/55000 [2:36:33<185:56:19, 12.33s/it, Loss=10.6913, Denoising=10.5220]Training:   1%|â–         | 713/55000 [2:36:33<185:56:19, 12.33s/it, Loss=10.3722, Denoising=10.1939]Training:   1%|â–         | 714/55000 [2:36:46<187:56:21, 12.46s/it, Loss=10.3722, Denoising=10.1939]Training:   1%|â–         | 714/55000 [2:36:46<187:56:21, 12.46s/it, Loss=10.5329, Denoising=10.3586]Training:   1%|â–         | 715/55000 [2:37:00<193:52:59, 12.86s/it, Loss=10.5329, Denoising=10.3586]Training:   1%|â–         | 715/55000 [2:37:00<193:52:59, 12.86s/it, Loss=10.4725, Denoising=10.3046]Training:   1%|â–         | 716/55000 [2:37:13<195:46:37, 12.98s/it, Loss=10.4725, Denoising=10.3046]Training:   1%|â–         | 716/55000 [2:37:13<195:46:37, 12.98s/it, Loss=10.4881, Denoising=10.3212]Training:   1%|â–         | 717/55000 [2:37:28<204:18:39, 13.55s/it, Loss=10.4881, Denoising=10.3212]Training:   1%|â–         | 717/55000 [2:37:28<204:18:39, 13.55s/it, Loss=10.2888, Denoising=10.1152]Training:   1%|â–         | 718/55000 [2:37:43<214:24:45, 14.22s/it, Loss=10.2888, Denoising=10.1152]Training:   1%|â–         | 718/55000 [2:37:44<214:24:45, 14.22s/it, Loss=10.5480, Denoising=10.3787]Training:   1%|â–         | 719/55000 [2:37:58<214:31:22, 14.23s/it, Loss=10.5480, Denoising=10.3787]Training:   1%|â–         | 719/55000 [2:37:58<214:31:22, 14.23s/it, Loss=10.4014, Denoising=10.2397]Training:   1%|â–         | 720/55000 [2:38:12<215:44:09, 14.31s/it, Loss=10.4014, Denoising=10.2397]Training:   1%|â–         | 720/55000 [2:38:12<215:44:09, 14.31s/it, Loss=10.5222, Denoising=10.3569]
--- PREVIEW (Step 720 | t=816) ---
Logit Range: [-0.97, 1.94]
Target: ### User:
<p>I am learning Java NIO and trying to write a simple client/server application using selectors. So far I've got
a PwpConnectionManager class that acts as both a server listening for incomi...
Predict: ,### user:
<p I am learning Java NIO and trying to write a simple client server application using selectors. So far I've got
a Pwp connection manager class that acts as both a server listening for inc...
--------------------------------------

Training:   1%|â–         | 721/55000 [2:38:26<215:16:38, 14.28s/it, Loss=10.5222, Denoising=10.3569]Training:   1%|â–         | 721/55000 [2:38:27<215:16:38, 14.28s/it, Loss=10.4636, Denoising=10.2955]Training:   1%|â–         | 722/55000 [2:38:41<214:48:57, 14.25s/it, Loss=10.4636, Denoising=10.2955]Training:   1%|â–         | 722/55000 [2:38:41<214:48:57, 14.25s/it, Loss=10.5833, Denoising=10.4149]Training:   1%|â–         | 723/55000 [2:38:55<214:30:16, 14.23s/it, Loss=10.5833, Denoising=10.4149]Training:   1%|â–         | 723/55000 [2:38:55<214:30:16, 14.23s/it, Loss=10.4277, Denoising=10.2547]Training:   1%|â–         | 724/55000 [2:39:07<205:42:14, 13.64s/it, Loss=10.4277, Denoising=10.2547]Training:   1%|â–         | 724/55000 [2:39:07<205:42:14, 13.64s/it, Loss=10.6281, Denoising=10.4597]Training:   1%|â–         | 725/55000 [2:39:21<206:18:51, 13.68s/it, Loss=10.6281, Denoising=10.4597]Training:   1%|â–         | 725/55000 [2:39:21<206:18:51, 13.68s/it, Loss=10.6959, Denoising=10.5190]Training:   1%|â–         | 726/55000 [2:39:32<195:24:33, 12.96s/it, Loss=10.6959, Denoising=10.5190]Training:   1%|â–         | 726/55000 [2:39:32<195:24:33, 12.96s/it, Loss=10.5881, Denoising=10.4129]Training:   1%|â–         | 727/55000 [2:39:45<196:36:16, 13.04s/it, Loss=10.5881, Denoising=10.4129]Training:   1%|â–         | 727/55000 [2:39:46<196:36:16, 13.04s/it, Loss=10.3465, Denoising=10.1822]Training:   1%|â–         | 728/55000 [2:40:00<201:46:17, 13.38s/it, Loss=10.3465, Denoising=10.1822]Training:   1%|â–         | 728/55000 [2:40:00<201:46:17, 13.38s/it, Loss=10.6036, Denoising=10.4264]Training:   1%|â–         | 729/55000 [2:40:12<199:43:53, 13.25s/it, Loss=10.6036, Denoising=10.4264]Training:   1%|â–         | 729/55000 [2:40:13<199:43:53, 13.25s/it, Loss=10.4657, Denoising=10.2980]Training:   1%|â–         | 730/55000 [2:40:27<203:23:00, 13.49s/it, Loss=10.4657, Denoising=10.2980]Training:   1%|â–         | 730/55000 [2:40:27<203:23:00, 13.49s/it, Loss=10.4378, Denoising=10.2713]Training:   1%|â–         | 731/55000 [2:40:40<201:59:11, 13.40s/it, Loss=10.4378, Denoising=10.2713]Training:   1%|â–         | 731/55000 [2:40:40<201:59:11, 13.40s/it, Loss=10.6134, Denoising=10.4461]Training:   1%|â–         | 732/55000 [2:40:54<204:50:26, 13.59s/it, Loss=10.6134, Denoising=10.4461]Training:   1%|â–         | 732/55000 [2:40:54<204:50:26, 13.59s/it, Loss=10.7430, Denoising=10.5702]Training:   1%|â–         | 733/55000 [2:41:08<206:58:27, 13.73s/it, Loss=10.7430, Denoising=10.5702]Training:   1%|â–         | 733/55000 [2:41:08<206:58:27, 13.73s/it, Loss=10.4385, Denoising=10.2707]Training:   1%|â–         | 734/55000 [2:41:13<169:21:46, 11.24s/it, Loss=10.4385, Denoising=10.2707]Training:   1%|â–         | 734/55000 [2:41:13<169:21:46, 11.24s/it, Loss=10.3226, Denoising=10.1606]Training:   1%|â–         | 735/55000 [2:41:25<173:08:57, 11.49s/it, Loss=10.3226, Denoising=10.1606]Training:   1%|â–         | 735/55000 [2:41:25<173:08:57, 11.49s/it, Loss=10.4383, Denoising=10.2726]Training:   1%|â–         | 736/55000 [2:41:39<183:07:13, 12.15s/it, Loss=10.4383, Denoising=10.2726]Training:   1%|â–         | 736/55000 [2:41:39<183:07:13, 12.15s/it, Loss=10.5793, Denoising=10.4012]Training:   1%|â–         | 737/55000 [2:41:51<182:03:12, 12.08s/it, Loss=10.5793, Denoising=10.4012]Training:   1%|â–         | 737/55000 [2:41:51<182:03:12, 12.08s/it, Loss=10.5905, Denoising=10.4221]Training:   1%|â–         | 738/55000 [2:42:03<183:29:31, 12.17s/it, Loss=10.5905, Denoising=10.4221]Training:   1%|â–         | 738/55000 [2:42:03<183:29:31, 12.17s/it, Loss=10.3658, Denoising=10.2062]Training:   1%|â–         | 739/55000 [2:42:16<184:06:37, 12.21s/it, Loss=10.3658, Denoising=10.2062]Training:   1%|â–         | 739/55000 [2:42:16<184:06:37, 12.21s/it, Loss=10.9235, Denoising=10.7628]Training:   1%|â–         | 740/55000 [2:42:29<191:29:26, 12.70s/it, Loss=10.9235, Denoising=10.7628]Training:   1%|â–         | 740/55000 [2:42:30<191:29:26, 12.70s/it, Loss=10.2882, Denoising=10.1165]
--- PREVIEW (Step 740 | t=161) ---
Logit Range: [-0.97, 1.98]
Target: ### User:
League of Nations | Project Gutenberg Self-Publishing - eBooks | Read eBooks online
Title: League of Nations
Subject: World War I casualties, Permanent Court of International Justice, Britis...
Predict: ,### User:
League of Nations | Project Gutenberg self-Publishing - eBooks | Read eBooks online
 title: League of Nations
 subject: World War I casualties, Permanent Court of International Justice, Bri...
--------------------------------------

Training:   1%|â–         | 741/55000 [2:42:43<194:15:47, 12.89s/it, Loss=10.2882, Denoising=10.1165]Training:   1%|â–         | 741/55000 [2:42:43<194:15:47, 12.89s/it, Loss=10.7452, Denoising=10.5736]Training:   1%|â–         | 742/55000 [2:42:57<201:52:23, 13.39s/it, Loss=10.7452, Denoising=10.5736]Training:   1%|â–         | 742/55000 [2:42:58<201:52:23, 13.39s/it, Loss=10.6007, Denoising=10.4220]Training:   1%|â–         | 743/55000 [2:43:11<201:45:57, 13.39s/it, Loss=10.6007, Denoising=10.4220]Training:   1%|â–         | 743/55000 [2:43:11<201:45:57, 13.39s/it, Loss=10.3314, Denoising=10.1543]Training:   1%|â–         | 744/55000 [2:43:23<195:15:09, 12.96s/it, Loss=10.3314, Denoising=10.1543]Training:   1%|â–         | 744/55000 [2:43:23<195:15:09, 12.96s/it, Loss=10.5206, Denoising=10.3562]Training:   1%|â–         | 745/55000 [2:43:35<191:05:38, 12.68s/it, Loss=10.5206, Denoising=10.3562]Training:   1%|â–         | 745/55000 [2:43:35<191:05:38, 12.68s/it, Loss=10.5521, Denoising=10.3851]Training:   1%|â–         | 746/55000 [2:43:48<196:04:41, 13.01s/it, Loss=10.5521, Denoising=10.3851]Training:   1%|â–         | 746/55000 [2:43:49<196:04:41, 13.01s/it, Loss=10.5279, Denoising=10.3686]Training:   1%|â–         | 747/55000 [2:44:01<192:44:56, 12.79s/it, Loss=10.5279, Denoising=10.3686]Training:   1%|â–         | 747/55000 [2:44:01<192:44:56, 12.79s/it, Loss=10.7084, Denoising=10.5342]Training:   1%|â–         | 748/55000 [2:44:12<185:23:20, 12.30s/it, Loss=10.7084, Denoising=10.5342]Training:   1%|â–         | 748/55000 [2:44:12<185:23:20, 12.30s/it, Loss=10.4323, Denoising=10.2718]Training:   1%|â–         | 749/55000 [2:44:24<183:39:40, 12.19s/it, Loss=10.4323, Denoising=10.2718]Training:   1%|â–         | 749/55000 [2:44:24<183:39:40, 12.19s/it, Loss=10.5604, Denoising=10.3919]Training:   1%|â–         | 750/55000 [2:44:37<190:06:58, 12.62s/it, Loss=10.5604, Denoising=10.3919]Training:   1%|â–         | 750/55000 [2:44:38<190:06:58, 12.62s/it, Loss=10.7156, Denoising=10.5376]Training:   1%|â–         | 751/55000 [2:44:50<187:40:51, 12.45s/it, Loss=10.7156, Denoising=10.5376]Training:   1%|â–         | 751/55000 [2:44:50<187:40:51, 12.45s/it, Loss=10.7362, Denoising=10.5773]Training:   1%|â–         | 752/55000 [2:45:02<187:51:27, 12.47s/it, Loss=10.7362, Denoising=10.5773]Training:   1%|â–         | 752/55000 [2:45:02<187:51:27, 12.47s/it, Loss=10.4979, Denoising=10.3215]Training:   1%|â–         | 753/55000 [2:45:16<193:26:11, 12.84s/it, Loss=10.4979, Denoising=10.3215]Training:   1%|â–         | 753/55000 [2:45:16<193:26:11, 12.84s/it, Loss=10.2657, Denoising=10.0918]Training:   1%|â–         | 754/55000 [2:45:31<203:08:04, 13.48s/it, Loss=10.2657, Denoising=10.0918]Training:   1%|â–         | 754/55000 [2:45:31<203:08:04, 13.48s/it, Loss=10.3124, Denoising=10.1461]Training:   1%|â–         | 755/55000 [2:45:44<200:32:15, 13.31s/it, Loss=10.3124, Denoising=10.1461]Training:   1%|â–         | 755/55000 [2:45:44<200:32:15, 13.31s/it, Loss=10.5258, Denoising=10.3657]Training:   1%|â–         | 756/55000 [2:45:56<194:23:12, 12.90s/it, Loss=10.5258, Denoising=10.3657]Training:   1%|â–         | 756/55000 [2:45:56<194:23:12, 12.90s/it, Loss=10.9026, Denoising=10.7331]Training:   1%|â–         | 757/55000 [2:46:08<193:13:03, 12.82s/it, Loss=10.9026, Denoising=10.7331]Training:   1%|â–         | 757/55000 [2:46:08<193:13:03, 12.82s/it, Loss=10.4890, Denoising=10.3268]Training:   1%|â–         | 758/55000 [2:46:21<194:08:00, 12.88s/it, Loss=10.4890, Denoising=10.3268]Training:   1%|â–         | 758/55000 [2:46:21<194:08:00, 12.88s/it, Loss=10.6341, Denoising=10.4658]Training:   1%|â–         | 759/55000 [2:46:35<198:09:21, 13.15s/it, Loss=10.6341, Denoising=10.4658]Training:   1%|â–         | 759/55000 [2:46:35<198:09:21, 13.15s/it, Loss=10.4020, Denoising=10.2355]Training:   1%|â–         | 760/55000 [2:46:46<190:04:18, 12.62s/it, Loss=10.4020, Denoising=10.2355]Training:   1%|â–         | 760/55000 [2:46:46<190:04:18, 12.62s/it, Loss=10.4465, Denoising=10.2769]
--- PREVIEW (Step 760 | t=278) ---
Logit Range: [-1.07, 1.96]
Target: ### User:
If the pharmacy currently has 20 tubs in storage but needs a total of 100 tubs for the week, and they decide to purchase a quarter of the remaining tubs from a new vendor, how many tubs will...
Predict: ,### user:
 if the pharmacy currently has 20 tubs in storage but needs a total of 100 tubs for the week, and they decide to purchase a quarter of the remaining tubs from a new vendor, how many tubs wi...
--------------------------------------

Training:   1%|â–         | 761/55000 [2:47:00<193:17:29, 12.83s/it, Loss=10.4465, Denoising=10.2769]Training:   1%|â–         | 761/55000 [2:47:00<193:17:29, 12.83s/it, Loss=10.7563, Denoising=10.5912]Training:   1%|â–         | 762/55000 [2:47:12<190:10:58, 12.62s/it, Loss=10.7563, Denoising=10.5912]Training:   1%|â–         | 762/55000 [2:47:12<190:10:58, 12.62s/it, Loss=10.7385, Denoising=10.5664]Training:   1%|â–         | 763/55000 [2:47:26<195:32:36, 12.98s/it, Loss=10.7385, Denoising=10.5664]Training:   1%|â–         | 763/55000 [2:47:26<195:32:36, 12.98s/it, Loss=10.5113, Denoising=10.3443]
[WARNING] NaN loss detected! Skipping batch.
Training:   1%|â–         | 764/55000 [2:47:38<191:01:18, 12.68s/it, Loss=10.5113, Denoising=10.3443]Training:   1%|â–         | 764/55000 [2:47:38<191:01:18, 12.68s/it, Loss=10.2401, Denoising=10.0682]Training:   1%|â–         | 765/55000 [2:47:52<199:33:11, 13.25s/it, Loss=10.2401, Denoising=10.0682]Training:   1%|â–         | 765/55000 [2:47:52<199:33:11, 13.25s/it, Loss=10.4000, Denoising=10.2300]Training:   1%|â–         | 766/55000 [2:48:05<198:19:11, 13.16s/it, Loss=10.4000, Denoising=10.2300]Training:   1%|â–         | 766/55000 [2:48:05<198:19:11, 13.16s/it, Loss=10.9736, Denoising=10.7982]Training:   1%|â–         | 767/55000 [2:48:19<202:11:14, 13.42s/it, Loss=10.9736, Denoising=10.7982]Training:   1%|â–         | 767/55000 [2:48:19<202:11:14, 13.42s/it, Loss=10.4082, Denoising=10.2431]Training:   1%|â–         | 768/55000 [2:48:33<206:02:44, 13.68s/it, Loss=10.4082, Denoising=10.2431]Training:   1%|â–         | 768/55000 [2:48:34<206:02:44, 13.68s/it, Loss=10.7357, Denoising=10.5578]Training:   1%|â–         | 769/55000 [2:48:45<196:37:38, 13.05s/it, Loss=10.7357, Denoising=10.5578]Training:   1%|â–         | 769/55000 [2:48:45<196:37:38, 13.05s/it, Loss=10.4392, Denoising=10.2803]Training:   1%|â–         | 770/55000 [2:48:59<200:59:52, 13.34s/it, Loss=10.4392, Denoising=10.2803]Training:   1%|â–         | 770/55000 [2:48:59<200:59:52, 13.34s/it, Loss=10.6358, Denoising=10.4652]Training:   1%|â–         | 771/55000 [2:49:14<208:21:17, 13.83s/it, Loss=10.6358, Denoising=10.4652]Training:   1%|â–         | 771/55000 [2:49:14<208:21:17, 13.83s/it, Loss=10.6588, Denoising=10.4948]Training:   1%|â–         | 772/55000 [2:49:27<204:44:47, 13.59s/it, Loss=10.6588, Denoising=10.4948]Training:   1%|â–         | 772/55000 [2:49:27<204:44:47, 13.59s/it, Loss=10.3886, Denoising=10.2212]Training:   1%|â–         | 773/55000 [2:49:40<201:02:31, 13.35s/it, Loss=10.3886, Denoising=10.2212]Training:   1%|â–         | 773/55000 [2:49:40<201:02:31, 13.35s/it, Loss=10.3597, Denoising=10.1998]Training:   1%|â–         | 774/55000 [2:49:52<196:37:44, 13.05s/it, Loss=10.3597, Denoising=10.1998]Training:   1%|â–         | 774/55000 [2:49:52<196:37:44, 13.05s/it, Loss=10.6106, Denoising=10.4366]Training:   1%|â–         | 775/55000 [2:50:06<197:39:22, 13.12s/it, Loss=10.6106, Denoising=10.4366]Training:   1%|â–         | 775/55000 [2:50:06<197:39:22, 13.12s/it, Loss=10.2834, Denoising=10.1182]Training:   1%|â–         | 776/55000 [2:50:18<196:33:17, 13.05s/it, Loss=10.2834, Denoising=10.1182]Training:   1%|â–         | 776/55000 [2:50:19<196:33:17, 13.05s/it, Loss=10.7683, Denoising=10.5965]Training:   1%|â–         | 777/55000 [2:50:31<192:49:14, 12.80s/it, Loss=10.7683, Denoising=10.5965]Training:   1%|â–         | 777/55000 [2:50:31<192:49:14, 12.80s/it, Loss=10.6073, Denoising=10.4430]Training:   1%|â–         | 778/55000 [2:50:42<187:25:13, 12.44s/it, Loss=10.6073, Denoising=10.4430]Training:   1%|â–         | 778/55000 [2:50:42<187:25:13, 12.44s/it, Loss=10.4800, Denoising=10.3204]Training:   1%|â–         | 779/55000 [2:50:50<166:04:57, 11.03s/it, Loss=10.4800, Denoising=10.3204]Training:   1%|â–         | 779/55000 [2:50:50<166:04:57, 11.03s/it, Loss=10.4184, Denoising=10.2632]Training:   1%|â–         | 780/55000 [2:51:03<173:39:00, 11.53s/it, Loss=10.4184, Denoising=10.2632]Training:   1%|â–         | 780/55000 [2:51:03<173:39:00, 11.53s/it, Loss=10.3259, Denoising=10.1601]
--- PREVIEW (Step 780 | t=318) ---
Logit Range: [-1.07, 1.98]
Target: ### Assistant:
You are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. While performing the task think step-by-step and justify your steps.
...
Predict: ,### Assistant:
You are an AI assistant. user will you give you a task. Your goal is to complete the task as faithfully as you can. while performing the task think step by step and justify your steps....
--------------------------------------

Training:   1%|â–         | 781/55000 [2:51:18<188:45:53, 12.53s/it, Loss=10.3259, Denoising=10.1601]Training:   1%|â–         | 781/55000 [2:51:18<188:45:53, 12.53s/it, Loss=10.6192, Denoising=10.4517]Training:   1%|â–         | 782/55000 [2:51:33<199:50:36, 13.27s/it, Loss=10.6192, Denoising=10.4517]Training:   1%|â–         | 782/55000 [2:51:33<199:50:36, 13.27s/it, Loss=10.4114, Denoising=10.2403]Training:   1%|â–         | 783/55000 [2:51:45<195:59:32, 13.01s/it, Loss=10.4114, Denoising=10.2403]Training:   1%|â–         | 783/55000 [2:51:45<195:59:32, 13.01s/it, Loss=10.3202, Denoising=10.1488]Training:   1%|â–         | 784/55000 [2:51:57<190:13:45, 12.63s/it, Loss=10.3202, Denoising=10.1488]Training:   1%|â–         | 784/55000 [2:51:57<190:13:45, 12.63s/it, Loss=10.3230, Denoising=10.1513]Training:   1%|â–         | 785/55000 [2:52:10<194:56:54, 12.95s/it, Loss=10.3230, Denoising=10.1513]Training:   1%|â–         | 785/55000 [2:52:11<194:56:54, 12.95s/it, Loss=10.6220, Denoising=10.4562]Training:   1%|â–         | 786/55000 [2:52:24<196:22:01, 13.04s/it, Loss=10.6220, Denoising=10.4562]Training:   1%|â–         | 786/55000 [2:52:24<196:22:01, 13.04s/it, Loss=10.4436, Denoising=10.2776]Training:   1%|â–         | 787/55000 [2:52:37<196:47:27, 13.07s/it, Loss=10.4436, Denoising=10.2776]Training:   1%|â–         | 787/55000 [2:52:37<196:47:27, 13.07s/it, Loss=10.3804, Denoising=10.2090]Training:   1%|â–         | 788/55000 [2:52:50<197:16:07, 13.10s/it, Loss=10.3804, Denoising=10.2090]Training:   1%|â–         | 788/55000 [2:52:50<197:16:07, 13.10s/it, Loss=10.5134, Denoising=10.3359]Training:   1%|â–         | 789/55000 [2:53:01<187:12:39, 12.43s/it, Loss=10.5134, Denoising=10.3359]Training:   1%|â–         | 789/55000 [2:53:01<187:12:39, 12.43s/it, Loss=10.6442, Denoising=10.4756]Training:   1%|â–         | 790/55000 [2:53:15<195:04:23, 12.95s/it, Loss=10.6442, Denoising=10.4756]Training:   1%|â–         | 790/55000 [2:53:15<195:04:23, 12.95s/it, Loss=10.4714, Denoising=10.3032]Training:   1%|â–         | 791/55000 [2:53:28<195:56:36, 13.01s/it, Loss=10.4714, Denoising=10.3032]Training:   1%|â–         | 791/55000 [2:53:28<195:56:36, 13.01s/it, Loss=10.5177, Denoising=10.3577]Training:   1%|â–         | 792/55000 [2:53:42<201:15:26, 13.37s/it, Loss=10.5177, Denoising=10.3577]Training:   1%|â–         | 792/55000 [2:53:42<201:15:26, 13.37s/it, Loss=10.6058, Denoising=10.4324]Training:   1%|â–         | 793/55000 [2:53:54<195:09:40, 12.96s/it, Loss=10.6058, Denoising=10.4324]Training:   1%|â–         | 793/55000 [2:53:54<195:09:40, 12.96s/it, Loss=10.3627, Denoising=10.1985]Training:   1%|â–         | 794/55000 [2:54:08<198:38:56, 13.19s/it, Loss=10.3627, Denoising=10.1985]Training:   1%|â–         | 794/55000 [2:54:08<198:38:56, 13.19s/it, Loss=10.5991, Denoising=10.4264]Training:   1%|â–         | 795/55000 [2:54:21<197:54:01, 13.14s/it, Loss=10.5991, Denoising=10.4264]Training:   1%|â–         | 795/55000 [2:54:21<197:54:01, 13.14s/it, Loss=10.6941, Denoising=10.5271]Training:   1%|â–         | 796/55000 [2:54:35<199:56:58, 13.28s/it, Loss=10.6941, Denoising=10.5271]Training:   1%|â–         | 796/55000 [2:54:35<199:56:58, 13.28s/it, Loss=10.3575, Denoising=10.1879]Training:   1%|â–         | 797/55000 [2:54:47<197:48:53, 13.14s/it, Loss=10.3575, Denoising=10.1879]Training:   1%|â–         | 797/55000 [2:54:48<197:48:53, 13.14s/it, Loss=10.6724, Denoising=10.5094]Training:   1%|â–         | 798/55000 [2:55:01<199:06:40, 13.22s/it, Loss=10.6724, Denoising=10.5094]Training:   1%|â–         | 798/55000 [2:55:01<199:06:40, 13.22s/it, Loss=10.3611, Denoising=10.1894]Training:   1%|â–         | 799/55000 [2:55:14<198:01:12, 13.15s/it, Loss=10.3611, Denoising=10.1894]Training:   1%|â–         | 799/55000 [2:55:14<198:01:12, 13.15s/it, Loss=10.4640, Denoising=10.2990]Training:   1%|â–         | 800/55000 [2:55:28<204:27:37, 13.58s/it, Loss=10.4640, Denoising=10.2990]Training:   1%|â–         | 800/55000 [2:55:29<204:27:37, 13.58s/it, Loss=10.3333, Denoising=10.1608]
--- PREVIEW (Step 800 | t=227) ---
Logit Range: [-1.06, 1.97]
Target: ### User:
How would you check if a string contains only positive prime numbers in C++ efficiently, without using any built-in functions or libraries for prime number calculations?

### Assistant:
To c...
Predict: ### user:
 how would you check if a string contains only positive prime numbers in C++ efficiently, without using any built-in functions or libraries for prime number calculations?

### Assistant:
To ...
--------------------------------------

âš¡ Thunder PrefixLM: Diffusion layers and custom embeddings saved to ./thunder_prefixlm_llama/checkpoint-800

âš¡ Checkpoint saved to ./thunder_prefixlm_llama/checkpoint-800
âš¡ Removed old checkpoint ./thunder_prefixlm_llama/checkpoint-200
Training:   1%|â–         | 801/55000 [2:55:42<203:54:13, 13.54s/it, Loss=10.3333, Denoising=10.1608]Training:   1%|â–         | 801/55000 [2:55:42<203:54:13, 13.54s/it, Loss=10.9202, Denoising=10.7438]Training:   1%|â–         | 802/55000 [2:55:56<204:56:17, 13.61s/it, Loss=10.9202, Denoising=10.7438]Training:   1%|â–         | 802/55000 [2:55:56<204:56:17, 13.61s/it, Loss=10.4088, Denoising=10.2402]Training:   1%|â–         | 803/55000 [2:56:09<205:41:06, 13.66s/it, Loss=10.4088, Denoising=10.2402]Training:   1%|â–         | 803/55000 [2:56:10<205:41:06, 13.66s/it, Loss=10.4374, Denoising=10.2688]Training:   1%|â–         | 804/55000 [2:56:24<209:52:08, 13.94s/it, Loss=10.4374, Denoising=10.2688]Training:   1%|â–         | 804/55000 [2:56:24<209:52:08, 13.94s/it, Loss=10.6796, Denoising=10.5125]Training:   1%|â–         | 805/55000 [2:56:39<212:46:52, 14.13s/it, Loss=10.6796, Denoising=10.5125]Training:   1%|â–         | 805/55000 [2:56:39<212:46:52, 14.13s/it, Loss=10.5530, Denoising=10.3832]Training:   1%|â–         | 806/55000 [2:56:51<205:09:29, 13.63s/it, Loss=10.5530, Denoising=10.3832]Training:   1%|â–         | 806/55000 [2:56:51<205:09:29, 13.63s/it, Loss=10.8577, Denoising=10.6877]